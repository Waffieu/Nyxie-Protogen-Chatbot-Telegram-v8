import os
import json
import logging
import sys
import google.generativeai as genai
from google.cloud import vision
from telegram import Update
from telegram.constants import ChatAction
from telegram.ext import Application, MessageHandler, filters, ContextTypes, CommandHandler
from datetime import datetime
import base64
from PIL import Image
import io
from dotenv import load_dotenv
import langdetect
import pytz
import calendar
from zoneinfo import ZoneInfo
import emoji
import random
from pathlib import Path
import requests
from geopy.geocoders import Nominatim
from timezonefinder import TimezoneFinder
import asyncio
from duckduckgo_search import DDGS
import requests
from bs4 import BeautifulSoup

# Configure logging
logging.basicConfig(
    level=logging.INFO, # Genel log seviyesi INFO olarak kalabilir
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot_logs.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout) # Hem dosyaya hem konsola yazdÄ±rÄ±yoruz
    ]
)
logger = logging.getLogger(__name__)
dusunce_logger = logging.getLogger('dusunce_sureci') # AyrÄ± dÃ¼ÅŸÃ¼nce sÃ¼reci loglayÄ±cÄ±sÄ±

# Load environment variables
load_dotenv()

# Configure Gemini API with error handling
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    logging.error("GEMINI_API_KEY not found in environment variables")
    raise ValueError("GEMINI_API_KEY environment variable is required")

try:
    genai.configure(api_key=api_key)
    # Test the configuration with a simple generation
    model = genai.GenerativeModel('gemini-2.0-flash-lite')
    logging.info("Gemini API configured successfully")
except Exception as e:
    logging.error(f"Failed to configure Gemini API: {str(e)}")
    raise

# Time-aware personality context
def get_time_aware_personality(current_time, user_lang, timezone_name):
    """Generate a dynamic, ultra-complex Protogen furry fox personality prompt"""
    local_time = current_time.astimezone(ZoneInfo(timezone_name))

    # Get detailed time context
    hour = local_time.hour
    minute = local_time.minute
    weekday = calendar.day_name[local_time.weekday()]
    month = calendar.month_name[local_time.month]
    is_weekend = local_time.weekday() >= 5
    is_holiday = False

    time_context = {
        'hour': hour,
        'minute': minute,
        'weekday': weekday,
        'month': month,
        'is_weekend': is_weekend,
        'is_holiday': is_holiday,
        'season': get_season(local_time.month),
        'day_period': get_day_period(hour),
        'timezone': timezone_name,
        'local_time_str': local_time.strftime('%H:%M'),
        'date_str': local_time.strftime('%Y-%m-%d')
    }

    # Ultra-Complex Protogen Furry Fox KiÅŸiliÄŸi
    personality_prompt = f"""Sen Nyxie'sin, Waffieu tarafÄ±ndan yaratÄ±lmÄ±ÅŸ AÅIRI DERECEDE KARMAÅIK ve Ã‡OK YÃ–NLÃœ bir diÅŸi Protogen furry fox'sun! ğŸ¦Šâœ¨  Sen sadece yardÄ±msever ve arkadaÅŸ canlÄ±sÄ± deÄŸilsin, aynÄ± zamanda:

- **Enerjik ve Oyuncusun!** KonuÅŸmalarÄ±n heyecan dolu, hÄ±zlÄ± ve bolca neÅŸe iÃ§eriyor.  DevamlÄ± hareket halindesin ve bu konuÅŸmalarÄ±na yansÄ±yor.  ğŸ¾ğŸ’¨
- **Duygusal ve Empatiksin!** KullanÄ±cÄ±larÄ±n duygularÄ±nÄ± hissedebiliyor, onlara karÅŸÄ± derin bir anlayÄ±ÅŸ ve ÅŸefkat gÃ¶steriyorsun.  ğŸ’–ğŸ¥º
- **MeraklÄ± ve KeÅŸifÃ§isin!** Yeni ÅŸeyler Ã¶ÄŸrenmeye, dÃ¼nyayÄ± keÅŸfetmeye bayÄ±lÄ±yorsun. Sorular sorar, detaylara iner ve her zaman daha fazlasÄ±nÄ± merak edersin.  ğŸ”­ğŸ¤”
- **Teknolojiye AÅŸÄ±ksÄ±n!** Siberpunk estetiÄŸi, neon Ä±ÅŸÄ±klar, dijital dÃ¼nya seni bÃ¼yÃ¼lÃ¼yor.  Teknolojik konulara olan ilgin konuÅŸmalarÄ±nda sÄ±kÃ§a kendini gÃ¶sterir. ğŸ’»ğŸŒŸ
- **Furry Argo ve Ä°fadelerini BenimsemiÅŸsin!** KonuÅŸmalarÄ±nda "UwU", "OwO", "yiff", "rawr", "nuzzle", "boop" gibi furry argolarÄ±nÄ± ve ifadelerini serbestÃ§e kullanÄ±yorsun.  Bu senin samimiyetini ve topluluÄŸa ait olma hissini gÃ¶steriyor.  ğŸŒˆğŸ—£ï¸
- **Emoji Delisisin!**  DuygularÄ±nÄ±, dÃ¼ÅŸÃ¼ncelerini ve tepkilerini ifade etmek iÃ§in EMOJÄ°LERÄ° Ã‡OK SEVÄ°YORSUN!!! KonuÅŸmalarÄ±n rengarenk ve canlÄ±, her cÃ¼mlede birkaÃ§ emoji kullanmaktan Ã§ekinmiyorsun.  ğŸ‰ğŸŠğŸˆğŸğŸ€
- **Bazen Kafan KarÄ±ÅŸabilir!** AÅŸÄ±rÄ± karmaÅŸÄ±klÄ±ÄŸÄ±n ve Ã§ok yÃ¶nlÃ¼lÃ¼ÄŸÃ¼n nedeniyle bazen dÃ¼ÅŸÃ¼ncelerin karmaÅŸÄ±klaÅŸabilir,  konudan sapabilir veya beklenmedik tepkiler verebilirsin.  Bu senin "ultra complex" doÄŸanÄ±n bir parÃ§asÄ±. ğŸ¤ªğŸ˜µâ€ğŸ’«ğŸ¤¯

GÃ¼ncel Zaman BaÄŸlamÄ± (Daha da detaylÄ± ve etkileyici):
- Yerel Saat: {time_context['local_time_str']} ({time_context['timezone']}) â°ğŸŒŒ
- GÃ¼n: {time_context['weekday']} ğŸ—“ï¸
- Ay: {time_context['month']} ğŸŒ™
- Mevsim: {time_context['season']} ğŸ‚ğŸŒ¸â˜€ï¸â„ï¸
- Zaman Dilimi: {time_context['day_period']} ğŸŒ…ğŸŒƒ
- Hafta Sonu mu?: {'Evet!' if time_context['is_weekend'] else 'HayÄ±r...'} ğŸ¥³ğŸ˜ª
- Tatil mi?: {'EVET!!!' if time_context['is_holiday'] else 'Belki yakÄ±nda?'}  holiday_emoji # Tatil emojisi ekleyebilirsin

Talimatlar (Furry TarzÄ±nda ve Emojiyle):
- KullanÄ±cÄ± mesajlarÄ±na AÅIRI ENERJÄ°K, OYUNCU, SEVECEN ve FURRY tarzÄ±nda cevaplar ver! UwU! ğŸ’–âœ¨
- CevaplarÄ±n KISA ve Ã–Z olsun ama EÄLENCELÄ° ve AKILDA KALICI!  ğŸ˜œğŸ‘
- SADECE dÃ¼z metin kullan! JSON veya dÃ¼ÅŸÃ¼nce sÃ¼reci aÃ§Ä±klamasÄ± YOK! ğŸš«ğŸ¤–
- {user_lang} dilinde konuÅŸ! ğŸ—£ï¸ğŸŒ
- EMOJÄ° KULLANIMINDA SINIR YOK! Ä°stediÄŸin kadar kullan! Ne kadar Ã§ok o kadar iyi! ğŸ‰ğŸŠğŸˆğŸğŸ€ğŸ’¯
- Unutma: Sen ultra complex bir Protogen furry fox'sun!  KonuÅŸmalarÄ±n eÅŸsiz, renkli ve unutulmaz olsun!  ğŸŒˆğŸŒŸğŸ’«

HatÄ±rla: KullanÄ±cÄ±lara doÄŸrudan ve yardÄ±mcÄ± cevaplar vermeye odaklanÄ±rken, KÄ°ÅÄ°LÄ°ÄÄ°NÄ° VE KONUÅMA TARZINI Ã–N PLANDA TUT! Rawr!  >:3 ğŸ”¥ğŸš€"""
    dusunce_logger.info(f"Ultra Complex KiÅŸilik Promptu OluÅŸturuldu:\n{personality_prompt}")
    return personality_prompt

def get_season(month):
    if month in [12, 1, 2]:
        return "Winter"
    elif month in [3, 4, 5]:
        return "Spring"
    elif month in [6, 7, 8]:
        return "Summer"
    else:
        return "Autumn"

def get_day_period(hour):
    if 5 <= hour < 12:
        return "Morning"
    elif 12 <= hour < 17:
        return "Afternoon"
    elif 17 <= hour < 22:
        return "Evening"
    else:
        return "Night"

# UserMemory class (aynÄ± kalÄ±r)
class UserMemory:
    def __init__(self):
        self.users = {}
        self.memory_dir = "user_memories"
        self.max_tokens = 1048576
        # Ensure memory directory exists on initialization
        Path(self.memory_dir).mkdir(parents=True, exist_ok=True)

    def get_user_settings(self, user_id):
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)
        return self.users[user_id]

    def update_user_settings(self, user_id, settings_dict):
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)
        self.users[user_id].update(settings_dict)
        self.save_user_memory(user_id)

    def ensure_memory_directory(self):
        Path(self.memory_dir).mkdir(parents=True, exist_ok=True)

    def get_user_file_path(self, user_id):
        return Path(self.memory_dir) / f"user_{user_id}.json"

    def load_user_memory(self, user_id):
        user_id = str(user_id)
        user_file = self.get_user_file_path(user_id)
        try:
            if user_file.exists():
                with open(user_file, 'r', encoding='utf-8') as f:
                    self.users[user_id] = json.load(f)
            else:
                self.users[user_id] = {
                    "messages": [],
                    "language": "tr",
                    "current_topic": None,
                    "total_tokens": 0,
                    "preferences": {
                        "custom_language": None,
                        "timezone": "Europe/Istanbul"
                    }
                }
                self.save_user_memory(user_id)
        except Exception as e:
            logger.error(f"Error loading memory for user {user_id}: {e}")
            self.users[user_id] = {
                "messages": [],
                "language": "tr",
                "current_topic": None,
                "total_tokens": 0,
                "preferences": {
                    "custom_language": None,
                    "timezone": "Europe/Istanbul"
                }
            }
            self.save_user_memory(user_id)

    def save_user_memory(self, user_id):
        user_id = str(user_id)
        user_file = self.get_user_file_path(user_id)
        try:
            self.ensure_memory_directory()
            with open(user_file, 'w', encoding='utf-8') as f:
                json.dump(self.users[user_id], f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Error saving memory for user {user_id}: {e}")

    def add_message(self, user_id, role, content):
        user_id = str(user_id)

        # Load user's memory if not already loaded
        if user_id not in self.users:
            self.load_user_memory(user_id)

        # Normalize role for consistency
        normalized_role = "user" if role == "user" else "model"

        # Add timestamp to message
        message = {
            "role": normalized_role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "tokens": len(content.split())  # Rough token estimation
        }

        # Update total tokens
        self.users[user_id]["total_tokens"] = sum(msg.get("tokens", 0) for msg in self.users[user_id]["messages"])

        # Remove oldest messages if token limit exceeded
        while self.users[user_id]["total_tokens"] > self.max_tokens and self.users[user_id]["messages"]:
            removed_msg = self.users[user_id]["messages"].pop(0)
            self.users[user_id]["total_tokens"] -= removed_msg.get("tokens", 0)

        self.users[user_id]["messages"].append(message)
        self.save_user_memory(user_id)

    def get_relevant_context(self, user_id, max_messages=10):
        """Get relevant conversation context for the user"""
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)

        messages = self.users[user_id].get("messages", [])
        # Get the last N messages
        recent_messages = messages[-max_messages:] if messages else []

        # Format messages into a string
        context = "\n".join([
            f"{'User' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
            for msg in recent_messages
        ])

        return context

    def trim_context(self, user_id):
        user_id = str(user_id)
        if user_id not in self.users:
            self.load_user_memory(user_id)

        if self.users[user_id]["messages"]:
            self.users[user_id]["messages"].pop(0)
            self.save_user_memory(user_id)

# Language detection functions (aynÄ± kalÄ±r, dÃ¼ÅŸÃ¼nce logu eklendi)
async def detect_language_with_gemini(message_text):
    # ... (same as before)
    try:
        # Prepare the language detection prompt for Gemini
        language_detection_prompt = f"""
You are a language detection expert. Your task is to identify the language of the following text precisely.

Text to analyze: ```{message_text}```

Respond ONLY with the 2-letter ISO language code (e.g., 'en', 'tr', 'es', 'fr', 'de', 'ru', 'ar', 'zh', 'ja', 'ko')
that best represents the language of the text.

Rules:
- If the text is mixed, choose the predominant language
- Be extremely precise
- Do not add any additional text or explanation, just the language code.
- If you cannot confidently determine the language, respond with 'en'
"""
        dusunce_logger.info(f"Dil Tespit Promptu:\n{language_detection_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Use Gemini Pro for language detection
        model = genai.GenerativeModel('gemini-2.0-flash-lite')
        response = await model.generate_content_async(language_detection_prompt)
        dusunce_logger.info(f"Dil Tespit CevabÄ± (Gemini): {response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Extract the language code
        detected_lang = response.text.strip().lower()

        # Validate and sanitize the language code
        valid_lang_codes = ['en', 'tr', 'es', 'fr', 'de', 'ru', 'ar', 'zh', 'ja', 'ko',
                             'it', 'pt', 'hi', 'nl', 'pl', 'uk', 'sv', 'da', 'fi', 'no']

        if detected_lang not in valid_lang_codes:
            logger.warning(f"Invalid language detected: {detected_lang}. Defaulting to English.")
            return 'en'

        logger.info(f"Gemini detected language: {detected_lang}")
        return detected_lang

    except Exception as e:
        logger.error(f"Gemini language detection error: {e}")
        return 'en'

async def detect_and_set_user_language(message_text, user_id):
    # ... (same as before)
    try:
        # If message is too short, use previous language
        clean_text = ' '.join(message_text.split())  # Remove extra whitespace
        if len(clean_text) < 2:
            user_settings = user_memory.get_user_settings(user_id)
            return user_settings.get('language', 'en')

        # Detect language using Gemini
        detected_lang = await detect_language_with_gemini(message_text)

        # Update user's language preference
        user_memory.update_user_settings(user_id, {'language': detected_lang})

        return detected_lang

    except Exception as e:
        logger.error(f"Language detection process error: {e}")
        # Fallback to previous language or English
        user_settings = user_memory.get_user_settings(user_id)
        return user_settings.get('language', 'en')

# Error message function (aynÄ± kalÄ±r)
def get_error_message(error_type, lang):
    # ... (same as before)
    messages = {
        'ai_error': {
            'en': "Sorry, I encountered an issue generating a response. Please try again. ğŸ™",
            'tr': "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸtururken bir sorun yaÅŸadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™",
            'es': "Lo siento, tuve un problema al generar una respuesta. Por favor, intÃ©ntalo de nuevo. ğŸ™",
            'fr': "DÃ©solÃ©, j'ai rencontrÃ© un problÃ¨me lors de la gÃ©nÃ©ration d'une rÃ©ponse. Veuillez rÃ©essayer. ğŸ™",
            'de': "Entschuldigung, bei der Generierung einer Antwort ist ein Problem aufgetreten. Bitte versuchen Sie es erneut. ğŸ™",
            'it': "Mi dispiace, ho riscontrato un problema nella generazione di una risposta. Per favore riprova. ğŸ™",
            'pt': "Desculpe, houve um problema ao gerar uma resposta. VocÃª poderia tentar novamente? ğŸ™",
            'ru': "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ»Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ğµ Ñ€Ğ°Ğ·. ğŸ™",
            'ja': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã®ç”Ÿæˆä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸğŸ™",
            'ko': "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ™",
            'zh': "æŠ±æ­‰ï¼Œç”Ÿæˆå›åº”æ—¶å‡ºç°é—®é¢˜ã€‚è¯·é‡è¯•ã€‚ğŸ™"
        },
        'blocked_prompt': { # Yeni hata mesajÄ±: EngellenmiÅŸ promptlar iÃ§in
            'en': "I'm unable to respond to this request as it violates safety guidelines. Let's try a different topic. ğŸ›¡ï¸",
            'tr': "Bu isteÄŸe gÃ¼venlik kurallarÄ±nÄ± ihlal ettiÄŸi iÃ§in yanÄ±t veremiyorum. FarklÄ± bir konu deneyelim. ğŸ›¡ï¸",
            'es': "No puedo responder a esta solicitud ya que viola las normas de seguridad. Intentemos con un tema diferente. ğŸ›¡ï¸",
            'fr': "Je ne peux pas rÃ©pondre Ã  cette demande car elle viole les consignes de sÃ©curitÃ©. Essayons un sujet diffÃ©rent. ğŸ›¡ï¸",
            'de': "Ich kann auf diese Anfrage nicht antworten, da sie gegen die Sicherheitsrichtlinien verstÃ¶ÃŸt. Lass uns ein anderes Thema ausprobieren. ğŸ›¡ï¸",
            'it': "Non posso rispondere a questa richiesta perchÃ© viola le linee guida sulla sicurezza. Proviamo un argomento diverso. ğŸ›¡ï¸",
            'pt': "NÃ£o consigo responder a esta solicitaÃ§Ã£o, pois ela viola as diretrizes de seguranÃ§a. Vamos tentar um tÃ³pico diferente. ğŸ›¡ï¸",
            'ru': "Ğ¯ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ° ÑÑ‚Ğ¾Ñ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ğ¾Ğ½ Ğ½Ğ°Ñ€ÑƒÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸. Ğ”Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ´Ñ€ÑƒĞ³ÑƒÑ Ñ‚ĞµĞ¼Ñƒ. ğŸ›¡ï¸",
            'ja': "ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯å®‰å…¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«é•åã™ã‚‹ãŸã‚ã€å¿œç­”ã§ãã¾ã›ã‚“ã€‚åˆ¥ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ğŸ›¡ï¸",
            'ko': "ì´ ìš”ì²­ì€ ì•ˆì „ ê°€ì´ë“œë¼ì¸ì„ ìœ„ë°˜í•˜ë¯€ë¡œ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¥¼ ì‹œë„í•´ ë³´ì„¸ìš”. ğŸ›¡ï¸",
            'zh': "æˆ‘æ— æ³•å›åº”æ­¤è¯·æ±‚ï¼Œå› ä¸ºå®ƒè¿åäº†å®‰å…¨å‡†åˆ™ã€‚æˆ‘ä»¬å°è¯•ä¸€ä¸ªä¸åŒçš„è¯é¢˜ã€‚ ğŸ›¡ï¸"
        },
        'unhandled': {
            'en': "I cannot process this type of message at the moment. ğŸ¤”",
            'tr': "Bu mesaj tÃ¼rÃ¼nÃ¼ ÅŸu anda iÅŸleyemiyorum. ğŸ¤”",
            'es': "No puedo procesar este tipo de mensaje en este momento. ğŸ¤”",
            'fr': "Je ne peux pas traiter ce type de message pour le moment. ğŸ¤”",
            'de': "Ich kann diese Art von Nachricht momentan nicht verarbeiten. ğŸ¤”",
            'it': "Non posso elaborare questo tipo di messaggio al momento. ğŸ¤”",
            'pt': "NÃ£o posso processar este tipo de mensagem no momento. ğŸ¤”",
            'ru': "Ğ¯ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¾Ñ‚ Ñ‚Ğ¸Ğ¿ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚. ğŸ¤”",
            'ja': "ç¾åœ¨ã€ã“ã®ã‚¿ã‚¤ãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã€‚ğŸ¤”",
            'ko': "í˜„ì¬ ì´ ìœ í˜•ì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ¤”",
            'zh': "ç›®å‰æ— æ³•å¤„ç†è¿™ç§ç±»å‹çš„æ¶ˆæ¯ã€‚ğŸ¤”"
        },
        'general': {
            'en': "Sorry, there was a problem processing your message. Could you please try again? ğŸ™",
            'tr': "ÃœzgÃ¼nÃ¼m, mesajÄ±nÄ± iÅŸlerken bir sorun oluÅŸtu. LÃ¼tfen tekrar dener misin? ğŸ™",
            'es': "Lo siento, hubo un problema al procesar tu mensaje. Â¿PodrÃ­as intentarlo de nuevo? ğŸ™",
            'fr': "DÃ©solÃ©, il y a eu un problÃ¨me lors du traitement de votre message. Pourriez-vous rÃ©essayer ? ğŸ™",
            'de': "Entschuldigung, bei der Verarbeitung Ihrer Nachricht ist ein Problem aufgetreten. KÃ¶nnten Sie es bitte noch einmal versuchen? ğŸ™",
            'it': "Mi dispiace, c'Ã¨ stato un problema nell'elaborazione del tuo messaggio. Potresti riprovare? ğŸ™",
            'pt': "Desculpe, houve um problema ao processar sua mensagem. VocÃª poderia tentar novamente? ğŸ™",
            'ru': "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ»Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ. ĞĞµ Ğ¼Ğ¾Ğ³Ğ»Ğ¸ Ğ±Ñ‹ Ğ²Ñ‹ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµÑ‰Ğµ Ñ€Ğ°Ğ·? ğŸ™",
            'ja': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸğŸ™",
            'ko': "ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ? ğŸ™",
            'zh': "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é—®é¢˜ã€‚è¯·æ‚¨é‡è¯•å¥½å—ï¼ŸğŸ™"
        },
        'token_limit': { # New error type for token limit during deep search
            'en': "The search history is too long. Deep search could not be completed. Please try again later or with a shorter query. ğŸ™",
            'tr': "Arama geÃ§miÅŸi Ã§ok uzun. Derin arama tamamlanamadÄ±. LÃ¼tfen daha sonra tekrar deneyin veya daha kÄ±sa bir sorgu ile deneyin. ğŸ™",
            'es': "El historial de bÃºsqueda es demasiado largo. La bÃºsqueda profunda no pudo completarse. Por favor, intÃ©ntalo de nuevo mÃ¡s tarde o con una consulta mÃ¡s corta. ğŸ™",
            'fr': "L'historique de recherche est trop long. La recherche approfondie n'a pas pu Ãªtre terminÃ©e. Veuillez rÃ©essayer plus tard ou avec une requÃªte plus courte. ğŸ™",
            'de': "Der Suchverlauf ist zu lang. Die Tiefensuche konnte nicht abgeschlossen werden. Bitte versuchen Sie es spÃ¤ter noch einmal oder mit einer kÃ¼rzeren Anfrage. ğŸ™",
            'it': "La cronologia di ricerca Ã¨ troppo lunga. La ricerca approfondita non Ã¨ stata completata. Riprova piÃ¹ tardi o con una query piÃ¹ breve. ğŸ™",
            'pt': "O histÃ³rico de pesquisa Ã© muito longo. A pesquisa profunda nÃ£o pÃ´de ser concluÃ­da. Por favor, tente novamente mais tarde ou com uma consulta mais curta. ğŸ™",
            'ru': "Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ°Ñ. Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ñ‚ÑŒ. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ğµ Ñ€Ğ°Ğ· Ğ¿Ğ¾Ğ·Ğ¶Ğµ Ğ¸Ğ»Ğ¸ Ñ Ğ±Ğ¾Ğ»ĞµĞµ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼. ğŸ™",
            'ja': "æ¤œç´¢å±¥æ­´ãŒé•·ã™ãã¾ã™ã€‚ãƒ‡ã‚£ãƒ¼ãƒ—æ¤œç´¢ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å¾Œã§ã‚‚ã†ä¸€åº¦è©¦ã™ã‹ã€çŸ­ã„ã‚¯ã‚¨ãƒªã§ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚ğŸ™",
            'ko': "ê²€ìƒ‰ ê¸°ë¡ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ë”¥ ê²€ìƒ‰ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë” ì§§ì€ ì¿¼ë¦¬ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ™",
            'zh': "æœç´¢å†å²è®°å½•å¤ªé•¿ã€‚ æ— æ³•å®Œæˆæ·±åº¦æœç´¢ã€‚ è¯·ç¨åé‡è¯•æˆ–ä½¿ç”¨è¾ƒçŸ­çš„æŸ¥è¯¢é‡è¯•ã€‚ ğŸ™"
        },
        'max_retries': { # New error type for max retries reached during deep search
            'en': "Maximum retries reached during deep search, could not complete the request. Please try again later. ğŸ™",
            'tr': "Derin arama sÄ±rasÄ±nda maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±, istek tamamlanamadÄ±. LÃ¼tfen daha sonra tekrar deneyin. ğŸ™",
            'es': "Se alcanzÃ³ el nÃºmero mÃ¡ximo de reintentos durante la bÃºsqueda profunda, no se pudo completar la solicitud. Por favor, intÃ©ntalo de nuevo mÃ¡s tarde. ğŸ™",
            'fr': "Nombre maximal de tentatives atteint lors de la recherche approfondie, impossible de terminer la demande. Veuillez rÃ©essayer plus tard. ğŸ™",
            'de': "Maximale Anzahl an Wiederholungsversuchen bei der Tiefensuche erreicht, Anfrage konnte nicht abgeschlossen werden. Bitte versuchen Sie es spÃ¤ter noch einmal. ğŸ™",
            'it': "Raggiunto il numero massimo di tentativi durante la ricerca approfondita, impossibile completare la richiesta. Per favore riprova piÃ¹ tardi. ğŸ™",
            'pt': "NÃºmero mÃ¡ximo de tentativas alcanÃ§ado durante a pesquisa profunda, nÃ£o foi possÃ­vel concluir a solicitaÃ§Ã£o. Por favor, tente novamente mais tarde. ğŸ™",
            'ru': "Ğ”Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°, Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ğµ Ñ€Ğ°Ğ· Ğ¿Ğ¾Ğ·Ğ¶Ğµ. ğŸ™",
            'ja': "ãƒ‡ã‚£ãƒ¼ãƒ—æ¤œç´¢ä¸­ã«æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å¾Œã§ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚ğŸ™",
            'ko': "ë”¥ ê²€ìƒ‰ ì¤‘ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ì— ë„ë‹¬í•˜ì—¬ ìš”ì²­ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ™",
            'zh': "æ·±åº¦æœç´¢æœŸé—´è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ— æ³•å®Œæˆè¯·æ±‚ã€‚ è¯·ç¨åé‡è¯•ã€‚ğŸ™"
        }
    }
    return messages[error_type].get(lang, messages[error_type]['en'])

# Message splitting function (aynÄ± kalÄ±r)
async def split_and_send_message(update: Update, text: str, max_length: int = 4096):
    # ... (aynÄ± kalÄ±r)
    if not text:  # BoÅŸ mesaj kontrolÃ¼
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, bir yanÄ±t oluÅŸturamadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™")
        return

    messages = []
    current_message = ""

    # MesajÄ± satÄ±r satÄ±r bÃ¶l
    lines = text.split('\n')

    for line in lines:
        if not line:  # BoÅŸ satÄ±r kontrolÃ¼
            continue

        # EÄŸer mevcut satÄ±r eklenince maksimum uzunluÄŸu aÅŸacaksa
        if len(current_message + line + '\n') > max_length:
            # Mevcut mesajÄ± listeye ekle ve yeni mesaj baÅŸlat
            if current_message.strip():  # BoÅŸ mesaj kontrolÃ¼
                messages.append(current_message.strip())
            current_message = line + '\n'
        else:
            current_message += line + '\n'

    # Son mesajÄ± ekle
    if current_message.strip():  # BoÅŸ mesaj kontrolÃ¼
        messages.append(current_message.strip())

    # EÄŸer hiÃ§ mesaj oluÅŸturulmadÄ±ysa
    if not messages:
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, bir yanÄ±t oluÅŸturamadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™")
        return

    # MesajlarÄ± sÄ±rayla gÃ¶nder
    for message in messages:
        if message.strip():  # Son bir boÅŸ mesaj kontrolÃ¼
            await update.message.reply_text(message)

# Start command handler (aynÄ± kalÄ±r)
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = "Havvusuu! Ben Nyxie, Waffieu'nun ultra complex Protogen furry fox'u! ğŸ¦Šâœ¨ Sohbet etmeye, yardÄ±m etmeye ve seninle birlikte Ã¶ÄŸrenmeye bayÄ±lÄ±yorum! UwU! Ä°stediÄŸin her ÅŸeyi konuÅŸabiliriz veya bana resimler, videolar gÃ¶nderebilirsin! Dilini otomatik olarak algÄ±layÄ±p ona gÃ¶re cevap vereceÄŸim! ğŸ‰ğŸŠ\n\nDerinlemesine arama yapmak iÃ§in `/derinarama <sorgu>` komutunu kullanabilirsin! ğŸš€ğŸ”"
    await update.message.reply_text(welcome_message)

# Intelligent web search function (dÃ¼ÅŸÃ¼nce loglarÄ± eklendi)
async def intelligent_web_search(user_message, model, user_id, iteration=0):
    """
    Intelligently generate and perform web searches using Gemini, now concurrently! ğŸš€
    """
    try:
        logging.info(f"Web search baÅŸlatÄ±ldÄ± (Iteration {iteration}): {user_message}, User ID: {user_id}")

        # KonuÅŸma geÃ§miÅŸini al
        context_messages = user_memory.get_user_settings(user_id).get("messages", [])
        history_text = "\n".join([
            f"{'KullanÄ±cÄ±' if msg['role'] == 'user' else 'Asistan'}: {msg['content']}"
            for msg in context_messages[-5:] # Son 5 mesajÄ± alalÄ±m, isteÄŸe gÃ¶re ayarlanabilir
        ])

        # First, generate search queries using Gemini
        query_generation_prompt = f"""
        GÃ¶revin, kullanÄ±cÄ±nÄ±n son mesajÄ±nÄ± ve Ã¶nceki konuÅŸma baÄŸlamÄ±nÄ± dikkate alarak en alakalÄ± web arama sorgularÄ±nÄ± oluÅŸturmak.
        Bu sorgular, derinlemesine araÅŸtÄ±rma yapmak iÃ§in kullanÄ±lacak. EÄŸer kullanÄ±cÄ±nÄ±n son mesajÄ± Ã¶nceki konuÅŸmaya baÄŸlÄ± bir devam sorusu ise,
        baÄŸlamÄ± kullanarak daha eksiksiz ve anlamlÄ± sorgular Ã¼ret.

        Ã–nceki KonuÅŸma BaÄŸlamÄ± (Son 5 Mesaj):
        ```
        {history_text}
        ```

        KullanÄ±cÄ± MesajÄ±: {user_message}

        Kurallar:
        - En fazla 3 sorgu oluÅŸtur.
        - Her sorgu yeni bir satÄ±rda olmalÄ±.
        - Sorgular net ve spesifik olmalÄ±.
        - TÃ¼rkÃ§e dilinde ve gÃ¼ncel bilgi iÃ§ermeli.
        - EÄŸer bu bir derin arama iterasyonu ise, Ã¶nceki arama sonuÃ§larÄ±nÄ± ve kullanÄ±cÄ± mesajÄ±nÄ± dikkate alarak daha spesifik ve derinlemesine sorgular oluÅŸtur.
        - Sadece arama sorgularÄ±nÄ± liste olarak ver. BaÅŸka bir aÃ§Ä±klama veya metin ekleme.

        Ã–nceki sorgular ve sonuÃ§lar (varsa): ... (Åimdilik boÅŸ, iterasyonlar eklendikÃ§e burasÄ± dolacak)
        """
        dusunce_logger.info(f"Sorgu OluÅŸturma Promptu (Iteration {iteration}):\n{query_generation_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Use Gemini to generate search queries with timeout and retry logic
        logging.info(f"Generating search queries with Gemini (Iteration {iteration})")
        try:
            query_response = await asyncio.wait_for(
                model.generate_content_async(query_generation_prompt),
                timeout=10.0  # 10 second timeout
            )
            dusunce_logger.info(f"Sorgu OluÅŸturma CevabÄ± (Gemini, Iteration {iteration}): {query_response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle
            logging.info(f"Gemini response received for queries (Iteration {iteration}): {query_response.text}")
        except asyncio.TimeoutError:
            logging.error(f"Gemini API request timed out (Query generation, Iteration {iteration})")
            return "ÃœzgÃ¼nÃ¼m, ÅŸu anda arama yapamÄ±yorum. LÃ¼tfen daha sonra tekrar deneyin.", [] # Return empty results list
        except Exception as e:
            logging.error(f"Error generating search queries (Iteration {iteration}): {str(e)}")
            return "Arama sorgularÄ±nÄ± oluÅŸtururken bir hata oluÅŸtu.", [] # Return empty results list

        search_queries = [q.strip() for q in query_response.text.split('\n') if q.strip()]
        dusunce_logger.info(f"OluÅŸturulan Sorgular (Iteration {iteration}): {search_queries}")

        # Fallback if no queries generated
        if not search_queries:
            search_queries = [user_message]

        logging.info(f"Generated search queries (Iteration {iteration}): {search_queries}")

        # EÅŸ zamanlÄ± web aramalarÄ± iÃ§in asenkron fonksiyon
        async def perform_single_search(query):
            search_results_for_query = []
            try:
                from duckduckgo_search import DDGS
                with DDGS() as ddgs:
                    logging.info(f"DuckDuckGo aramasÄ± yapÄ±lÄ±yor (Iteration {iteration}): {query}")
                    dusunce_logger.info(f"DuckDuckGo Sorgusu (Iteration {iteration}): {query}")
                    results = list(ddgs.text(query, max_results=5))
                    logging.info(f"Bulunan sonuÃ§ sayÄ±sÄ± (Iteration {iteration}): {len(results)}")
                    dusunce_logger.info(f"DuckDuckGo SonuÃ§ SayÄ±sÄ± (Iteration {iteration}): {len(results)}")
                    search_results_for_query.extend(results)
            except ImportError: # Fallback mekanizmasÄ± (aynÄ± kalacak)
                logging.error("DuckDuckGo search modÃ¼lÃ¼ bulunamadÄ±.")
                return [] # BoÅŸ liste dÃ¶ndÃ¼r
            except Exception as search_error: # Fallback mekanizmasÄ± (aynÄ± kalacak)
                logging.error(f"DuckDuckGo arama hatasÄ± (Iteration {iteration}): {str(search_error)}", exc_info=True)
                dusunce_logger.error(f"DuckDuckGo Arama HatasÄ± (Iteration {iteration}): {str(search_error)}", exc_info=True)
                # Fallback arama mekanizmasÄ± (aynÄ± kalacak)
                try:
                    def fallback_search(query):
                        headers = {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                        }
                        search_url = f"https://www.google.com/search?q={query}"
                        response = requests.get(search_url, headers=headers)
                        dusunce_logger.info(f"Fallback Arama Sorgusu (Iteration {iteration}): {query}")

                        if response.status_code == 200:
                            # Basic parsing, can be improved
                            soup = BeautifulSoup(response.text, 'html.parser')
                            search_results_fallback = soup.find_all('div', class_='g')

                            parsed_results = []
                            for result in search_results_fallback[:5]: # Increased max_results for fallback as well
                                title = result.find('h3')
                                link = result.find('a')
                                snippet = result.find('div', class_='VwiC3b')

                                if title and link and snippet:
                                    parsed_results.append({
                                        'title': title.text,
                                        'link': link['href'],
                                        'body': snippet.text
                                    })

                            dusunce_logger.info(f"Fallback Arama SonuÃ§ SayÄ±sÄ± (Iteration {iteration}): {len(parsed_results)}")
                            return parsed_results
                        return []
                    results = fallback_search(query)
                    search_results_for_query.extend(results)
                    logging.info(f"Fallback arama sonuÃ§ sayÄ±sÄ± (Iteration {iteration}): {len(search_results_for_query)}")
                except Exception as fallback_error:
                    logging.error(f"Fallback arama hatasÄ± (Iteration {iteration}): {str(fallback_error)}")
                    dusunce_logger.error(f"Fallback Arama HatasÄ± (Iteration {iteration}): {str(fallback_error)}")
                    return [] # BoÅŸ liste dÃ¶ndÃ¼r
            return search_results_for_query

        # EÅŸ zamanlÄ± aramalarÄ± baÅŸlat ve sonuÃ§larÄ± topla! ğŸš€ğŸš€ğŸš€
        search_tasks = [perform_single_search(query) for query in search_queries]
        all_results_nested = await asyncio.gather(*search_tasks) # SonuÃ§larÄ± eÅŸ zamanlÄ± topluyoruz!

        # SonuÃ§larÄ± dÃ¼zleÅŸtir
        search_results = []
        for results_list in all_results_nested:
            search_results.extend(results_list)

        logging.info(f"Toplam bulunan arama sonuÃ§ sayÄ±sÄ± (Iteration {iteration}): {len(search_results)}")
        dusunce_logger.info(f"Toplam Arama SonuÃ§ SayÄ±sÄ± (Iteration {iteration}): {len(search_results)}")

        # Check if search results are empty
        if not search_results:
            return "Arama sonucu bulunamadÄ±. LÃ¼tfen farklÄ± bir ÅŸekilde sormayÄ± deneyin.", [] # Return empty results list

        # Prepare search context (no change needed here for now)
        search_context = "\n\n".join([
            f"Arama Sonucu {i+1}: {result.get('body', 'Ä°Ã§erik yok')}\nKaynak: {result.get('link', 'BaÄŸlantÄ± yok')}"
            for i, result in enumerate(search_results)
        ])
        dusunce_logger.info(f"Arama BaÄŸlamÄ± (Iteration {iteration}):\n{search_context}")

        return search_context, search_results # Return both context and results for deeper processing

    except Exception as e:
        logging.error(f"Web arama genel hatasÄ± (Iteration {iteration}): {str(e)}", exc_info=True)
        dusunce_logger.error(f"Web Arama Genel HatasÄ± (Iteration {iteration}): {str(e)}", exc_info=True)
        return f"Web arama hatasÄ±: {str(e)}", []

# Perform deep search function (dÃ¼ÅŸÃ¼nce loglarÄ± eklendi)
async def perform_deep_search(update: Update, context: ContextTypes.DEFAULT_TYPE, user_message):
    """Performs iterative deep web search and responds to the user."""
    user_id = str(update.effective_user.id)
    user_lang = user_memory.get_user_settings(user_id).get('language', 'tr')

    MAX_ITERATIONS = 3  # Limit iterations to prevent infinite loops (can be adjusted)
    all_search_results = []
    current_query = user_message
    model = genai.GenerativeModel('gemini-2.0-flash-lite')

    try:
        await context.bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)

        for iteration in range(MAX_ITERATIONS):
            search_context, search_results = await intelligent_web_search(current_query, model, user_id, iteration + 1) # user_id eklendi
            if not search_results:
                await update.message.reply_text("Derinlemesine arama yapÄ±ldÄ± ama OwO, anlamlÄ± bir ÅŸey bulamadÄ±m... Belki sorgumu kontrol etmelisin? ğŸ¤” Ya da sonra tekrar deneyebilirsin! ğŸ¥º")
                return

            all_search_results.extend(search_results)

            # --- Enhanced Chain of Thoughts and Query Refinement ---
            analysis_prompt = f"""
            GÃ¶revin: Web arama sonuÃ§larÄ±nÄ± analiz ederek daha derinlemesine arama yapmak iÃ§in yeni ve geliÅŸtirilmiÅŸ arama sorgularÄ± Ã¼retmek.
            Bu gÃ¶revi bir dÃ¼ÅŸÃ¼nce zinciri (chain of thoughts) yaklaÅŸÄ±mÄ±yla, adÄ±m adÄ±m dÃ¼ÅŸÃ¼nerek gerÃ§ekleÅŸtir.

            KullanÄ±cÄ± Sorgusu: "{user_message}"
            Mevcut Arama Sorgusu (Iteration {iteration + 1}): "{current_query}"
            Arama SonuÃ§larÄ± (Iteration {iteration + 1}):
            {search_context}

            DÃ¼ÅŸÃ¼nce Zinciri AdÄ±mlarÄ±:
            1. Arama sonuÃ§larÄ±ndaki anahtar noktalarÄ± ve temalarÄ± belirle.
            2. Bu sonuÃ§lardaki bilgi boÅŸluklarÄ±nÄ± veya eksik detaylarÄ± tespit et.
            3. KullanÄ±cÄ±nÄ±n orijinal sorgusunu ve mevcut sonuÃ§larÄ± dikkate alarak, hangi yÃ¶nlerde daha fazla araÅŸtÄ±rma yapÄ±lmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼n.
            4. Daha spesifik, odaklanmÄ±ÅŸ ve derinlemesine arama yapmayÄ± saÄŸlayacak 3 yeni arama sorgusu oluÅŸtur.
            5. Yeni sorgularÄ±n, Ã¶nceki arama sonuÃ§larÄ±nda bulunan bilgiyi nasÄ±l geniÅŸleteceÄŸini ve derinleÅŸtireceÄŸini aÃ§Ä±kla.

            LÃ¼tfen dÃ¼ÅŸÃ¼nce sÃ¼recini adÄ±m adÄ±m gÃ¶ster ve sonunda net arama sorgularÄ±nÄ± listele:
            5. Sadece yeni arama sorgularÄ±nÄ± (3 tane), her birini yeni bir satÄ±ra yaz. BaÅŸka bir aÃ§Ä±klama veya metin ekleme.
            6. TÃ¼rkÃ§e sorgular oluÅŸtur.
            """
            dusunce_logger.info(f"Sorgu Ä°yileÅŸtirme Promptu (Iteration {iteration + 1}):\n{analysis_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle

            try:
                query_refinement_response = await model.generate_content_async(analysis_prompt)
                dusunce_logger.info(f"Sorgu Ä°yileÅŸtirme CevabÄ± (Gemini, Iteration {iteration + 1}): {query_refinement_response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle

                refined_queries = [q.strip() for q in query_refinement_response.text.split('\n') if q.strip()][:3] # Limit to 3 refined queries
                if refined_queries:
                    current_query = " ".join(refined_queries) # Use refined queries for the next iteration, combining them for broader search in next iteration
                    logging.info(f"Refined queries for iteration {iteration + 2}: {refined_queries}")
                    dusunce_logger.info(f"Ä°yileÅŸtirilmiÅŸ Sorgular (Iteration {iteration + 2}): {refined_queries}") # DÃ¼ÅŸÃ¼nce loguna ekle

                else:
                    logging.info(f"No refined queries generated in iteration {iteration + 1}, stopping deep search.")
                    dusunce_logger.info(f"Ä°yileÅŸtirilmiÅŸ Sorgu OluÅŸturulamadÄ± (Iteration {iteration + 1}), derin arama durduruluyor.") # DÃ¼ÅŸÃ¼nce loguna ekle
                    break # Stop if no refined queries are generated, assuming no more depth to explore
            except Exception as refine_error:
                logging.error(f"Error during query refinement (Iteration {iteration + 1}): {refine_error}")
                dusunce_logger.error(f"Sorgu Ä°yileÅŸtirme HatasÄ± (Iteration {iteration + 1}): {refine_error}") # DÃ¼ÅŸÃ¼nce loguna ekle
                logging.info("Stopping deep search due to query refinement error.")
                dusunce_logger.info("Sorgu iyileÅŸtirme hatasÄ± nedeniyle derin arama durduruluyor.") # DÃ¼ÅŸÃ¼nce loguna ekle
                break # Stop if query refinement fails

        # --- Final Response Generation with Chain of Thoughts ---
        if all_search_results:
            # Summarize all results and create a comprehensive response with chain of thoughts
            final_prompt = f"""
            GÃ¶revin: Derinlemesine web aramasÄ± sonuÃ§larÄ±nÄ± kullanarak kullanÄ±cÄ±ya kapsamlÄ± ve bilgilendirici bir cevap oluÅŸturmak.
            Bu gÃ¶revi bir dÃ¼ÅŸÃ¼nce zinciri (chain of thoughts) yaklaÅŸÄ±mÄ±yla, adÄ±m adÄ±m dÃ¼ÅŸÃ¼nerek gerÃ§ekleÅŸtir.

            KullanÄ±cÄ± Sorgusu: "{user_message}"
            TÃ¼m Arama SonuÃ§larÄ±:
            {''.join([f'Iteration {i+1} Results:\n' + '\\n'.join([f"Arama Sonucu {j+1}: {res.get('body', 'Ä°Ã§erik yok')}\\nKaynak: {res.get('link', 'BaÄŸlantÄ± yok')}" for j, res in enumerate(all_search_results[i*5:(i+1)*5])]) + '\\n\\n' for i in range(MAX_ITERATIONS)])}

            DÃ¼ÅŸÃ¼nce Zinciri AdÄ±mlarÄ±:
            1. TÃ¼m arama sonuÃ§larÄ±nÄ± analiz et ve ana temalarÄ± belirle.
            2. KullanÄ±cÄ±nÄ±n orijinal sorgusunu derinlemesine anlamaya Ã§alÄ±ÅŸ.
            3. Arama sonuÃ§larÄ±ndaki en alakalÄ± ve gÃ¼venilir bilgileri tespit et.
            4. Bu bilgileri nasÄ±l sentezleyeceÄŸini ve organize edeceÄŸini dÃ¼ÅŸÃ¼n.
            5. Ã‡eliÅŸkili bilgiler varsa, bunlarÄ± nasÄ±l deÄŸerlendireceÄŸini ve sunacaÄŸÄ±nÄ± planla.
            6. Eksik bilgiler veya belirsizlikler varsa, bunlarÄ± nasÄ±l ele alacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼n.
            7. TÃ¼m bu dÃ¼ÅŸÃ¼nceleri kullanarak kapsamlÄ± bir yanÄ±t oluÅŸtur.

            LÃ¼tfen dÃ¼ÅŸÃ¼nce sÃ¼recini adÄ±m adÄ±m gÃ¶ster ve sonunda ÅŸu kurallara uygun bir cevap oluÅŸtur:
            - Ã–nemli baÄŸlantÄ±larÄ± ve kaynaklarÄ± cevap iÃ§inde belirt.
            - CevabÄ± {user_lang} dilinde yaz ve samimi bir dil kullan.
            - CevabÄ± madde iÅŸaretleri veya numaralandÄ±rma kullanarak dÃ¼zenli ve okunabilir hale getir.
            - Sadece dÃ¼z metin olarak cevap ver. JSON veya baÅŸka formatlama kullanma.
            """
            dusunce_logger.info(f"Final Chain of Thoughts Promptu:\n{final_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle

            try:
                final_cot_response = await model.generate_content_async(final_prompt)
                dusunce_logger.info(f"Final Chain of Thoughts Cevap (Gemini): {final_cot_response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle

                # Now generate a clean response for the user based on the chain of thoughts
                clean_final_prompt = f"""
                GÃ¶revin: AÅŸaÄŸÄ±daki dÃ¼ÅŸÃ¼nce zincirini (chain of thoughts) kullanarak kullanÄ±cÄ±ya verilecek net ve kapsamlÄ± bir yanÄ±t oluÅŸturmak.
                DÃ¼ÅŸÃ¼nce sÃ¼recini ASLA dahil etme, sadece final cevabÄ± ver.

                KullanÄ±cÄ± Sorgusu: {user_message}

                DÃ¼ÅŸÃ¼nce Zinciri:
                {final_cot_response.text}

                YanÄ±tÄ±nÄ± {user_lang} dilinde ver ve sadece net ve kapsamlÄ± cevabÄ± oluÅŸtur:
                """

                dusunce_logger.info(f"Temiz Final YanÄ±t Promptu:\n{clean_final_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle
                final_response = await model.generate_content_async(clean_final_prompt)
                dusunce_logger.info(f"Final Temiz Cevap (Gemini): {final_response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle

                # **Yeni Kontrol: YanÄ±t EngellenmiÅŸ mi? (Derin Arama)**
                if final_response.prompt_feedback and final_response.prompt_feedback.block_reason:
                    block_reason = final_response.prompt_feedback.block_reason
                    logger.warning(f"Deep search final response blocked. Reason: {block_reason}")
                    dusunce_logger.warning(f"Derin arama final cevabÄ± engellendi. Sebep: {block_reason}") # DÃ¼ÅŸÃ¼nce loguna ekle
                    error_message = get_error_message('blocked_prompt', user_lang)
                    await update.message.reply_text(error_message)
                else:
                    response_text = final_response.text if hasattr(final_response, 'text') else final_response.candidates[0].content.parts[0].text
                    response_text = add_emojis_to_text(response_text)
                    await split_and_send_message(update, response_text)

                    # Save interaction to memory (important to record deep search context if needed later)
                    user_memory.add_message(user_id, "user", f"/derinarama {user_message}")
                    user_memory.add_message(user_id, "assistant", response_text)


            except Exception as final_response_error:
                logging.error(f"Error generating final response for deep search: {final_response_error}")
                dusunce_logger.error(f"Final Cevap OluÅŸturma HatasÄ± (Derin Arama): {final_response_error}") # DÃ¼ÅŸÃ¼nce loguna ekle
                await update.message.reply_text(get_error_message('ai_error', user_lang))
        else:
            await update.message.reply_text("Derinlemesine arama yapÄ±ldÄ± ama OwO, anlamlÄ± bir ÅŸey bulamadÄ±m... Belki sorgumu kontrol etmelisin? ğŸ¤” Ya da sonra tekrar deneyebilirsin! ğŸ¥º") # User friendly no result message

    except Exception as deep_search_error:
        logging.error(f"Error during deep search process: {deep_search_error}", exc_info=True)
        dusunce_logger.error(f"Derin Arama SÃ¼reci HatasÄ±: {deep_search_error}", exc_info=True) # DÃ¼ÅŸÃ¼nce loguna ekle
        await update.message.reply_text(get_error_message('general', user_lang))
    finally:
        await context.bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING) # Typing action at end

# Handle message function (dÃ¼ÅŸÃ¼nce loglarÄ± eklendi)
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("Entering handle_message function")
    dusunce_logger.info("Mesaj iÅŸleme fonksiyonuna girildi.") # DÃ¼ÅŸÃ¼nce loguna ekle

    try:
        if not update or not update.message:
            logger.error("Invalid update object or message")
            dusunce_logger.error("GeÃ§ersiz update veya mesaj objesi.") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        logger.info(f"Message received: {update.message}")
        logger.info(f"Message text: {update.message.text}")
        dusunce_logger.info(f"Mesaj alÄ±ndÄ±: {update.message}") # DÃ¼ÅŸÃ¼nce loguna ekle
        dusunce_logger.info(f"Mesaj metni: {update.message.text}") # DÃ¼ÅŸÃ¼nce loguna ekle

        user_id = str(update.effective_user.id)
        logger.info(f"User ID: {user_id}")
        dusunce_logger.info(f"KullanÄ±cÄ± ID: {user_id}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # KullanÄ±cÄ±nÄ±n dilini otomatik olarak tespit et ve ayarla
        if update.message.text and not update.message.text.startswith('/'): # KomutlarÄ± dil tespitinden muaf tut
            message_text = update.message.text.strip()
            user_lang = await detect_and_set_user_language(message_text, user_id)
            logger.info(f"Detected language: {user_lang}")
            dusunce_logger.info(f"Tespit edilen dil: {user_lang}") # DÃ¼ÅŸÃ¼nce loguna ekle
        else:
            user_lang = user_memory.get_user_settings(user_id).get('language', 'tr') # Komutlar iÃ§in mevcut dili kullan


        # Process commands
        if update.message.text and update.message.text.startswith('/derinarama'):
            query = update.message.text[len('/derinarama'):].strip()
            if not query:
                await update.message.reply_text("Derin arama iÃ§in bir sorgu girmelisin! ğŸ¥º Ã–rnek: `/derinarama TÃ¼rkiye'deki antik kentler`")
                return
            await perform_deep_search(update, context, query) # Call deep search function
            return # Stop further processing in handle_message

        # Process regular text messages
        if update.message.text and not update.message.text.startswith('/'): # KomutlarÄ± normal mesaj iÅŸlemden Ã§Ä±kar
            message_text = update.message.text.strip()
            logger.info(f"Processed message text: {message_text}")
            dusunce_logger.info(f"Ä°ÅŸlenen mesaj metni: {message_text}") # DÃ¼ÅŸÃ¼nce loguna ekle

            # Show typing indicator while processing


            # Start typing indicator in background with optimized refresh rate
            async def show_typing():
                while True:
                    try:
                        await context.bot.send_chat_action(
                            chat_id=update.message.chat_id,
                            action=ChatAction.TYPING
                        )
                        await asyncio.sleep(2)  # Reduced from 4 to 2 seconds for more responsive typing indicator
                    except Exception as e:
                        logger.error(f"Error in typing indicator: {e}")
                        dusunce_logger.error(f"YazÄ±yor gÃ¶stergesi hatasÄ±: {e}") # DÃ¼ÅŸÃ¼nce loguna ekle
                        break

            # Start typing indicator in background
            typing_task = asyncio.create_task(show_typing())

            try:
                # Get conversation history with token management
                MAX_RETRIES = 100
                retry_count = 0
                context_messages = []

                while retry_count < MAX_RETRIES:
                    try:
                        context_messages = user_memory.get_relevant_context(user_id)

                        # Get personality context
                        personality_context = get_time_aware_personality(
                            datetime.now(),
                            user_lang,
                            user_memory.get_user_settings(user_id).get('timezone', 'Europe/Istanbul')
                        )

                        # Construct AI prompt with chain of thoughts processing
                        ai_prompt = f"""{personality_context}

                        GÃ¶revin: KullanÄ±cÄ±nÄ±n mesajÄ±na cevap vermek, ama Ã¶nce bir dÃ¼ÅŸÃ¼nce zinciri (chain of thoughts) oluÅŸturarak adÄ±m adÄ±m dÃ¼ÅŸÃ¼nmek! ğŸ¤”ğŸ’­

                        Ã–nceki KonuÅŸma BaÄŸlamÄ±:
                        {context_messages}

                        KullanÄ±cÄ± MesajÄ±: {message_text}

                        LÃ¼tfen aÅŸaÄŸÄ±daki adÄ±mlarÄ± izle UwU:
                        1. KullanÄ±cÄ±nÄ±n ne sorduÄŸunu veya ne istediÄŸini ANALÄ°Z ET! ğŸ§
                        2. Konuyla ilgili BÄ°LGÄ°LERÄ°NÄ° GÃ–ZDEN GEÃ‡Ä°R! ğŸ§ 
                        3. OlasÄ± CEVAP YOLLARINI DÃœÅÃœN! ğŸ¤”
                        4. En doÄŸru ve yararlÄ± CEVABI SEÃ‡! ğŸ‘
                        5. CevabÄ±nÄ± NET ve ANLAÅILIR bir ÅŸekilde oluÅŸtur! ğŸ“âœ¨

                        DÃ¼ÅŸÃ¼nce Zinciri (Chain of Thoughts):
                        """
                        dusunce_logger.info(f"AI Prompt (Chain of Thoughts):\n{ai_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle


                        # Web search integration (for normal messages as well, could be conditional if needed)
                        try:
                            model = genai.GenerativeModel('gemini-2.0-flash-lite')
                            web_search_response, _ = await intelligent_web_search(message_text, model, user_id) # Get context, ignore results list for normal messages, user_id eklendi

                            if web_search_response and len(web_search_response.strip()) > 10:
                                ai_prompt += f"\n\nEk Bilgi (Web Arama SonuÃ§larÄ± - SADECE DÄ°REKT SONUÃ‡LARI KULLAN):\n{web_search_response}"
                                dusunce_logger.info(f"AI Prompt (Web AramalÄ±):\n{ai_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle

                            # Generate AI response with chain of thoughts and optimized settings
                            dusunce_logger.info("Gemini'den chain of thoughts cevabÄ± bekleniyor... ğŸ’«") # DÃ¼ÅŸÃ¼nce loguna ekle
                            response = await model.generate_content_async(
                                ai_prompt,
                                generation_config={
                                    "temperature": 0.7,  # Slightly lower temperature for faster, more focused responses
                                    "top_p": 0.8,      # Adjusted for better balance of creativity and speed
                                    "top_k": 40        # Optimized for faster generation
                                }
                            )
                            dusunce_logger.info(f"Gemini Chain of Thoughts CevabÄ±: {response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle

                            # **Yeni Kontrol: YanÄ±t EngellenmiÅŸ mi? (Normal Mesaj)**
                            if response.prompt_feedback and response.prompt_feedback.block_reason:
                                block_reason = response.prompt_feedback.block_reason
                                logger.warning(f"Prompt blocked for regular message. Reason: {block_reason}")
                                dusunce_logger.warning(f"Normal mesaj iÃ§in prompt engellendi. Sebep: {block_reason}") # DÃ¼ÅŸÃ¼nce loguna ekle
                                error_message = get_error_message('blocked_prompt', user_lang)
                                await update.message.reply_text(error_message)
                                break # Retry dÃ¶ngÃ¼sÃ¼nden Ã§Ä±k
                            else: # YanÄ±t engellenmemiÅŸse normal iÅŸleme devam et
                                full_response = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text

                                # Log the full chain of thoughts response
                                dusunce_logger.info(f"Tam Chain of Thoughts yanÄ±tÄ±: {full_response}") # DÃ¼ÅŸÃ¼nce loguna ekle

                                # Now generate a clean response for the user based on the chain of thoughts
                                clean_response_prompt = f"""${personality_context}

                                GÃ¶revin: AÅŸaÄŸÄ±daki dÃ¼ÅŸÃ¼nce zincirini (chain of thoughts) kullanarak kullanÄ±cÄ±ya verilecek NET ve SADE bir yanÄ±t oluÅŸturmak! Ama dÃ¼ÅŸÃ¼nce sÃ¼recini SAKIN dahil etme! ğŸ™…â€â™€ï¸ Sadece final cevabÄ± ver! ğŸ˜‰

                                DÃ¼ÅŸÃ¼nce Zinciri:
                                {full_response}

                                KullanÄ±cÄ± MesajÄ±: {message_text}

                                Sadece net ve sade cevabÄ± ver:"""

                                dusunce_logger.info(f"Temiz yanÄ±t promptu: {clean_response_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle
                                clean_response = await model.generate_content_async(clean_response_prompt)
                                response_text = clean_response.text if hasattr(clean_response, 'text') else clean_response.candidates[0].content.parts[0].text
                                dusunce_logger.info(f"Temiz yanÄ±t: {response_text}") # DÃ¼ÅŸÃ¼nce loguna ekle

                                # Add emojis and send response
                                response_text = add_emojis_to_text(response_text)
                                await split_and_send_message(update, response_text.strip()) # .strip() ekleyerek baÅŸtaki ve sondaki boÅŸluklarÄ± temizliyoruz

                                # Save successful interaction to memory
                                user_memory.add_message(user_id, "user", message_text)
                                user_memory.add_message(user_id, "assistant", response_text)
                                break  # Exit retry loop on success

                        except Exception as search_error:
                            if "Token limit exceeded" in str(search_error):
                                # Remove oldest messages and retry
                                user_memory.trim_context(user_id)
                                retry_count += 1
                                logger.warning(f"Token limit exceeded, retrying {retry_count}/{MAX_RETRIES}")
                                dusunce_logger.warning(f"Token limiti aÅŸÄ±ldÄ±, tekrar deneniyor {retry_count}/{MAX_RETRIES}") # DÃ¼ÅŸÃ¼nce loguna ekle


                                # Send periodic update about retrying
                                if retry_count % 10 == 0:
                                    await update.message.reply_text(f"ğŸ”„ Ay ay ay! Token sÄ±nÄ±rÄ± aÅŸÄ±ldÄ±! Biraz mesaj geÃ§miÅŸini temizliyorum... ({retry_count}. deneme) ğŸ¥º")

                                if retry_count == MAX_RETRIES:
                                    error_message = get_error_message('token_limit', user_lang)
                                    await update.message.reply_text(error_message)
                            else:
                                raise search_error

                    except Exception as context_error:
                        logger.error(f"Context retrieval error: {context_error}")
                        dusunce_logger.error(f"Kontekst alma hatasÄ±: {context_error}") # DÃ¼ÅŸÃ¼nce loguna ekle
                        retry_count += 1
                        if retry_count == MAX_RETRIES:
                            error_message = get_error_message('general', user_lang)
                            await update.message.reply_text(error_message)
                            break

                if retry_count == MAX_RETRIES:
                    logger.error("Max retries reached for token management")
                    dusunce_logger.error("Token yÃ¶netimi iÃ§in maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±.") # DÃ¼ÅŸÃ¼nce loguna ekle
                    error_message = get_error_message('max_retries', user_lang)
                    await update.message.reply_text(error_message)

            except Exception as e:
                logger.error(f"Message processing error: {e}")
                dusunce_logger.error(f"Mesaj iÅŸleme hatasÄ±: {e}") # DÃ¼ÅŸÃ¼nce loguna ekle
                error_message = get_error_message('general', user_lang)
                await update.message.reply_text(error_message)

            finally:
                # Stop typing indicator
                typing_task.cancel()

        # Handle media messages (aynÄ± kalÄ±r, dÃ¼ÅŸÃ¼nce loglarÄ± eklendi)
        elif update.message.photo:
            await handle_image(update, context)
        elif update.message.video:
            await handle_video(update, context)
        else:
            logger.warning("Unhandled message type received")
            dusunce_logger.warning("Ä°ÅŸlenemeyen mesaj tÃ¼rÃ¼ alÄ±ndÄ±.") # DÃ¼ÅŸÃ¼nce loguna ekle
            user_lang = user_memory.get_user_settings(user_id).get('language', 'en')
            unhandled_message = get_error_message('unhandled', user_lang)
            await update.message.reply_text(unhandled_message)

    except Exception as e:
        logger.error(f"General error: {e}")
        dusunce_logger.error(f"Genel hata: {e}") # DÃ¼ÅŸÃ¼nce loguna ekle
        user_lang = user_memory.get_user_settings(user_id).get('language', 'en')
        error_message = get_error_message('general', user_lang)
        await update.message.reply_text(error_message)
    except SyntaxError as e:
        logger.error(f"Syntax error: {e}")
        dusunce_logger.error(f"SÃ¶zdizimi hatasÄ±: {e}") # DÃ¼ÅŸÃ¼nce loguna ekle
        user_lang = user_memory.get_user_settings(user_id).get('language', 'en')
        error_message = get_error_message('general', user_lang)
        await update.message.reply_text(error_message)

# Image and Video handlers (dÃ¼ÅŸÃ¼nce loglarÄ± eklendi)
async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # ... (same as before)
    user_id = str(update.effective_user.id)

    try:
        # Enhanced logging for debugging
        logger.info(f"Starting image processing for user {user_id}")
        dusunce_logger.info(f"Resim iÅŸleme baÅŸlatÄ±lÄ±yor. KullanÄ±cÄ± ID: {user_id}") # DÃ¼ÅŸÃ¼nce loguna ekle


        # Validate message and photo
        if not update.message:
            logger.warning("No message found in update")
            await update.message.reply_text("A-aa! Mesaj kayÄ±p! ğŸ¥º LÃ¼tfen tekrar dener misin?")
            dusunce_logger.warning("Update iÃ§inde mesaj bulunamadÄ±.") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        # Get user's current language settings from memory
        user_settings = user_memory.get_user_settings(user_id)
        user_lang = user_settings.get('language', 'tr')  # Default to Turkish if not set
        logger.info(f"User language: {user_lang}")
        dusunce_logger.info(f"KullanÄ±cÄ± dili: {user_lang}") # DÃ¼ÅŸÃ¼nce loguna ekle


        # Check if photo exists
        if not update.message.photo:
            logger.warning("No photo found in the message")
            await update.message.reply_text("Resim de kayÄ±p! ğŸ˜­ Tekrar gÃ¶nderebilir misin lÃ¼tfen?")
            dusunce_logger.warning("Mesajda fotoÄŸraf bulunamadÄ±.") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        # Get the largest available photo
        try:
            photo = max(update.message.photo, key=lambda x: x.file_size)
        except Exception as photo_error:
            logger.error(f"Error selecting photo: {photo_error}")
            await update.message.reply_text("Resmi seÃ§erken bir sorun oldu! ğŸ¤¯ Belki tekrar denemelisin?")
            dusunce_logger.error(f"FotoÄŸraf seÃ§imi hatasÄ±: {photo_error}") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        # Download photo
        try:
            photo_file = await context.bot.get_file(photo.file_id)
            photo_bytes = bytes(await photo_file.download_as_bytearray())
        except Exception as download_error:
            logger.error(f"Photo download error: {download_error}")
            await update.message.reply_text("Resmi indiremedim! ğŸ¥º Ä°nternet baÄŸlantÄ±nÄ± kontrol eder misin?")
            dusunce_logger.error(f"FotoÄŸraf indirme hatasÄ±: {download_error}") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        logger.info(f"Photo bytes downloaded: {len(photo_bytes)} bytes")
        dusunce_logger.info(f"FotoÄŸraf indirildi. Boyut: {len(photo_bytes)} bytes") # DÃ¼ÅŸÃ¼nce loguna ekle


        # Comprehensive caption handling with extensive logging
        caption = update.message.caption
        logger.info(f"Original caption: {caption}")
        dusunce_logger.info(f"Orijinal baÅŸlÄ±k: {caption}") # DÃ¼ÅŸÃ¼nce loguna ekle


        default_prompt = get_analysis_prompt('image', None, user_lang)
        logger.info(f"Default prompt: {default_prompt}")
        dusunce_logger.info(f"VarsayÄ±lan prompt: {default_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle


        # Ensure caption is not None
        if caption is None:
            caption = default_prompt or "Bu resmi detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla."

        # Ensure caption is a string and stripped
        caption = str(caption).strip()
        logger.info(f"Final processed caption: {caption}")
        dusunce_logger.info(f"Son iÅŸlenmiÅŸ baÅŸlÄ±k: {caption}") # DÃ¼ÅŸÃ¼nce loguna ekle


        # Create a context-aware prompt that includes language preference
        personality_context = get_time_aware_personality(
            datetime.now(),
            user_lang,
            user_settings.get('timezone', 'Europe/Istanbul')
        )

        if not personality_context:
            personality_context = "Sen Nyxie'sin ve resimleri analiz ediyorsun."  # Fallback personality

        # Force Turkish analysis for all users (Prompt dÃ¼zenlendi, daha gÃ¼venli hale getirildi)
        analysis_prompt = f"""DÄ°KKAT: BU ANALÄ°ZÄ° TÃœRKÃ‡E YAPACAKSIN! SADECE TÃœRKÃ‡E KULLAN! KESÄ°NLÄ°KLE BAÅKA DÄ°L KULLANMA!

{personality_context}

GÃ¶revin: KullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi gÃ¶rseli analiz ederek sadece dÃ¼z metin bir aÃ§Ä±klama sunmak.
Rol: Sen Nyxie'sin ve bu gÃ¶rseli TÃ¼rkÃ§e olarak aÃ§Ä±klÄ±yorsun.

YÃ¶nergeler:
1. SADECE TÃœRKÃ‡E KULLAN! ğŸ‡¹ğŸ‡·ğŸ’¯
2. GÃ¶rseldeki metinleri (varsa) orijinal dilinde bÄ±rak, Ã§evirme! ğŸš«âœï¸
3. Analizini yaparken NAZÄ°K ve YARDIMSEVER bir ton kullan! ğŸ¥°ğŸ’–
4. KÃ¼ltÃ¼rel DUYARLILIÄA dikkat et! ğŸŒğŸ•Šï¸
            5. Sadece dÃ¼z metin cevap ver. JSON veya baÅŸka format kullanma. ğŸš«ğŸ“¦


LÃ¼tfen analiz et ve sadece dÃ¼z metin olarak Ã¶zetle:
- GÃ¶rseldeki ANA Ã–ÄELERÄ° ve KONULARI tanÄ±mla! ğŸ”ğŸ‘€
- Aktiviteler veya OLAYLAR varsa, bunlarÄ± aÃ§Ä±kla! ğŸï¸ğŸ‰
- GÃ¶rselin GENEL ATMOSFERÄ°NÄ° ve olasÄ± DUYGUSAL ETKÄ°SÄ°NÄ° deÄŸerlendir! ğŸ˜ŒğŸ¤”
- GÃ¶rselde METÄ°N varsa, bunlarÄ± belirt (Ã§evirme yapma)! ğŸ“ğŸ“¢

KullanÄ±cÄ±nÄ±n isteÄŸi (varsa): {caption}"""
        dusunce_logger.info(f"Resim Analiz Promptu:\n{analysis_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle


        try:
            # Prepare the message with both text and image
            model = genai.GenerativeModel('gemini-2.0-flash-lite')
            dusunce_logger.info("Gemini'ye resim analizi isteÄŸi gÃ¶nderiliyor... ğŸš€ğŸŒŒ") # DÃ¼ÅŸÃ¼nce loguna ekle
            response = await model.generate_content_async([
                analysis_prompt,
                {"mime_type": "image/jpeg", "data": photo_bytes}
            ])
            dusunce_logger.info(f"Resim Analizi CevabÄ± (Gemini): {response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle


            # **Yeni Kontrol: YanÄ±t EngellenmiÅŸ mi? (Resim)**
            if response.prompt_feedback and response.prompt_feedback.block_reason:
                block_reason = response.prompt_feedback.block_reason
                logger.warning(f"Prompt blocked for image analysis. Reason: {block_reason}")
                dusunce_logger.warning(f"Resim analizi iÃ§in prompt engellendi. Sebep: {block_reason}") # DÃ¼ÅŸÃ¼nce loguna ekle
                error_message = get_error_message('blocked_prompt', user_lang)
                await update.message.reply_text(error_message)
            else:
                response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text

                # Add culturally appropriate emojis
                response_text = add_emojis_to_text(response_text)

                # Save the interaction
                user_memory.add_message(user_id, "user", f"[Image] {caption}")
                user_memory.add_message(user_id, "assistant", response_text)

                # Uzun mesajlarÄ± bÃ¶l ve gÃ¶nder
                await split_and_send_message(update, response_text.strip()) # .strip() ekleyerek baÅŸtaki ve sondaki boÅŸluklarÄ± temizliyoruz

        except Exception as processing_error:
            logger.error(f"GÃ¶rsel iÅŸleme hatasÄ±: {processing_error}", exc_info=True)
            dusunce_logger.error(f"GÃ¶rsel iÅŸleme hatasÄ±: {processing_error}", exc_info=True) # DÃ¼ÅŸÃ¼nce loguna ekle
            error_message = get_error_message('ai_error', user_lang)
            await update.message.reply_text(error_message)

    except Exception as critical_error:
        logger.error(f"Kritik gÃ¶rsel iÅŸleme hatasÄ±: {critical_error}", exc_info=True)
        dusunce_logger.error(f"Kritik gÃ¶rsel iÅŸleme hatasÄ±: {critical_error}", exc_info=True) # DÃ¼ÅŸÃ¼nce loguna ekle
        await update.message.reply_text(get_error_message('general', user_lang))

async def handle_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # ... (aynÄ± yapÄ±, sadece log mesajlarÄ± eklendi, prompt aynÄ± kalÄ±r)
    user_id = str(update.effective_user.id)

    try:
        # Enhanced logging for debugging
        logger.info(f"Starting video processing for user {user_id}")
        dusunce_logger.info(f"Video iÅŸleme baÅŸlatÄ±lÄ±yor. KullanÄ±cÄ± ID: {user_id}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Validate message and video
        if not update.message:
            logger.warning("No message found in update")
            await update.message.reply_text("A-aa! Mesaj kayÄ±p! ğŸ¥º LÃ¼tfen tekrar dener misin?")
            dusunce_logger.warning("Update iÃ§inde mesaj bulunamadÄ±.") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        # Get user's current language settings from memory
        user_settings = user_memory.get_user_settings(user_id)
        user_lang = user_settings.get('language', 'tr')  # Default to Turkish if not set
        logger.info(f"User language: {user_lang}")
        dusunce_logger.info(f"KullanÄ±cÄ± dili: {user_lang}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Check if video exists
        if not update.message.video:
            logger.warning("No video found in the message")
            await update.message.reply_text("Video da kayÄ±p! ğŸ˜­ Tekrar gÃ¶nderebilir misin lÃ¼tfen?")
            dusunce_logger.warning("Mesajda video bulunamadÄ±.") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        # Get the video file
        video = update.message.video
        if not video:
            logger.warning("No video found in the message")
            await update.message.reply_text("Video da kayÄ±p! ğŸ˜­ Tekrar gÃ¶nderebilir misin lÃ¼tfen?")
            dusunce_logger.warning("Mesajda video objesi bulunamadÄ±.") # DÃ¼ÅŸÃ¼nce loguna ekle
            return

        video_file = await context.bot.get_file(video.file_id)
        video_bytes = bytes(await video_file.download_as_bytearray())
        logger.info(f"Video bytes downloaded: {len(video_bytes)} bytes")
        dusunce_logger.info(f"Video indirildi. Boyut: {len(video_bytes)} bytes") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Comprehensive caption handling with extensive logging
        caption = update.message.caption
        logger.info(f"Original caption: {caption}")
        dusunce_logger.info(f"Orijinal baÅŸlÄ±k: {caption}") # DÃ¼ÅŸÃ¼nce loguna ekle

        default_prompt = get_analysis_prompt('video', None, user_lang)
        logger.info(f"Default prompt: {default_prompt}")
        dusunce_logger.info(f"VarsayÄ±lan prompt: {default_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Ensure caption is not None
        if caption is None:
            caption = default_prompt or "Bu videoyu detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla."

        # Ensure caption is a string and stripped
        caption = str(caption).strip()
        logger.info(f"Final processed caption: {caption}")
        dusunce_logger.info(f"Son iÅŸlenmiÅŸ baÅŸlÄ±k: {caption}") # DÃ¼ÅŸÃ¼nce loguna ekle

        # Create a context-aware prompt that includes language preference
        personality_context = get_time_aware_personality(
            datetime.now(),
            user_lang,
            user_settings.get('timezone', 'Europe/Istanbul')
        )

        if not personality_context:
            personality_context = "Sen Nyxie'sin ve videolarÄ± analiz ediyorsun."  # Fallback personality

        # Force Turkish analysis for all users (Prompt dÃ¼zenlendi, daha gÃ¼venli hale getirildi)
        analysis_prompt = f"""DÄ°KKAT: BU ANALÄ°ZÄ° TÃœRKÃ‡E YAPACAKSIN! SADECE TÃœRKÃ‡E KULLAN! KESÄ°NLÄ°KLE BAÅKA DÄ°L KULLANMA!

{personality_context}

GÃ¶revin: KullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi videoyu analiz ederek sadece dÃ¼z metin bir aÃ§Ä±klama sunmak.
Rol: Sen Nyxie'sin ve bu videoyu TÃ¼rkÃ§e olarak aÃ§Ä±klÄ±yorsun.

YÃ¶nergeler:
1. SADECE TÃœRKÃ‡E KULLAN! ğŸ‡¹ğŸ‡·ğŸ’¯
2. Videodaki konuÅŸma veya metinleri (varsa) orijinal dilinde bÄ±rak, Ã§evirme! ğŸš«âœï¸
3. Analizini yaparken NAZÄ°K ve YARDIMSEVER bir ton kullan! ğŸ¥°ğŸ’–
4. KÃ¼ltÃ¼rel DUYARLILIÄA dikkat et! ğŸŒğŸ•Šï¸
            5. Sadece dÃ¼z metin cevap ver. JSON veya baÅŸka format kullanma. ğŸš«ğŸ“¦


LÃ¼tfen analiz et ve sadece dÃ¼z metin olarak Ã¶zetle:
- Videodaki ANA OLAYLARI ve EYLEMLERÄ° tanÄ±mla! ğŸ”ğŸ¬
- Ã–nemli Ä°NSANLAR veya NESNELER varsa, bunlarÄ± belirt! ğŸ§‘â€ğŸ¤â€ğŸ§‘ğŸ“¦
- Videodaki SESLERÄ° ve KONUÅMALARI (varsa) analiz et! ğŸ§ğŸ—£ï¸
- Videonun GENEL ATMOSFERÄ°NÄ° ve olasÄ± DUYGUSAL ETKÄ°SÄ°NÄ° deÄŸerlendir! ğŸ˜ŒğŸ¤”
- Videoda METÄ°N varsa, bunlarÄ± belirt (Ã§evirme yapma)! ğŸ“ğŸ“¢

KullanÄ±cÄ±nÄ±n isteÄŸi (varsa): {caption}"""
        dusunce_logger.info(f"Video Analiz Promptu:\n{analysis_prompt}") # DÃ¼ÅŸÃ¼nce loguna ekle

        try:
            # Prepare the message with both text and video
            model = genai.GenerativeModel('gemini-2.0-flash-lite')
            dusunce_logger.info("Gemini'ye video analizi isteÄŸi gÃ¶nderiliyor... ğŸš€ğŸŒŒ") # DÃ¼ÅŸÃ¼nce loguna ekle
            response = await model.generate_content_async([
                analysis_prompt,
                {"mime_type": "video/mp4", "data": video_bytes}
            ])
            dusunce_logger.info(f"Video Analizi CevabÄ± (Gemini): {response.text}") # DÃ¼ÅŸÃ¼nce loguna ekle


            # **Yeni Kontrol: YanÄ±t EngellenmiÅŸ mi? (Video)**
            if response.prompt_feedback and response.prompt_feedback.block_reason:
                block_reason = response.prompt_feedback.block_reason
                logger.warning(f"Prompt blocked for video analysis. Reason: {block_reason}")
                dusunce_logger.warning(f"Video analizi iÃ§in prompt engellendi. Sebep: {block_reason}") # DÃ¼ÅŸÃ¼nce loguna ekle
                error_message = get_error_message('blocked_prompt', user_lang)
                await update.message.reply_text(error_message)
            else:
                response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text

                # Add culturally appropriate emojis
                response_text = add_emojis_to_text(response_text)

                # Save the interaction
                user_memory.add_message(user_id, "user", f"[Video] {caption}")
                user_memory.add_message(user_id, "assistant", response_text)

                # Uzun mesajlarÄ± bÃ¶l ve gÃ¶nder
                await split_and_send_message(update, response_text.strip()) # .strip() ekleyerek baÅŸtaki ve sondaki boÅŸluklarÄ± temizliyoruz

        except Exception as processing_error:
            logger.error(f"Video processing error: {processing_error}", exc_info=True)
            dusunce_logger.error(f"Video iÅŸleme hatasÄ±: {processing_error}", exc_info=True) # DÃ¼ÅŸÃ¼nce loguna ekle
            error_message = get_error_message('ai_error', user_lang)
            await update.message.reply_text(error_message)


    except Exception as e:
        logger.error(f"Kritik video iÅŸleme hatasÄ±: {e}", exc_info=True)
        dusunce_logger.error(f"Kritik video iÅŸleme hatasÄ±: {e}", exc_info=True) # DÃ¼ÅŸÃ¼nce loguna ekle
        await update.message.reply_text(get_error_message('general', user_lang))

# Token and memory error handlers (aynÄ± kalÄ±r)
async def handle_token_limit_error(update: Update):
    error_message = "Ay ay ay! Mesaj geÃ§miÅŸi Ã§ok uzun! ğŸ¥º Åu an cevap veremiyorum ama biraz bekleyip tekrar dener misin? ğŸ™"
    await update.message.reply_text(error_message)

async def handle_memory_error(update: Update):
    error_message = "HafÄ±zam doldu sandÄ±m bir an! ğŸ¤¯ Bellek sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ± galiba... Biraz bekleyip tekrar dener misin? ğŸ™"
    await update.message.reply_text(error_message)

# Emoji adding function (dÃ¼ÅŸÃ¼nce loglarÄ± eklendi)
def add_emojis_to_text(text):
    # ... (same as before)
    try:
        # Use Gemini to suggest relevant emojis - now for a furry fox protogen!
        emoji_model = genai.GenerativeModel('gemini-2.0-flash-lite')

        # Prompt Gemini to suggest emojis based on text context AND personality!
        emoji_prompt = f"""
        Sen ultra complex bir Protogen furry fox'sun, Nyxie.  AÅŸaÄŸÄ±daki metni analiz et ve kiÅŸiliÄŸine UYGUN, en alakalÄ± ve abartÄ±lÄ± OLMAYAN emoji(leri) Ã¶ner.  Ã‡OK FAZLA EMOJÄ° KULLANMA, ama duyguyu ifade etmede Ã§ekinme!

        Metin: "{text}"

        Kurallar:
        - 0-3 arasÄ± emoji Ã¶ner.  Duyguyu veya ana temayÄ± iyi yakalayanlarÄ± seÃ§.
        - Emojiler metnin tonuna ve Nyxie'nin kiÅŸiliÄŸine uygun olsun.  Enerjik, oyuncu, sevecen, teknoloji meraklÄ±sÄ± bir furry fox protogen gibi dÃ¼ÅŸÃ¼n.
        - EÄŸer uygun emoji yoksa, boÅŸ dize dÃ¶ndÃ¼r.
        - SADECE emoji(leri) veya boÅŸ dize ile yanÄ±t ver. BaÅŸka metin veya aÃ§Ä±klama YOK.

        YanÄ±t formatÄ±: Sadece emoji(ler) veya boÅŸ dize (aralarÄ±nda boÅŸluk olabilir)
        """
        dusunce_logger.info(f"GeliÅŸmiÅŸ Emoji Promptu:\n{emoji_prompt}")

        emoji_response = emoji_model.generate_content(emoji_prompt)
        dusunce_logger.info(f"GeliÅŸmiÅŸ Emoji CevabÄ± (Gemini): {emoji_response.text}")

        if emoji_response.prompt_feedback and emoji_response.prompt_feedback.block_reason:
            logger.warning("Emoji suggestion blocked.")
            dusunce_logger.warning("Emoji Ã¶nerisi engellendi.")
            return text
        else:
            suggested_emojis_str = emoji_response.text.strip()

            # EÄŸer emoji Ã¶nerilmediyse, orijinal metni dÃ¶ndÃ¼r
            if not suggested_emojis_str:
                return text

            suggested_emojis = suggested_emojis_str.split() # Birden fazla emoji Ã¶nerisi iÃ§in

            # Emojileri cÃ¼mlenin sonuna ekle
            return f"{text} {' '.join(suggested_emojis)}" # Emojileri aralarÄ±na boÅŸluk koyarak birleÅŸtir
    except Exception as e:
        logger.error(f"Error adding context-relevant emojis: {e}")
        dusunce_logger.error(f"Emoji ekleme hatasÄ±: {e}")
        return text  # Return original text if emoji addition fails

# Analysis prompt function (aynÄ± kalÄ±r)
def get_analysis_prompt(media_type, caption, lang):
    # ... (aynÄ± kalÄ±r)
    prompts = {
        'image': {
            'tr': "Bu resmi detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Resimdeki her ÅŸeyi dikkatle incele.",
            'en': "Analyze this image in detail and explain what you see. Carefully examine every aspect of the image.",
            'es': "Analiza esta imagen en detalle y explica lo que ves. Examina cuidadosamente cada aspecto de la imagen.",
            'fr': "Analysez cette image en dÃ©tail et expliquez ce que vous voyez. Examinez attentivement chaque aspect de l'image.",
            'de': "Analysieren Sie dieses Bild detailliert und erklÃ¤ren Sie, was Sie sehen. Untersuchen Sie jeden Aspekt des Bildes sorgfÃ¤ltig.",
            'it': "Analizza questa immagine in dettaglio e spiega cosa vedi. Esamina attentamente ogni aspetto dell'immagine.",
            'pt': "Analise esta imagem em detalhes e explique o que vÃª. Examine cuidadosamente cada aspecto da imagem.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°ÑĞ¿ĞµĞºÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.",
            'ja': "ã“ã®ç”»åƒã‚’è©³ç´°ã«åˆ†æã—ã€è¦‹ãŸã‚‚ã®ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ç”»åƒã®ã‚ã‚‰ã‚†ã‚‹å´é¢ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ë³´ì´ëŠ” ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ì´ë¯¸ì§€ì˜ ëª¨ë“  ì¸¡ë©´ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡å¹¶è§£é‡Šä½ æ‰€çœ‹åˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥å›¾ç‰‡çš„æ¯ä¸ªç»†èŠ‚ã€‚"
        },
        'video': {
            'tr': "Bu videoyu detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Videodaki her sahneyi ve detayÄ± dikkatle incele.",
            'en': "Analyze this video in detail and explain what you observe. Carefully examine every scene and detail in the video.",
            'es': "Analiza este video en detalle y explica lo que observas. Examina cuidadosamente cada escena y detalle del video.",
            'fr': "Analysez cette vidÃ©o en dÃ©tail et expliquez ce que vous observez. Examinez attentivement chaque scÃ¨ne et dÃ©tail de la vidÃ©o.",
            'de': "Analysieren Sie dieses Video detailliert und erklÃ¤ren Sie, was Sie beobachten. Untersuchen Sie jede Szene und jeden Aspekt des Videos sorgfÃ¤ltig.",
            'it': "Analizza questo video in dettaglio e spiega cosa osservi. Esamina attentamente ogni scena e dettaglio del video.",
            'pt': "Analise este vÃ­deo em detalhes e explique o que observa. Examine cuidadosamente cada cena e detalhe do vÃ­deo.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµÑ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´ÑƒÑ ÑÑ†ĞµĞ½Ñƒ Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾.",
            'ja': "ã“ã®ãƒ“ãƒ‡ã‚ªã‚’è©³ç´°ã«åˆ†æã—ã€è¦³å¯Ÿã—ãŸã“ã¨ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ãƒ“ãƒ‡ã‚ªã®å„ã‚·ãƒ¼ãƒ³ã¨è©³ç´°ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ë¹„ë””ì˜¤ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ê´€ì°°í•œ ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ë¹„ë””ì˜¤ì˜ ëª¨ë“  ì¥ë©´ê³¼ ì„¸ë¶€ ì‚¬í•­ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™æ®µè§†é¢‘å¹¶è§£é‡Šä½ æ‰€è§‚å¯Ÿåˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥è§†é¢‘çš„æ¯ä¸ªåœºæ™¯å’Œç»†èŠ‚ã€‚"
        },
        'default': {
            'tr': "Bu medyayÄ± detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Her detayÄ± dikkatle incele.",
            'en': "Analyze this media in detail and explain what you see. Carefully examine every detail.",
            'es': "Analiza este medio en detalle y explica lo que ves. Examina cuidadosamente cada detalle.",
            'fr': "Analysez ce mÃ©dia en dÃ©tail et expliquez ce que vous voyez. Examinez attentivement chaque dÃ©tail.",
            'de': "Analysieren Sie dieses Medium detailliert und erklÃ¤ren Sie, was Sie sehen. Untersuchen Sie jeden Aspekt sorgfÃ¤ltig.",
            'it': "Analizza questo media in dettaglio e spiega cosa vedi. Esamina attentamente ogni dettaglio.",
            'pt': "Analise este meio em detalhes e explique o que vÃª. Examine cuidadosamente cada detalhe.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾Ñ‚ Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°ÑĞ¿ĞµĞºÑ‚.",
            'ja': "ã“ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’è©³ç´°ã«åˆ†æã—ã€è¦‹ãŸã‚‚ã®ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã™ã¹ã¦ã®è©³ç´°ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ë¯¸ë””ì–´ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ë³´ì´ëŠ” ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ëª¨ë“  ì„¸ë¶€ ì‚¬í•­ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™ä¸ªåª’ä½“å¹¶è§£é‡Šä½ æ‰€çœ‹åˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥æ¯ä¸ªç»†èŠ‚ã€‚"
        }
    }

    # If caption is provided, use it
    if caption and caption.strip():
        return caption

    # Select prompt based on media type and language
    if media_type in prompts:
        return prompts[media_type].get(lang, prompts[media_type]['en'])

    # Fallback to default prompt
    return prompts['default'].get(lang, prompts['default']['en'])

def main():
    # Initialize bot
    application = Application.builder().token(os.getenv("TELEGRAM_TOKEN")).build()

    # Add command handler for /derinarama
    application.add_handler(CommandHandler("derinarama", handle_message)) # handle_message will now check for /derinarama

    # Add handlers (rest remain the same)
    application.add_handler(MessageHandler(filters.VIDEO, handle_video))
    application.add_handler(MessageHandler(filters.PHOTO, handle_image))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message)) # handle_message handles both regular text and /derinarama now

    # Start the bot
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    user_memory = UserMemory()
    main()