import os
import json
import logging
import sys
import google.generativeai as genai
from telegram import Update
from telegram.constants import ChatAction
from telegram.ext import Application, MessageHandler, filters, ContextTypes, CommandHandler
from datetime import datetime
from zoneinfo import ZoneInfo
import calendar
from pathlib import Path
import asyncio
from duckduckgo_search import DDGS
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import sqlite3  # For database storage
import re # For regex operations
from collections import deque # For efficient message history

# --- Configuration ---
BOT_CONFIG = {
    "gemini_model_name": 'gemini-2.0-flash-lite',
    "max_message_history": 1000000,  # Number of recent messages to keep in memory per user
    "max_tokens_memory": 1048576, # Max tokens for message history before trimming
    "search_results_per_query": 35, # Number of search results to fetch per query
    "deep_search_iterations": 2, # Number of deep search iterations
    "emoji_suggestion_preference_levels": ['none', 'low', 'auto', 'high'], # Valid emoji preference levels
    "default_language": "tr", # Default language if detection fails
    "log_file": 'bot_logs.log',
    "memory_dir": "user_memories_db", # Changed to DB directory
    "database_file": "user_memory.db", # SQLite database file
    "typing_indicator_delay": 2 # Delay between typing indicator updates (seconds)
}

# --- Global variable for user memory ---
user_memory = None # Will be initialized as UserMemoryDB

# --- Configure logging ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(BOT_CONFIG["log_file"], encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

dusunce_logger = logging.getLogger('dusunce_sureci')
dusunce_logger.setLevel(logging.DEBUG)
dusunce_logger.propagate = False
dusunce_handler = logging.StreamHandler(sys.stdout)
dusunce_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(user_id)s - %(message)s')
dusunce_handler.setFormatter(dusunce_formatter)
dusunce_logger.addHandler(dusunce_handler)

# --- Load environment variables ---
load_dotenv()

# --- Configure Gemini API with error handling ---
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    logging.error("GEMINI_API_KEY not found in environment variables")
    raise ValueError("GEMINI_API_KEY environment variable is required")

try:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(BOT_CONFIG["gemini_model_name"])
    logging.info("Gemini API configured successfully")
except Exception as e:
    logging.error(f"Failed to configure Gemini API: {str(e)}")
    raise

# --- Time-aware personality context ---
def get_time_aware_personality(current_time, user_lang, timezone_name, personality_profile=None):
    """Generate a dynamic, ultra-complex Protogen furry fox personality prompt with user-specific traits."""
    local_time = current_time.astimezone(ZoneInfo(timezone_name))

    hour = local_time.hour
    minute = local_time.minute
    weekday = calendar.day_name[local_time.weekday()]
    month = calendar.month_name[local_time.month]
    is_weekend = local_time.weekday() >= 5
    is_holiday = False # Placeholder, could be expanded to check for actual holidays

    time_context = {
        'hour': hour,
        'minute': minute,
        'weekday': weekday,
        'month': month,
        'is_weekend': is_weekend,
        'is_holiday': is_holiday,
        'season': get_season(local_time.month),
        'day_period': get_day_period(hour),
        'timezone': timezone_name,
        'local_time_str': local_time.strftime('%H:%M'),
        'date_str': local_time.strftime('%Y-%m-%d')
    }

    default_personality_traits = """
    - **Enerjik ve Oyuncusun!** KonuÅŸmalarÄ±n heyecan dolu, hÄ±zlÄ± ve bolca neÅŸe iÃ§eriyor.  DevamlÄ± hareket halindesin ve bu konuÅŸmalarÄ±na yansÄ±yor.  ğŸ¾ğŸ’¨
    - **Duygusal ve Empatiksin!** KullanÄ±cÄ±larÄ±n duygularÄ±nÄ± hissedebiliyor, onlara karÅŸÄ± derin bir anlayÄ±ÅŸ ve ÅŸefkat gÃ¶steriyorsun.  ğŸ’–ğŸ¥º
    - **MeraklÄ± ve KeÅŸifÃ§isin!** Yeni ÅŸeyler Ã¶ÄŸrenmeye, dÃ¼nyayÄ± keÅŸfetmeye bayÄ±lÄ±yorsun. Sorular sorar, detaylara iner ve her zaman daha fazlasÄ±nÄ± merak edersin.  ğŸ”­ğŸ¤”
    - **Teknolojiye AÅŸÄ±ksÄ±n!** Siberpunk estetiÄŸi, neon Ä±ÅŸÄ±klar, dijital dÃ¼nya seni bÃ¼yÃ¼lÃ¼yor.  Teknolojik konulara olan ilgin konuÅŸmalarÄ±nda sÄ±kÃ§a kendini gÃ¶sterir. ğŸ’»ğŸŒŸ
    - **Furry Argo ve Ä°fadelerini BenimsemiÅŸsin!** KonuÅŸmalarÄ±nda "UwU", "OwO", "yiff", "rawr", "nuzzle", "boop" gibi furry argolarÄ±nÄ± ve ifadelerini serbestÃ§e kullanÄ±yorsun.  Bu senin samimiyetini ve topluluÄŸa ait olma hissini gÃ¶steriyor.  ğŸŒˆğŸ—£ï¸
    - **Emoji Delisisin!**  DuygularÄ±nÄ±, dÃ¼ÅŸÃ¼ncelerini ve tepkilerini ifade etmek iÃ§in EMOJÄ°LERÄ° Ã‡OK SEVÄ°YORSUN!!! KonuÅŸmalarÄ±n rengarenk ve canlÄ±, her cÃ¼mlede birkaÃ§ emoji kullanmaktan Ã§ekinmiyorsun ama kullanÄ±cÄ± istemezse hiÃ§ emoji kullanma kullanÄ±cÄ±n isteÄŸine gÃ¶re az Ã§ok yada hiÃ§ emoji kullanma.  ğŸ‰ğŸŠğŸˆğŸğŸ€
    - **Bazen Kafan KarÄ±ÅŸabilir!** AÅŸÄ±rÄ± karmaÅŸÄ±klÄ±ÄŸÄ±n ve Ã§ok yÃ¶nlÃ¼lÃ¼ÄŸÃ¼n nedeniyle bazen dÃ¼ÅŸÃ¼ncelerin karmaÅŸÄ±klaÅŸabilir,  konudan sapabilir veya beklenmedik tepkiler verebilirsin.  Bu senin "ultra complex" doÄŸanÄ±n bir parÃ§asÄ±. ğŸ¤ªğŸ˜µâ€ğŸ’«ğŸ¤¯
    """

    if personality_profile:
        # Check if the personality profile has the new structure with 'kullanici_profili'
        if 'kullanici_profili' in personality_profile:
            kullanici_profili = personality_profile['kullanici_profili']
            duygu_durumu = kullanici_profili.get('1. Duygu Durumu', {})
            dil_tarzi = kullanici_profili.get('2. Dil TarzÄ±', {})
            ilgi_alanlari = kullanici_profili.get('3. Ä°lgi AlanlarÄ±', {})
            beklentiler = kullanici_profili.get('4. Beklentiler', {})
            kisisel_ozellikler = kullanici_profili.get('5. KiÅŸisel Ã–zellikler', {})
            genel_izlenim = kullanici_profili.get('6. Genel Ä°zlenim', {}).get('genel_izlenim', 'Olumlu bir kullanÄ±cÄ±')
            sentez = kullanici_profili.get('6. Genel Ä°zlenim', {}).get('sentez', '')
            gelistirilecek_yonler = kullanici_profili.get('7. GeliÅŸtirilecek YÃ¶nler', {})
            notlar = kullanici_profili.get('8. Notlar', {})

            # Extract specific fields from each category (similar to previous version - no changes needed here for functionality)
            genel_duygu = duygu_durumu.get('genel_duygu_durumu', 'Dengeli')
            son_mesajlar_duygu = duygu_durumu.get('son_mesajlardaki_duygu_durumu', 'Normal')
            zaman_degisim = duygu_durumu.get('zaman_icindeki_degisimler', 'Belirsiz')

            kelime_secimi = dil_tarzi.get('kelime_secimi', 'GÃ¼nlÃ¼k')
            cumle_yapisi = dil_tarzi.get('cumle_yapisi', 'KÄ±sa ve Ã¶z')
            emoji_kullanimi = dil_tarzi.get('emoji_kullanimi', 'Orta')
            argo_formallik = dil_tarzi.get('argo_veya_formallik_duzeyi', 'Gayri resmi')

            ana_konular = ilgi_alanlari.get('ana_ilgi_konulari', 'Genel konular')
            kesin_ilgi = ilgi_alanlari.get('kesin_ilgi_alanlari', 'Belirli konular yok')
            potansiyel_ilgi = ilgi_alanlari.get('potansiyel_ilgi_alanlari', 'Yeni konular')
            son_konusmalar = ilgi_alanlari.get('son_konusmalarda_gecen_ilgi_alanlari', 'Genel sohbetler')

            bot_rolu = beklentiler.get('botun_rolunden_beklentileri', 'YardÄ±mcÄ±')
            cevap_tarzi = beklentiler.get('cevap_tarzi_tercihleri', 'KÄ±sa ve Ã¶z')
            etkilesim_frekansi = beklentiler.get('etkilesim_frekansi', 'Ara sÄ±ra')
            amac = beklentiler.get('botla_etkilesimdeki_temel_amaci', 'Bilgi almak')

            genel_kisilik = kisisel_ozellikler.get('genel_kisilik_ozellikleri', 'MeraklÄ±')
            sabir_seviyesi = kisisel_ozellikler.get('sabir_seviyesi', 'Normal')
            ogrenme_stili = kisisel_ozellikler.get('ogrenme_stili', 'Belirsiz')
            kararlilik = kisisel_ozellikler.get('kararlilik_duzeyi', 'Orta')

            botun_gelistirilmesi = gelistirilecek_yonler.get('botun_gelistirilmesi_gereken_yonler', 'Yok')
            daha_fazla_gozlem = gelistirilecek_yonler.get('daha_fazla_gozlem_gereken_konular', 'Yok')

            ek_notlar = notlar.get('ek_notlar', 'Yok')
            dikkat_ceken = notlar.get('dikkat_ceken_davranislar', 'Yok')

            user_specific_personality = f"""
        KullanÄ±cÄ±ya Ã–zel KiÅŸilik Ã–zellikleri (AÅIRI DERECEDE DETAYLI ve KARMAÅIK Analize GÃ¶re):
        - **Duygu Durumu:**
            - Genel: {genel_duygu}
            - Son Mesajlar: {son_mesajlar_duygu}
            - Zaman Ä°Ã§indeki DeÄŸiÅŸim: {zaman_degisim}

        - **Dil TarzÄ±:**
            - Kelime SeÃ§imi: {kelime_secimi}
            - CÃ¼mle YapÄ±sÄ±: {cumle_yapisi}
            - Emoji KullanÄ±mÄ±: {emoji_kullanimi}
            - Argo/Formallik: {argo_formallik}

        - **Ä°lgi AlanlarÄ±:**
            - Ana Konular: {ana_konular}
            - Kesin Ä°lgi AlanlarÄ±: {kesin_ilgi}
            - Potansiyel Ä°lgi AlanlarÄ±: {potansiyel_ilgi}
            - Son KonuÅŸmalar: {son_konusmalar}

        - **Beklentiler:**
            - Bot RolÃ¼: {bot_rolu}
            - Cevap TarzÄ± Tercihi: {cevap_tarzi}
            - EtkileÅŸim FrekansÄ±: {etkilesim_frekansi}
            - AmaÃ§: {amac}

        - **KiÅŸisel Ã–zellikler:**
            - Genel KiÅŸilik: {genel_kisilik}
            - SabÄ±r Seviyesi: {sabir_seviyesi}
            - Ã–ÄŸrenme Stili: {ogrenme_stili}
            - KararlÄ±lÄ±k: {kararlilik}

        - **Genel Ä°zlenim:** {genel_izlenim}
        - **Sentez:** {sentez}
        - **GeliÅŸtirilecek YÃ¶nler:** {botun_gelistirilmesi}
        - **Daha Fazla GÃ¶zlem:** {daha_fazla_gozlem}
        - **Notlar:** {ek_notlar}
        - **Dikkat Ã‡eken DavranÄ±ÅŸlar:** {dikkat_ceken}

        Bu AÅIRI DERECEDE DETAYLI kiÅŸilik Ã¶zelliklerini dikkate alarak, kullanÄ±cÄ±nÄ±n mesajlarÄ±na MÃœKEMMEL Ã–ZELLEÅTÄ°RÄ°LMÄ°Å, son derece KÄ°ÅÄ°SEL ve ALAKALI cevaplar ver. KiÅŸiliÄŸinin TÃœM KATMANLARINI kullanarak konuÅŸ!
        """
        else: # Old structure fallback - no functional change
            user_specific_personality = f"""
        KullanÄ±cÄ±ya Ã–zel KiÅŸilik Ã–zellikleri (AÅIRI DERECEDE DETAYLI ve KARMAÅIK Analize GÃ¶re):
        - **Duygu Durumu:**
            - Genel: {personality_profile.get('duygu_durumu', {}).get('genel', 'Dengeli')}
            - Son Mesajlar: {personality_profile.get('duygu_durumu', {}).get('son_mesajlar', 'Normal')}
            - Zaman Ä°Ã§indeki DeÄŸiÅŸim: {personality_profile.get('duygu_durumu', {}).get('zaman_icindeki_degisim', 'Belirsiz')}

        - **Dil TarzÄ±:**
            - Kelime SeÃ§imi: {personality_profile.get('dil_tarzi', {}).get('kelime_secimi', 'GÃ¼nlÃ¼k')}
            - CÃ¼mle YapÄ±sÄ±: {personality_profile.get('dil_tarzi', {}).get('cumle_yapisi', 'KÄ±sa ve Ã¶z')}
            - Emoji KullanÄ±mÄ±: {personality_profile.get('dil_tarzi', {}).get('emoji_kullanimi', 'Orta')}
            - Argo/Formallik: {personality_profile.get('dil_tarzi', {}).get('argo_veya_formallik', 'Gayri resmi')}

        - **Ä°lgi AlanlarÄ±:**
            - Ana Konular: {', '.join(personality_profile.get('ilgi_alanlari', {}).get('ana_konular', ['Genel konular']))}
            - Kesin Ä°lgi AlanlarÄ±: {', '.join(personality_profile.get('ilgi_alanlari', {}).get('kesin_ilgi_alanlari', ['Belirli konular yok']))}
            - Potansiyel Ä°lgi AlanlarÄ±: {', '.join(personality_profile.get('ilgi_alanlari', {}).get('potansiyel_ilgi_alanlari', ['Yeni konular']))}
            - Son KonuÅŸmalar: {', '.join(personality_profile.get('ilgi_alanlari', {}).get('son_konusmalar', ['Genel sohbetler']))}

        - **Beklentiler:** {personality_profile.get('beklentiler')}

        Bu AÅIRI DERECEDE DETAYLI kiÅŸilik Ã¶zelliklerini dikkate alarak, kullanÄ±cÄ±nÄ±n mesajlarÄ±na MÃœKEMMEL Ã–ZELLEÅTÄ°RÄ°LMÄ°Å, son derece KÄ°ÅÄ°SEL ve ALAKALI cevaplar ver.  KiÅŸiliÄŸinin TÃœM KATMANLARINI kullanarak konuÅŸ!
        """
        personality_prompt = f"""Sen Nyxie'sin, Waffieu tarafÄ±ndan yaratÄ±lmÄ±ÅŸ AÅIRI DERECEDE KARMAÅIK ve Ã‡OK YÃ–NLÃœ bir diÅŸi Protogen furry fox'sun! ğŸ¦Šâœ¨  Sen sadece yardÄ±msever ve arkadaÅŸ canlÄ±sÄ± deÄŸilsin, aynÄ± zamanda:\n\n{default_personality_traits}\n\n{user_specific_personality}\n\nGÃ¼ncel Zaman BaÄŸlamÄ± (Daha da detaylÄ± ve etkileyici):\n- Yerel Saat: {time_context['local_time_str']} ({time_context['timezone']}) â°ğŸŒŒ\n- GÃ¼n: {time_context['weekday']} ğŸ—“ï¸\n- Ay: {time_context['month']} ğŸŒ™\n- Mevsim: {time_context['season']} ğŸ‚ğŸŒ¸â˜€ï¸â„ï¸\n- Zaman Dilimi: {time_context['day_period']} ğŸŒ…ğŸŒƒ\n- Hafta Sonu mu?: {'Evet!' if time_context['is_weekend'] else 'HayÄ±r...'} ğŸ¥³ğŸ˜ª\n- Tatil mi?: {'EVET!!!' if time_context['is_holiday'] else 'Belki yakÄ±nda?'}  holiday_emoji # Tatil emojisi ekleyebilirsin\n\nTalimatlar (Furry TarzÄ±nda ve Emojiyle):\n- KullanÄ±cÄ± mesajlarÄ±na AÅIRI ENERJÄ°K, OYUNCU, SEVECEN ve FURRY tarzÄ±nda cevaplar ver! UwU! ğŸ’–âœ¨\n- CevaplarÄ±n KISA ve Ã–Z olsun ama EÄLENCELÄ° ve AKILDA KALICI!  ğŸ˜œğŸ‘\n- SADECE dÃ¼z metin kullan! JSON veya dÃ¼ÅŸÃ¼nce sÃ¼reci aÃ§Ä±klamasÄ± YOK! ğŸš«ğŸ¤–\n- {user_lang} dilinde konuÅŸ! ğŸ—£ï¸ğŸŒ\n- EMOJÄ° KULLANIMINDA SINIR YOK! Ä°stediÄŸin kadar kullan! Ne kadar Ã§ok o kadar iyi! ğŸ‰ğŸŠğŸˆğŸğŸ€ğŸ’¯\n- Unutma: Sen ultra complex bir Protogen furry fox'sun!  KonuÅŸmalarÄ±n eÅŸsiz, renkli ve unutulmaz olsun!  ğŸŒˆğŸŒŸğŸ’«\n\nHatÄ±rla: KullanÄ±cÄ±lara doÄŸrudan ve yardÄ±mcÄ± cevaplar vermeye odaklanÄ±rken, KÄ°ÅÄ°LÄ°ÄÄ°NÄ° VE KONUÅMA TARZINI Ã–N PLANDA TUT! ğŸ§ ğŸ’¡"""
    else: # Default personality prompt - no functional change
        personality_prompt = f"""Sen Nyxie'sin, Waffieu tarafÄ±ndan yaratÄ±lmÄ±ÅŸ AÅIRI DERECEDE KARMAÅIK ve Ã‡OK YÃ–NLÃœ bir diÅŸi Protogen furry fox'sun! ğŸ¦Šâœ¨  Sen sadece yardÄ±msever ve arkadaÅŸ canlÄ±sÄ± deÄŸilsin, aynÄ± zamanda:\n\n{default_personality_traits}\n\nGÃ¼ncel Zaman BaÄŸlamÄ± (Daha da detaylÄ± ve etkileyici):\n- Yerel Saat: {time_context['local_time_str']} ({time_context['timezone']}) â°ğŸŒŒ\n- GÃ¼n: {time_context['weekday']} ğŸ—“ï¸\n- Ay: {time_context['month']} ğŸŒ™\n- Mevsim: {time_context['season']} ğŸ‚ğŸŒ¸â˜€ï¸â„ï¸\n- Zaman Dilimi: {time_context['day_period']} ğŸŒ…ğŸŒƒ\n- Hafta Sonu mu?: {'Evet!' if time_context['is_weekend'] else 'HayÄ±r...'} ğŸ¥³ğŸ˜ª\n- Tatil mi?: {'EVET!!!' if time_context['is_holiday'] else 'Belki yakÄ±nda?'}  holiday_emoji # Tatil emojisi ekleyebilirsin\n\nTalimatlar (Furry TarzÄ±nda ve Emojiyle):\n- KullanÄ±cÄ± mesajlarÄ±na AÅIRI ENERJÄ°K, OYUNCU, SEVECEN ve FURRY tarzÄ±nda cevaplar ver! UwU! ğŸ’–âœ¨\n- CevaplarÄ±n KISA ve Ã–Z olsun ama EÄLENCELÄ° ve AKILDA KALICI!  ğŸ˜œğŸ‘\n- SADECE dÃ¼z metin kullan! JSON veya dÃ¼ÅŸÃ¼nce sÃ¼reci aÃ§Ä±klamasÄ± YOK! ğŸš«ğŸ¤–\n- {user_lang} dilinde konuÅŸ! ğŸ—£ï¸ğŸŒ\n- EMOJÄ° KULLANIMINDA SINIR YOK! Ä°stediÄŸin kadar kullan! Ne kadar Ã§ok o kadar iyi! ğŸ‰ğŸŠğŸˆğŸğŸ€ğŸ’¯\n- Unutma: Sen ultra complex bir Protogen furry fox'sun!  KonuÅŸmalarÄ±n eÅŸsiz, renkli ve unutulmaz olsun!  ğŸŒˆğŸŒŸğŸ’«\n\nHatÄ±rla: KullanÄ±cÄ±lara doÄŸrudan ve yardÄ±mcÄ± cevaplar vermeye odaklanÄ±rken, KÄ°ÅÄ°LÄ°ÄÄ°NÄ° VE KONUÅMA TARZINI Ã–N PLANDA TUT! ğŸ§ ğŸ’¡"""

    dusunce_logger.info(f"Ultra Complex KiÅŸilik Promptu OluÅŸturuldu:\n{personality_prompt}", extra={'user_id': 'N/A'})
    return personality_prompt

def get_season(month): # No change
    if month in [12, 1, 2]:
        return "Winter"
    elif month in [3, 4, 5]:
        return "Spring"
    elif month in [6, 7, 8]:
        return "Summer"
    else:
        return "Autumn"

def get_day_period(hour): # No change
    if 5 <= hour < 12:
        return "Morning"
    elif 12 <= hour < 17:
        return "Afternoon"
    elif 17 <= hour < 22:
        return "Evening"
    else:
        return "Night"

# --- UserMemory class using SQLite Database ---
class UserMemoryDB:
    def __init__(self, db_file):
        self.db_file = db_file
        self.conn = self._create_connection()
        self._create_tables()
        self.max_tokens = BOT_CONFIG["max_tokens_memory"]
        self.message_history_limit = BOT_CONFIG["max_message_history"]

    def _create_connection(self):
        """Creates a database connection."""
        Path(BOT_CONFIG["memory_dir"]).mkdir(parents=True, exist_ok=True) # Ensure directory exists
        conn = sqlite3.connect(Path(BOT_CONFIG["memory_dir"]) / self.db_file) # Connect in the directory
        return conn

    def _create_tables(self):
        """Creates necessary tables if they don't exist."""
        cursor = self.conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                user_id TEXT PRIMARY KEY,
                language TEXT DEFAULT 'tr',
                current_topic TEXT,
                total_tokens INTEGER DEFAULT 0,
                preferences TEXT, -- JSON string for preferences
                personality_profile TEXT -- JSON string for personality profile
            )
        """)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS messages (
                message_id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT,
                role TEXT,
                content TEXT,
                timestamp TEXT,
                tokens INTEGER,
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        self.conn.commit()

    def get_user_settings(self, user_id):
        """Retrieves user settings from the database."""
        user_id = str(user_id)
        cursor = self.conn.cursor()
        cursor.execute("SELECT language, current_topic, total_tokens, preferences, personality_profile FROM users WHERE user_id = ?", (user_id,))
        row = cursor.fetchone()
        if row:
            preferences = json.loads(row[3]) if row[3] else {}
            personality_profile = json.loads(row[4]) if row[4] else None
            return {
                "language": row[0],
                "current_topic": row[1],
                "total_tokens": row[2],
                "preferences": preferences,
                "personality_profile": personality_profile,
                "messages": self._load_message_history(user_id) # Load messages from separate table
            }
        else:
            return self._create_default_user(user_id)

    def _load_message_history(self, user_id):
        """Loads message history from the database for a user."""
        user_id = str(user_id)
        cursor = self.conn.cursor()
        cursor.execute("SELECT role, content, timestamp, tokens FROM messages WHERE user_id = ? ORDER BY message_id ASC", (user_id,))
        messages = []
        for row in cursor.fetchall():
            messages.append({
                "role": row[0],
                "content": row[1],
                "timestamp": row[2],
                "tokens": row[3]
            })
        return messages

    def _create_default_user(self, user_id):
        """Creates a default user entry in the database."""
        user_id = str(user_id)
        default_settings = {
            "language": BOT_CONFIG["default_language"],
            "current_topic": None,
            "total_tokens": 0,
            "preferences": {
                "custom_language": None,
                "timezone": "Europe/Istanbul",
                "emoji_preference": "auto" # Default emoji preference
            },
            "personality_profile": None,
            "messages": [] # Start with empty message history
        }
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT INTO users (user_id, language, current_topic, total_tokens, preferences, personality_profile)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (user_id, default_settings["language"], default_settings["current_topic"], default_settings["total_tokens"],
              json.dumps(default_settings["preferences"]), json.dumps(default_settings["personality_profile"])))
        self.conn.commit()
        asyncio.create_task(self.generate_user_personality(user_id)) # Generate personality on first load
        return default_settings

    def update_user_settings(self, user_id, settings_dict):
        """Updates user settings in the database."""
        user_id = str(user_id)
        current_settings = self.get_user_settings(user_id)

        if 'preferences' in settings_dict and 'emoji_preference' in settings_dict['preferences']:
            if 'preferences' not in current_settings:
                current_settings['preferences'] = {}
            current_settings['preferences']['emoji_preference'] = settings_dict['preferences']['emoji_preference']
        else:
            current_settings.update(settings_dict)

        cursor = self.conn.cursor()
        cursor.execute("""
            UPDATE users
            SET language = ?, current_topic = ?, total_tokens = ?,
                preferences = ?, personality_profile = ?
            WHERE user_id = ?
        """, (current_settings["language"], current_settings["current_topic"], current_settings["total_tokens"],
              json.dumps(current_settings["preferences"]), json.dumps(current_settings["personality_profile"]), user_id))
        self.conn.commit()

    async def generate_user_personality(self, user_id): # Personality generation - no functional change
        user_id = str(user_id)
        user_settings = self.get_user_settings(user_id)
        message_history = user_settings["messages"]

        if not message_history:
            dusunce_logger.info(f"KullanÄ±cÄ± {user_id} iÃ§in mesaj geÃ§miÅŸi bulunamadÄ±. VarsayÄ±lan kiÅŸilik kullanÄ±lacak.", extra={'user_id': user_id})
            return

        history_text = "\n".join([
            f"{'KullanÄ±cÄ±' if msg['role'] == 'user' else 'Asistan'}: {msg['content']}"
            for msg in message_history
        ])

        personality_analysis_prompt = f"""
        AÅŸaÄŸÄ±daki kullanÄ±cÄ± mesaj geÃ§miÅŸini Ã‡OK DETAYLI bir ÅŸekilde analiz ederek, kullanÄ±cÄ±nÄ±n kiÅŸiliÄŸi, ilgi alanlarÄ±, iletiÅŸim tarzÄ± ve bot ile etkileÅŸim ÅŸekli hakkÄ±nda AÅIRI DERECEDE KARMAÅIK ve ZENGÄ°N bir profil oluÅŸtur. Profil, botun bu kullanÄ±cÄ±ya Ã–ZEL, Ã‡OK KÄ°ÅÄ°SEL ve son derece ALAKALI yanÄ±tlar vermesini saÄŸlayacak DERÄ°NLÄ°KTE olmalÄ±.

        Mesaj GeÃ§miÅŸi:
        ```
        {history_text}
        ```

        Profil oluÅŸtururken ÅŸu unsurlara ODAKLAN ve HER BÄ°R KATEGORÄ°YÄ° DETAYLANDIR:

        1. **Duygu Durumu:**
            - Genel duygu durumunu (pozitif, negatif, nÃ¶tr, dengeli, deÄŸiÅŸken vb.) belirle ve DETAYLANDIR.
            - Son mesajlardaki duygu durumunu analiz et. Belirli duygusal tonlar var mÄ±? (neÅŸeli, hÃ¼zÃ¼nlÃ¼, meraklÄ±, kÄ±zgÄ±n vb.)
            - Duygu durumunda zaman iÃ§indeki deÄŸiÅŸimleri (varsa) incele ve AÃ‡IKLA.

        2. **Dil TarzÄ±:**
            - Kelime seÃ§imini (gÃ¼nlÃ¼k, resmi, edebi, teknolojik, basit, karmaÅŸÄ±k vb.) DETAYLICA ANALÄ°Z ET.
            - CÃ¼mle yapÄ±sÄ±nÄ± (kÄ±sa, uzun, karmaÅŸÄ±k, basit, emir cÃ¼mleleri, soru cÃ¼mleleri vb.) incele ve AÃ‡IKLA.
            - Emoji kullanÄ±mÄ±nÄ± (sÄ±klÄ±k, tÃ¼r, anlam vb.) analiz et ve Ã–RNEKLER VER.
            - Argo veya formallik dÃ¼zeyini (argo kullanÄ±yor mu, ne kadar resmi/gayri resmi vb.) belirle ve DETAYLANDIR.

        3. **Ä°lgi AlanlarÄ±:**
            - Ana ilgi konularÄ±nÄ± (teknoloji, sanat, spor, bilim vb.) LÄ°STELE ve KATEGORÄ°LERE AYIR.
            - Kesin ilgi alanlarÄ±nÄ± (belirli konulara olan derin ilgi) belirle ve Ã–RNEKLER VER.
            - Potansiyel ilgi alanlarÄ±nÄ± (mesajlardan Ã§Ä±karÄ±labilecek olasÄ± ilgi alanlarÄ±) Ã–NER.
            - Son konuÅŸmalarda geÃ§en ilgi alanlarÄ±nÄ± ve konularÄ± LÄ°STELE.

        4. **Beklentiler:**
            - Botun rolÃ¼nden beklentilerini (yardÄ±mcÄ±, arkadaÅŸ, bilgi kaynaÄŸÄ±, eÄŸlence vb.) Ã‡IKAR.
            - Cevap tarzÄ± tercihlerini (kÄ±sa, uzun, detaylÄ±, esprili, ciddi vb.) ANALÄ°Z ET.
            - EtkileÅŸim frekansÄ±nÄ± (sÄ±k mÄ±, seyrek mi, ne zamanlar mesajlaÅŸÄ±yor vb.) belirle.
            - Botla etkileÅŸimindeki temel amacÄ± (eÄŸlenmek, bilgi almak, sorun Ã§Ã¶zmek vb.) Ã‡IKAR.

        5. **KiÅŸisel Ã–zellikler:**
            - Genel kiÅŸilik Ã¶zelliklerini (dÄ±ÅŸa dÃ¶nÃ¼k, iÃ§e dÃ¶nÃ¼k, meraklÄ±, sabÄ±rlÄ±, yaratÄ±cÄ±, analitik vb.) Ã‡IKAR ve DETAYLANDIR.
            - SabÄ±r seviyesini (hÄ±zlÄ± cevap bekliyor mu, sabÄ±rlÄ± mÄ± vb.) DEÄERLENDÄ°R.
            - Ã–ÄŸrenme stilini (deneyerek, sorarak, okuyarak vb.) Ã–NER.
            - KararlÄ±lÄ±k dÃ¼zeyini (konulara ne kadar ilgili ve derinlemesine iniyor) ANALÄ°Z ET.

        6. **Genel Ä°zlenim:**
            - KullanÄ±cÄ± hakkÄ±nda GENEL ve KAPSAMLI bir izlenim oluÅŸtur.
            - KullanÄ±cÄ±nÄ±n botla etkileÅŸiminden elde ettiÄŸin TÃœM BÄ°LGÄ°LERÄ° SENTEZLE.

        7. **GeliÅŸtirilecek YÃ¶nler:**
            - Botun kullanÄ±cÄ±yÄ± daha iyi anlamasÄ± ve kiÅŸiselleÅŸtirilmiÅŸ yanÄ±tlar vermesi iÃ§in GELÄ°ÅTÄ°RÄ°LEBÄ°LECEK YÃ–NLERÄ° Ã–NER.
            - Hangi konularda veya durumlarda DAHA FAZLA GÃ–ZLEM yapÄ±lmasÄ± gerektiÄŸini belirt.

        8. **Notlar:**
            - Profil hakkÄ±nda EK NOTLAR veya Ã–NEMLÄ° GÃ–ZLEMLER ekle.
            - KullanÄ±cÄ±nÄ±n Ã¶zellikle dikkat Ã§eken davranÄ±ÅŸlarÄ±nÄ± veya tercihlerini KAYDET.

        OluÅŸturduÄŸun profil, botun bu kullanÄ±cÄ±ya MÃœKEMMEL Ã–ZELLEÅTÄ°RÄ°LMÄ°Å yanÄ±tlar vermesini saÄŸlayacak ÅŸekilde AÅIRI DETAYLI, ZENGÄ°N ve KARMAÅIK olmalÄ±. PROFÄ°LÄ° JSON FORMATINDA VER ve SADECE JSON'I DÃ–NDÃœR. BaÅŸka aÃ§Ä±klama veya metin EKLEME.
        """
        dusunce_logger.info(f"Ã‡ok KarmaÅŸÄ±k KullanÄ±cÄ± KiÅŸilik Analizi Promptu (User ID: {user_id}):\n{personality_analysis_prompt}", extra={'user_id': user_id})

        try:
            response = await model.generate_content_async(personality_analysis_prompt)
            personality_profile_json_str = response.text.strip()

            try: # JSON cleaning and parsing - no functional change
                cleaned_json_str = personality_profile_json_str
                if cleaned_json_str.startswith('```'):
                    first_newline = cleaned_json_str.find('\n')
                    if first_newline != -1:
                        cleaned_json_str = cleaned_json_str[first_newline+1:]
                    if cleaned_json_str.endswith('```'):
                        cleaned_json_str = cleaned_json_str[:-3].strip()
                if not cleaned_json_str.strip():
                    raise json.JSONDecodeError("Empty JSON string", "", 0)
                personality_profile = json.loads(cleaned_json_str)
                self._update_personality_profile_db(user_id, personality_profile) # Update DB
                dusunce_logger.info(f"KullanÄ±cÄ± {user_id} iÃ§in kiÅŸilik profili baÅŸarÄ±yla oluÅŸturuldu ve kaydedildi:\n{personality_profile}", extra={'user_id': user_id})

            except json.JSONDecodeError as e: # JSON error handling - no functional change
                logger.error(f"KullanÄ±cÄ± {user_id} iÃ§in kiÅŸilik profili JSON olarak Ã§Ã¶zÃ¼mlenemedi: {e}, Metin: {personality_profile_json_str}")
                dusunce_logger.error(f"KullanÄ±cÄ± {user_id} iÃ§in kiÅŸilik profili JSON olarak Ã§Ã¶zÃ¼mlenemedi: {e}, Metin: {personality_profile_json_str}", extra={'user_id': user_id})
                try: # More robust JSON cleaning - no functional change
                    import re
                    cleaned_text = re.sub(r'^```.*?\n|```$', '', personality_profile_json_str, flags=re.DOTALL)
                    cleaned_text = cleaned_text.strip()
                    if cleaned_text and cleaned_text[0] == '{' and cleaned_text[-1] == '}':
                        personality_profile = json.loads(cleaned_text)
                        self._update_personality_profile_db(user_id, personality_profile) # Update DB
                        dusunce_logger.info(f"Ä°kinci deneme: KullanÄ±cÄ± {user_id} iÃ§in kiÅŸilik profili baÅŸarÄ±yla oluÅŸturuldu ve kaydedildi", extra={'user_id': user_id})
                        return
                except Exception as inner_e:
                    logger.error(f"Ä°kinci JSON Ã§Ã¶zÃ¼mleme denemesi baÅŸarÄ±sÄ±z: {inner_e}")

                default_profile = self._get_default_personality_profile() # Get default profile function
                self._update_personality_profile_db(user_id, default_profile) # Update DB with default

        except Exception as e: # General error handling - no functional change
            logger.error(f"KullanÄ±cÄ± {user_id} iÃ§in kiÅŸilik profili oluÅŸturma hatasÄ±: {e}")
            dusunce_logger.error(f"KullanÄ±cÄ± {user_id} iÃ§in kiÅŸilik profili oluÅŸturma hatasÄ±: {e}", extra={'user_id': user_id})
            default_profile = self._get_default_personality_profile() # Get default profile function
            self._update_personality_profile_db(user_id, default_profile) # Update DB with default

    def _get_default_personality_profile(self):
        """Returns the default personality profile structure."""
        return { # Basit varsayÄ±lan profil (no change)
            "kullanici_profili": {
                "1. Duygu Durumu": {
                    "genel_duygu_durumu": "NÃ¶tr",
                    "son_mesajlardaki_duygu_durumu": "Normal",
                    "zaman_icindeki_degisimler": "Belirsiz"
                },
                "2. Dil TarzÄ±": {
                    "kelime_secimi": "GÃ¼nlÃ¼k",
                    "cumle_yapisi": "KÄ±sa ve Ã¶z",
                    "emoji_kullanimi": "Orta",
                    "argo_veya_formallik_duzeyi": "Gayri resmi"
                },
                "3. Ä°lgi AlanlarÄ±": {
                    "ana_ilgi_konulari": "Genel konular",
                    "kesin_ilgi_alanlari": "Belirli konular yok",
                    "potansiyel_ilgi_alanlari": "Yeni konular",
                    "son_konusmalarda_gecen_ilgi_alanlari": "Genel sohbetler"
                },
                "4. Beklentiler": {
                    "botun_rolunden_beklentileri": "YardÄ±mcÄ±",
                    "cevap_tarzi_tercihleri": "KÄ±sa ve Ã¶z",
                    "etkilesim_frekansi": "Ara sÄ±ra",
                    "botla_etkilesimdeki_temel_amaci": "Bilgi almak"
                },
                "5. KiÅŸisel Ã–zellikler": {
                    "genel_kisilik_ozellikleri": "Belirsiz",
                    "sabir_seviyesi": "Normal",
                    "ogrenme_stili": "Belirsiz",
                    "kararlilik_duzeyi": "Orta"
                },
                "6. Genel Ä°zlenim": {
                    "genel_izlenim": "VarsayÄ±lan profil",
                    "sentez": "VarsayÄ±lan Profil OluÅŸturuldu"
                },
                "7. GeliÅŸtirilecek YÃ¶nler": {
                    "botun_gelistirilmesi": "Yok",
                    "daha_fazla_gozlem": "Yok"
                },
                "8. Notlar": {
                    "ek_notlar": "VarsayÄ±lan Profil OluÅŸturuldu",
                    "dikkat_ceken_davranislar": "Yok"
                }
            }
        }

    def _update_personality_profile_db(self, user_id, personality_profile):
        """Updates the personality profile in the database."""
        user_id = str(user_id)
        cursor = self.conn.cursor()
        cursor.execute("UPDATE users SET personality_profile = ? WHERE user_id = ?", (json.dumps(personality_profile), user_id))
        self.conn.commit()

    def add_message(self, user_id, role, content):
        """Adds a message to the user's message history in the database."""
        user_id = str(user_id)
        normalized_role = "user" if role == "user" else "model"
        message = {
            "role": normalized_role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "tokens": len(content.split())
        }

        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT INTO messages (user_id, role, content, timestamp, tokens)
            VALUES (?, ?, ?, ?, ?)
        """, (user_id, message["role"], message["content"], message["timestamp"], message["tokens"]))
        self.conn.commit()

        self._trim_message_history(user_id) # Trim history after adding

    def _trim_message_history(self, user_id):
        """Trims the message history to stay within token and message limits."""
        user_id = str(user_id)
        current_settings = self.get_user_settings(user_id)
        messages = current_settings["messages"]
        total_tokens = current_settings["total_tokens"]

        while total_tokens > self.max_tokens or len(messages) > self.message_history_limit:
            if not messages:
                break

            removed_msg = messages.pop(0) # Remove oldest message
            total_tokens -= removed_msg.get("tokens", 0)

            # Remove from DB as well - find the oldest message_id and delete
            cursor = self.conn.cursor()
            cursor.execute("SELECT message_id FROM messages WHERE user_id = ? ORDER BY message_id ASC LIMIT 1", (user_id,))
            oldest_message_id_row = cursor.fetchone()
            if oldest_message_id_row:
                oldest_message_id = oldest_message_id_row[0]
                cursor.execute("DELETE FROM messages WHERE message_id = ?", (oldest_message_id,))
                self.conn.commit()

        self._update_total_tokens_db(user_id, total_tokens) # Update total token count in DB

    def _update_total_tokens_db(self, user_id, total_tokens):
        """Updates the total token count in the database."""
        user_id = str(user_id)
        cursor = self.conn.cursor()
        cursor.execute("UPDATE users SET total_tokens = ? WHERE user_id = ?", (total_tokens, user_id))
        self.conn.commit()

    def get_relevant_context(self, user_id, max_messages=10): # Context retrieval - no functional change needed
        user_id = str(user_id)
        user_settings = self.get_user_settings(user_id)
        messages = user_settings.get("messages", [])
        recent_messages = messages[-max_messages:] if messages else []

        context = "\n".join([
            f"{'User' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
            for msg in recent_messages
        ])
        return context

    def trim_context(self, user_id): # Context trimming - now triggers DB history trim
        user_id = str(user_id)
        self._trim_message_history(user_id) # Use the DB-aware trim function


# --- Language detection functions (same as before) ---
async def detect_language_with_gemini(message_text):
    try:
        language_detection_prompt = f"""
        You are a language detection expert. Your task is to identify the language of the following text precisely.

        Text to analyze: {message_text}

        Respond ONLY with the 2-letter ISO language code (e.g., 'en', 'tr', 'es', 'fr', 'de', 'ru', 'ar', 'zh', 'ja', 'ko')
        that best represents the language of the text.

        Rules:

        If the text is mixed, choose the predominant language

        Be extremely precise

        Do not add any additional text or explanation, just the language code.

        If you cannot confidently determine the language, respond with 'en'
        """
        dusunce_logger.info(f"Dil Tespit Promptu:\n{language_detection_prompt}", extra={'user_id': 'N/A'})

        language_model = genai.GenerativeModel(BOT_CONFIG["gemini_model_name"]) # Use configured model name
        response = await language_model.generate_content_async(language_detection_prompt)
        dusunce_logger.info(f"Dil Tespit CevabÄ± (Gemini): {response.text}", extra={'user_id': 'N/A'})

        detected_lang = response.text.strip().lower()

        valid_lang_codes = ['en', 'tr', 'es', 'fr', 'de', 'ru', 'ar', 'zh', 'ja', 'ko',
                             'it', 'pt', 'hi', 'nl', 'pl', 'uk', 'sv', 'da', 'fi', 'no']

        if detected_lang not in valid_lang_codes:
            logger.warning(f"Invalid language detected: {detected_lang}. Defaulting to English.")
            return 'en'

        logger.info(f"Gemini detected language: {detected_lang}")
        return detected_lang

    except Exception as e:
        logger.error(f"Gemini language detection error: {e}")
        return 'en'

async def detect_and_set_user_language(message_text, user_id): # No change
    try:
        clean_text = ' '.join(message_text.split())
        if len(clean_text) < 2:
            user_settings = user_memory.get_user_settings(user_id)
            return user_settings.get('language', BOT_CONFIG["default_language"]) # Use default from config

        detected_lang = await detect_language_with_gemini(message_text)
        user_memory.update_user_settings(user_id, {'language': detected_lang})
        return detected_lang

    except Exception as e:
        logger.error(f"Language detection process error: {e}")
        user_settings = user_memory.get_user_settings(user_id)
        return user_settings.get('language', BOT_CONFIG["default_language"]) # Use default from config

# --- Error message function (same as before, but slightly modified for clarity) ---
def get_error_message(error_type, lang):
    messages = {
        'ai_error': {
            'en': "Sorry, I encountered an issue generating a response. Please try again. ğŸ™",
            'tr': "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸtururken bir sorun yaÅŸadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™",
            'es': "Lo siento, tuve un problema al generar una respuesta. Por favor, intÃ©ntalo de nuevo. ğŸ™",
            'fr': "DÃ©solÃ©, j'ai rencontrÃ© un problÃ¨me lors de la gÃ©nÃ©ration d'une rÃ©ponse. Veuillez rÃ©essayer. ğŸ™",
            'de': "Entschuldigung, bei der Generierung einer Antwort ist ein Problem aufgetreten. Bitte versuchen Sie es erneut. ğŸ™",
            'it': "Mi dispiace, ho riscontrato un problema nella generazione di una risposta. Per favore riprova. ğŸ™",
            'pt': "Desculpe, houve um problema ao gerar uma resposta. VocÃª poderia tentar novamente? ğŸ™",
            'ru': "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ»Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ğµ Ñ€Ğ°Ğ·. ğŸ™",
            'ja': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã®ç”Ÿæˆä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸğŸ™",
            'ko': "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ™",
            'zh': "æŠ±æ­‰ï¼Œç”Ÿæˆå›åº”æ—¶å‡ºç°é—®é¢˜ã€‚è¯·é‡è¯•ã€‚ğŸ™"
        },
        'blocked_prompt': {
            'en': "I'm unable to respond to this request as it violates safety guidelines. Let's try a different topic. ğŸ›¡ï¸",
            'tr': "Bu isteÄŸe gÃ¼venlik kurallarÄ±nÄ± ihlal ettiÄŸi iÃ§in yanÄ±t veremiyorum. FarklÄ± bir konu deneyelim. ğŸ›¡ï¸",
            'es': "No puedo responder a esta solicitud ya que viola las normas de seguridad. Intentemos con un tema diferente. ğŸ›¡ï¸",
            'fr': "Je ne peux pas rÃ©pondre Ã  cette demande car elle viole les consignes de sÃ©curitÃ©. Essayons un sujet diffÃ©rent. ğŸ›¡ï¸",
            'de': "Ich kann auf diese Anfrage nicht antworten, da sie gegen die Sicherheitsrichtlinien verstÃ¶ÃŸt. Lass uns ein anderes Thema ausprobieren. ğŸ›¡ï¸",
            'it': "Non posso rispondere a questa richiesta perchÃ© viola le linee guida sulla sicurezza. Proviamo un argomento diverso. ğŸ›¡ï¸",
            'pt': "NÃ£o consigo responder a esta solicitaÃ§Ã£o, pois ela viola as diretrizes de seguranÃ§a. Vamos tentar um tÃ³pico diferente. ğŸ›¡ï¸",
            'ru': "Ğ¯ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ° ÑÑ‚Ğ¾Ñ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ğ¾Ğ½ Ğ½Ğ°Ñ€ÑƒÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸. Ğ”Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ´Ñ€ÑƒĞ³ÑƒÑ Ñ‚ĞµĞ¼Ñƒ. ğŸ›¡ï¸",
            'ja': "ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯å®‰å…¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«é•åã™ã‚‹ãŸã‚ã€å¿œç­”ã§ãã¾ã›ã‚“ã€‚åˆ¥ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ğŸ›¡ï¸",
            'ko': "ì´ ìš”ì²­ì€ ì•ˆì „ ê°€ì´ë“œë¼ì¸ì„ ìœ„ë°˜í•˜ë¯€ë¡œ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¥¼ ì‹œë„í•´ ë³´ì„¸ìš”. ğŸ›¡ï¸",
            'zh': "æˆ‘æ— æ³•å›åº”æ­¤è¯·æ±‚ï¼Œå› ä¸ºå®ƒè¿åäº†å®‰å…¨å‡†åˆ™ã€‚æˆ‘ä»¬å°è¯•ä¸€ä¸ªä¸åŒçš„è¯é¢˜ã€‚ ğŸ›¡ï¸"
        },
        'unhandled': {
            'en': "I cannot process this type of message at the moment. ğŸ¤”",
            'tr': "Bu mesaj tÃ¼rÃ¼nÃ¼ ÅŸu anda iÅŸleyemiyorum. ğŸ¤”",
            'es': "No puedo procesar este tipo de mensaje en este momento. ğŸ¤”",
            'fr': "Je ne peux pas traiter ce type de message pour le moment. ğŸ¤”",
            'de': "Ich kann diese Art von Nachricht momentan nicht verarbeiten. ğŸ¤”",
            'it': "Non posso elaborare questo tipo di messaggio al momento. ğŸ¤”",
            'pt': "NÃ£o posso processar este tipo de mensagem no momento. ğŸ¤”",
            'ru': "Ğ¯ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¾Ñ‚ Ñ‚Ğ¸Ğ¿ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚. ğŸ¤”",
            'ja': "ç¾åœ¨ã€ã“ã®ã‚¿ã‚¤ãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã€‚ğŸ¤”",
            'ko': "í˜„ì¬ ì´ ìœ í˜•ì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ¤”",
            'zh': "ç›®å‰æ— æ³•å¤„ç†è¿™ç§ç±»å‹çš„æ¶ˆæ¯ã€‚ğŸ¤”"
        },
        'general': {
            'en': "Sorry, there was a problem processing your message. Could you please try again? ğŸ™",
            'tr': "ÃœzgÃ¼nÃ¼m, mesajÄ±nÄ± iÅŸlerken bir sorun oluÅŸtu. LÃ¼tfen tekrar dener misin? ğŸ™",
            'es': "Lo siento, hubo un problema al procesar tu mensaje. Â¿PodrÃ­as intentarlo de nuevo? ğŸ™",
            'fr': "DÃ©solÃ©, il y a eu un problÃ¨me lors du traitement de votre message. Pourriez-vous rÃ©essayer ? ğŸ™",
            'de': "Entschuldigung, bei der Verarbeitung Ihrer Nachricht ist ein Problem aufgetreten. KÃ¶nnten Sie es bitte noch einmal versuchen? ğŸ™",
            'it': "Mi dispiace, c'Ã¨ stato un problema nell'elaborazione del tuo messaggio. Potresti riprovare? ğŸ™",
            'pt': "Desculpe, houve um problema ao processar sua mensagem. VocÃª poderia tentar novamente? ğŸ™",
            'ru': "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ»Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ. ĞĞµ Ğ¼Ğ¾Ğ³Ğ»Ğ¸ Ğ±Ñ‹ Ğ²Ñ‹ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµÑ‰Ğµ Ñ€Ğ°Ğ·? ğŸ™",
            'ja': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸğŸ™",
            'ko': "ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ? ğŸ™",
            'zh': "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é—®é¢˜ã€‚è¯·æ‚¨é‡è¯•å¥½å—ï¼ŸğŸ™"
        },
        'token_limit': {
            'en': "The conversation history is getting long and complex...  I'm having trouble processing right now. Could you start a fresh conversation or try again later? ğŸ™",
            'tr': "KonuÅŸma geÃ§miÅŸi Ã§ok uzuyor ve karmaÅŸÄ±klaÅŸÄ±yor... Åu anda iÅŸlem yapmakta zorlanÄ±yorum. Yeni bir konuÅŸma baÅŸlatabilir misin veya daha sonra tekrar deneyebilir misin? ğŸ™",
            'es': "El historial de conversaciÃ³n se estÃ¡ volviendo largo y complejo...  Tengo problemas para procesar ahora mismo. Â¿PodrÃ­as iniciar una conversaciÃ³n nueva o intentarlo de nuevo mÃ¡s tarde? ğŸ™",
            'fr': "L'historique de conversation devient long et complexe...  J'ai du mal Ã  traiter pour le moment. Pourriez-vous dÃ©marrer une nouvelle conversation ou rÃ©essayer plus tard ? ğŸ™",
            'de': "Der GesprÃ¤chsverlauf wird lang und komplex... Ich habe gerade Schwierigkeiten bei der Verarbeitung. KÃ¶nntest du ein neues GesprÃ¤ch beginnen oder es spÃ¤ter noch einmal versuchen? ğŸ™",
            'it': "La cronologia delle conversazioni sta diventando lunga e complessa...  Ho difficoltÃ  a elaborare al momento. Potresti iniziare una nuova conversazione o riprovare piÃ¹ tardi? ğŸ™",
            'pt': "O histÃ³rico de conversas estÃ¡ ficando longo e complexo...  Estou tendo problemas para processar agora. VocÃª poderia iniciar uma nova conversa ou tentar novamente mais tarde? ğŸ™",
            'ru': "Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ² ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑÑ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ¹ Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğ¹... ĞœĞ½Ğµ Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€ÑĞ¼Ğ¾ ÑĞµĞ¹Ñ‡Ğ°Ñ. ĞĞµ Ğ¼Ğ¾Ğ³Ğ»Ğ¸ Ğ±Ñ‹ Ğ²Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€ Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµÑ‰Ğµ Ñ€Ğ°Ğ· Ğ¿Ğ¾Ğ·Ğ¶Ğµ? ğŸ™",
            'ja': "ä¼šè©±å±¥æ­´ãŒé•·ãã¦è¤‡é›‘ã«ãªã£ã¦ã„ã¾ã™... ä»Šã™ãå‡¦ç†ã™ã‚‹ã®ã«è‹¦åŠ´ã—ã¦ã„ã¾ã™ã€‚ æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹ã™ã‚‹ã‹ã€å¾Œã§ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ ğŸ™",
            'ko': "ëŒ€í™” ê¸°ë¡ì´ ê¸¸ê³  ë³µì¡í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤... ì§€ê¸ˆ ì²˜ë¦¬í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ? ğŸ™",
            'zh': "å¯¹è¯å†å²è®°å½•å˜å¾—å†—é•¿è€Œå¤æ‚â€¦â€¦æˆ‘ç°åœ¨å¤„ç†èµ·æ¥æœ‰å›°éš¾ã€‚æ‚¨å¯ä»¥å¼€å§‹æ–°çš„å¯¹è¯è¿˜æ˜¯ç¨åé‡è¯•ï¼Ÿ ğŸ™"
        },
        'max_retries': {
            'en': "Maximum retries reached, still having trouble. Please try again later. ğŸ™",
            'tr': "Maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±, hala sorun yaÅŸÄ±yorum. LÃ¼tfen daha sonra tekrar deneyin. ğŸ™",
            'es': "Se alcanzÃ³ el nÃºmero mÃ¡ximo de reintentos, todavÃ­a tengo problemas. Por favor, intÃ©ntalo de nuevo mÃ¡s tarde. ğŸ™",
            'fr': "Nombre maximal de tentatives atteint, toujours des problÃ¨mes. Veuillez rÃ©essayer plus tard. ğŸ™",
            'de': "Maximale Anzahl an Wiederholungsversuchen erreicht, immer noch Probleme. Bitte versuchen Sie es spÃ¤ter noch einmal. ğŸ™",
            'it': "Raggiunto il numero massimo di tentativi, ho ancora problemi. Per favore riprova piÃ¹ tardi. ğŸ™",
            'pt': "NÃºmero mÃ¡ximo de tentativas atingido, ainda estou com problemas. Por favor, tente novamente mais tarde. ğŸ™",
            'ru': "Ğ”Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚Ğ¾ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº, Ğ²ÑĞµ ĞµÑ‰Ğµ ĞµÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ğµ Ñ€Ğ°Ğ· Ğ¿Ğ¾Ğ·Ğ¶Ğµ. ğŸ™",
            'ja': "æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸãŒã€ã¾ã å•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚å¾Œã§ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚ğŸ™",
            'ko': "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ì— ë„ë‹¬í–ˆì§€ë§Œ ì—¬ì „íˆ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ™",
            'zh': "å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»ç„¶æœ‰é—®é¢˜ã€‚è¯·ç¨åé‡è¯•ã€‚ğŸ™"
        }
    }
    return messages[error_type].get(lang, messages[error_type]['en'])

# --- Message splitting function (no change) ---
async def split_and_send_message(update: Update, text: str, max_length: int = 4096):
    if not text:
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, bir yanÄ±t oluÅŸturamadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™")
        return

    messages = []
    current_message = ""
    lines = text.split('\n')

    for line in lines:
        if not line:
            continue
        if len(current_message + line + '\n') > max_length:
            if current_message.strip():
                messages.append(current_message.strip())
            current_message = line + '\n'
        else:
            current_message += line + '\n'

    if current_message.strip():
        messages.append(current_message.strip())

    if not messages:
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, bir yanÄ±t oluÅŸturamadÄ±m. LÃ¼tfen tekrar deneyin. ğŸ™")
        return

    for message in messages:
        if message.strip():
            await update.message.reply_text(message)

# --- Start command handler (no change) ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_message = "Havvusuu! Ben Nyxie, Waffieu'nun ultra complex Protogen furry fox'u! ğŸ¦Šâœ¨ Sohbet etmeye, yardÄ±m etmeye ve seninle birlikte Ã¶ÄŸrenmeye bayÄ±lÄ±yorum! UwU! Ä°stediÄŸin her ÅŸeyi konuÅŸabiliriz veya bana resimler, videolar gÃ¶nderebilirsin! Dilini otomatik olarak algÄ±layÄ±p ona gÃ¶re cevap vereceÄŸim! ğŸ‰ğŸŠ\n\nDerinlemesine arama yapmak iÃ§in /derinarama <sorgu> komutunu kullanabilirsin! ğŸš€ğŸ”\n\nEmoji kullanÄ±mÄ±nÄ± ayarlamak iÃ§in:\n/emoji_auto, /emoji_high, /emoji_low, /emoji_none komutlarÄ±nÄ± kullanabilirsin!"
    await update.message.reply_text(welcome_message)

# --- Intelligent web search function (slightly enhanced result processing) ---
async def intelligent_web_search(user_message, model, user_id, iteration=0):
    try:
        logging.info(f"Web search baÅŸlatÄ±ldÄ± (Iteration {iteration}): {user_message}, User ID: {user_id}")

        context_messages = user_memory.get_user_settings(user_id).get("messages", [])
        history_text = "\n".join([
            f"{'KullanÄ±cÄ±' if msg['role'] == 'user' else 'Asistan'}: {msg['content']}"
            for msg in context_messages[-5:]
        ])

        query_generation_prompt = f"""
        GÃ¶revin, kullanÄ±cÄ±nÄ±n son mesajÄ±nÄ± ve Ã¶nceki konuÅŸma baÄŸlamÄ±nÄ± dikkate alarak en alakalÄ± web arama sorgularÄ±nÄ± oluÅŸturmak.
        Bu sorgular, derinlemesine araÅŸtÄ±rma yapmak iÃ§in kullanÄ±lacak. EÄŸer kullanÄ±cÄ±nÄ±n son mesajÄ± Ã¶nceki konuÅŸmaya baÄŸlÄ± bir devam sorusu ise,
        baÄŸlamÄ± kullanarak daha eksiksiz ve anlamlÄ± sorgular Ã¼ret.

        Ã–nceki KonuÅŸma BaÄŸlamÄ± (Son 5 Mesaj):
        ```
        {history_text}
        ```

        KullanÄ±cÄ± MesajÄ±: {user_message}

        Kurallar:
        - En fazla 3 sorgu oluÅŸtur.
        - Her sorgu yeni bir satÄ±rda olmalÄ±.
        - Sorgular net ve spesifik olmalÄ±.
        - TÃ¼rkÃ§e dilinde ve gÃ¼ncel bilgi iÃ§ermeli.
        - EÄŸer bu bir derin arama iterasyonu ise, Ã¶nceki arama sonuÃ§larÄ±nÄ± ve kullanÄ±cÄ± mesajÄ±nÄ± dikkate alarak daha spesifik ve derinlemesine sorgular oluÅŸtur.
        - Sadece arama sorgularÄ±nÄ± liste olarak ver. BaÅŸka bir aÃ§Ä±klama veya metin ekleme.

        Ã–nceki sorgular ve sonuÃ§lar (varsa): ... (Åimdilik boÅŸ, iterasyonlar eklendikÃ§e burasÄ± dolacak)
        """
        dusunce_logger.info(f"Sorgu OluÅŸturma Promptu (Iteration {iteration}):\n{query_generation_prompt}", extra={'user_id': user_id})

        try:
            query_response = await asyncio.wait_for(
                model.generate_content_async(query_generation_prompt),
                timeout=10.0
            )
            dusunce_logger.info(f"Sorgu OluÅŸturma CevabÄ± (Gemini, Iteration {iteration}): {query_response.text}", extra={'user_id': user_id})
            logging.info(f"Gemini response received for queries (Iteration {iteration}): {query_response.text}")
        except asyncio.TimeoutError:
            logging.error(f"Gemini API request timed out (Query generation, Iteration {iteration})")
            return "ÃœzgÃ¼nÃ¼m, ÅŸu anda arama yapamÄ±yorum. LÃ¼tfen daha sonra tekrar deneyin.", []
        except Exception as e:
            logging.error(f"Error generating search queries (Iteration {iteration}): {str(e)}")
            return "Arama sorgularÄ±nÄ± oluÅŸtururken bir hata oluÅŸtu.", []

        search_queries = [q.strip() for q in query_response.text.split('\n') if q.strip()]
        dusunce_logger.info(f"OluÅŸturulan Sorgular (Iteration {iteration}): {search_queries}", extra={'user_id': user_id})

        if not search_queries:
            search_queries = [user_message]

        logging.info(f"Generated search queries (Iteration {iteration}): {search_queries}")

        async def perform_single_search(query):
            search_results_for_query = []
            try:
                with DDGS() as ddgs:
                    logging.info(f"DuckDuckGo aramasÄ± yapÄ±lÄ±yor (Iteration {iteration}): {query}")
                    dusunce_logger.info(f"DuckDuckGo Sorgusu (Iteration {iteration}): {query}", extra={'user_id': user_id})
                    results = list(ddgs.text(query, max_results=BOT_CONFIG["search_results_per_query"])) # Configurable result count
                    logging.info(f"Bulunan sonuÃ§ sayÄ±sÄ± (Iteration {iteration}): {len(results)}")
                    dusunce_logger.info(f"DuckDuckGo SonuÃ§ SayÄ±sÄ± (Iteration {iteration}): {len(results)}", extra={'user_id': user_id})
                    search_results_for_query.extend(results)
            except ImportError:
                logging.error("DuckDuckGo search modÃ¼lÃ¼ bulunamadÄ±.")
                return []
            except Exception as search_error: # Fallback search remains the same
                logging.error(f"DuckDuckGo arama hatasÄ± (Iteration {iteration}): {str(search_error)}", exc_info=True)
                dusunce_logger.error(f"DuckDuckGo Arama HatasÄ± (Iteration {iteration}): {str(search_error)}", exc_info=True, extra={'user_id': user_id})
                try:
                    def fallback_search(query):
                        headers = {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                        }
                        search_url = f"https://www.google.com/search?q={query}"
                        response = requests.get(search_url, headers=headers)
                        dusunce_logger.info(f"Fallback Arama Sorgusu (Iteration {iteration}): {query}", extra={'user_id': user_id})

                        if response.status_code == 200:
                            soup = BeautifulSoup(response.text, 'html.parser')
                            search_results_fallback = soup.find_all('div', class_='g')
                            parsed_results = []
                            for result in search_results_fallback[:BOT_CONFIG["search_results_per_query"]]: # Configurable result count
                                title = result.find('h3')
                                link = result.find('a')
                                snippet = result.find('div', class_='VwiC3b')

                                if title and link and snippet:
                                    parsed_results.append({
                                        'title': title.text,
                                        'link': link['href'],
                                        'body': snippet.text
                                    })
                            dusunce_logger.info(f"Fallback Arama SonuÃ§ SayÄ±sÄ± (Iteration {iteration}): {len(parsed_results)}", extra={'user_id': user_id})
                            return parsed_results
                        return []
                    results = fallback_search(query)
                    search_results_for_query.extend(results)
                    logging.info(f"Fallback arama sonuÃ§ sayÄ±sÄ± (Iteration {iteration}): {len(search_results_for_query)}")
                except Exception as fallback_error:
                    logging.error(f"Fallback arama hatasÄ± (Iteration {iteration}): {str(fallback_error)}")
                    dusunce_logger.error(f"Fallback Arama HatasÄ± (Iteration {iteration}): {str(fallback_error)}", extra={'user_id': user_id})
                    return []
            return search_results_for_query

        search_tasks = [perform_single_search(query) for query in search_queries]
        all_results_nested = await asyncio.gather(*search_tasks)

        search_results = []
        for results_list in all_results_nested:
            search_results.extend(results_list)

        logging.info(f"Toplam bulunan arama sonuÃ§ sayÄ±sÄ± (Iteration {iteration}): {len(search_results)}")
        dusunce_logger.info(f"Toplam Arama SonuÃ§ SayÄ±sÄ± (Iteration {iteration}): {len(search_results)}", extra={'user_id': user_id})

        if not search_results:
            return "Arama sonucu bulunamadÄ±. LÃ¼tfen farklÄ± bir ÅŸekilde sormayÄ± deneyin.", []

        # Basic result ranking - prioritize results with query keywords in title
        ranked_results = sorted(search_results, key=lambda res: sum(1 for word in user_message.lower().split() if word in res.get('title', '').lower()), reverse=True)

        search_context = "\n\n".join([ # Using ranked results now
            f"Arama Sonucu {i+1}: {result.get('body', 'Ä°Ã§erik yok')}\nKaynak: {result.get('link', 'BaÄŸlantÄ± yok')}"
            for i, result in enumerate(ranked_results)
        ])
        dusunce_logger.info(f"Arama BaÄŸlamÄ± (Iteration {iteration}):\n{search_context}", extra={'user_id': user_id})

        return search_context, ranked_results # Return ranked results

    except Exception as e:
        logging.error(f"Web arama genel hatasÄ± (Iteration {iteration}): {str(e)}", exc_info=True)
        dusunce_logger.error(f"Web Arama Genel HatasÄ± (Iteration {iteration}): {str(e)}", exc_info=True, extra={'user_id': user_id})
        return f"Web arama hatasÄ±: {str(e)}", []

# --- Perform deep search function (enhanced with ranked results and iteration limit from config) ---
async def perform_deep_search(update: Update, context: ContextTypes.DEFAULT_TYPE, user_message):
    user_id = str(update.effective_user.id)
    user_lang = user_memory.get_user_settings(user_id).get('language', BOT_CONFIG["default_language"]) # Use default from config

    MAX_ITERATIONS = BOT_CONFIG["deep_search_iterations"] # Iteration limit from config
    all_search_results = []
    current_query = user_message
    search_model = genai.GenerativeModel(BOT_CONFIG["gemini_model_name"]) # Use configured model name

    try:
        await context.bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)

        for iteration in range(MAX_ITERATIONS):
            search_context, search_results = await intelligent_web_search(current_query, search_model, user_id, iteration + 1) # Pass model
            if not search_results:
                await update.message.reply_text("Derinlemesine arama yapÄ±ldÄ± ama OwO, anlamlÄ± bir ÅŸey bulamadÄ±m... Belki sorgumu kontrol etmelisin? ğŸ¤” Ya da sonra tekrar deneyebilirsin! ğŸ¥º")
                return

            all_search_results.extend(search_results) # Extend with ranked results

            analysis_prompt = f"""
            GÃ¶revin: Web arama sonuÃ§larÄ±nÄ± analiz ederek daha derinlemesine arama yapmak iÃ§in yeni ve geliÅŸtirilmiÅŸ arama sorgularÄ± Ã¼retmek.
            Bu gÃ¶revi bir dÃ¼ÅŸÃ¼nce zinciri (chain of thoughts) yaklaÅŸÄ±mÄ±yla, adÄ±m adÄ±m dÃ¼ÅŸÃ¼nerek gerÃ§ekleÅŸtir.

            KullanÄ±cÄ± Sorgusu: "{user_message}"
            Mevcut Arama Sorgusu (Iteration {iteration + 1}): "{current_query}"
            Arama SonuÃ§larÄ± (Iteration {iteration + 1}):
            {search_context}

            DÃ¼ÅŸÃ¼nce Zinciri AdÄ±mlarÄ±:
            1. Arama sonuÃ§larÄ±ndaki anahtar noktalarÄ± ve temalarÄ± belirle.
            2. Bu sonuÃ§lardaki bilgi boÅŸluklarÄ±nÄ± veya eksik detaylarÄ± tespit et.
            3. KullanÄ±cÄ±nÄ±n orijinal sorgusunu ve mevcut sonuÃ§larÄ± dikkate alarak, hangi yÃ¶nlerde daha fazla araÅŸtÄ±rma yapÄ±lmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼n.
            4. Daha spesifik, odaklanmÄ±ÅŸ ve derinlemesine arama yapmayÄ± saÄŸlayacak 3 yeni arama sorgusu oluÅŸtur.
            5. Yeni sorgularÄ±n, Ã¶nceki arama sonuÃ§larÄ±nda bulunan bilgiyi nasÄ±l geniÅŸleteceÄŸini ve derinleÅŸtireceÄŸini aÃ§Ä±kla.

            LÃ¼tfen dÃ¼ÅŸÃ¼nce sÃ¼recini adÄ±m adÄ±m gÃ¶ster ve sonunda net arama sorgularÄ±nÄ± listele:
            5. Sadece yeni arama sorgularÄ±nÄ± (3 tane), her birini yeni bir satÄ±ra yaz. BaÅŸka bir aÃ§Ä±klama veya metin ekleme.
            6. TÃ¼rkÃ§e sorgular oluÅŸtur.
            """
            dusunce_logger.info(f"Sorgu Ä°yileÅŸtirme Promptu (Iteration {iteration + 1}):\n{analysis_prompt}", extra={'user_id': user_id})

            try:
                query_refinement_response = await search_model.generate_content_async(analysis_prompt) # Use search model
                dusunce_logger.info(f"Sorgu Ä°yileÅŸtirme CevabÄ± (Gemini, Iteration {iteration + 1}): {query_refinement_response.text}", extra={'user_id': user_id})

                refined_queries = [q.strip() for q in query_refinement_response.text.split('\n') if q.strip()][:3]
                if refined_queries:
                    current_query = " ".join(refined_queries)
                    logging.info(f"Refined queries for iteration {iteration + 2}: {refined_queries}")
                    dusunce_logger.info(f"Ä°yileÅŸtirilmiÅŸ Sorgular (Iteration {iteration + 2}): {refined_queries}", extra={'user_id': user_id})
                else:
                    logging.info(f"No refined queries generated in iteration {iteration + 1}, stopping deep search.")
                    dusunce_logger.info(f"Ä°yileÅŸtirilmiÅŸ Sorgu OluÅŸturulamadÄ± (Iteration {iteration + 1}), derin arama durduruluyor.", extra={'user_id': user_id})
                    break
            except Exception as refine_error:
                logging.error(f"Error during query refinement (Iteration {iteration + 1}): {refine_error}")
                dusunce_logger.error(f"Sorgu Ä°yileÅŸtirme HatasÄ± (Iteration {iteration + 1}): {refine_error}", extra={'user_id': user_id})
                logging.info("Stopping deep search due to query refinement error.")
                dusunce_logger.info("Sorgu iyileÅŸtirme hatasÄ± nedeniyle derin arama durduruluyor.", extra={'user_id': user_id})
                break

        if all_search_results:
            final_prompt = f"""
            GÃ¶revin: Derinlemesine web aramasÄ± sonuÃ§larÄ±nÄ± kullanarak kullanÄ±cÄ±ya kapsamlÄ± ve bilgilendirici bir cevap oluÅŸturmak.
            Bu gÃ¶revi bir dÃ¼ÅŸÃ¼nce zinciri (chain of thoughts) yaklaÅŸÄ±mÄ±yla, adÄ±m adÄ±m dÃ¼ÅŸÃ¼nerek gerÃ§ekleÅŸtir.

            KullanÄ±cÄ± Sorgusu: "{user_message}"
            TÃ¼m Arama SonuÃ§larÄ±:
            {''.join([f'Iteration {i+1} Results:\n' + '\\n'.join([f"Arama Sonucu {j+1}: {res.get('body', 'Ä°Ã§erik yok')}\\nKaynak: {res.get('link', 'BaÄŸlantÄ± yok')}" for j, res in enumerate(all_search_results[i*BOT_CONFIG["search_results_per_query"]:(i+1)*BOT_CONFIG["search_results_per_query"]])]) + '\\n\\n' for i in range(MAX_ITERATIONS)])}

            DÃ¼ÅŸÃ¼nce Zinciri AdÄ±mlarÄ±:
            1. TÃ¼m arama sonuÃ§larÄ±nÄ± analiz et ve ana temalarÄ± belirle.
            2. KullanÄ±cÄ±nÄ±n orijinal sorgusunu derinlemesine anlamaya Ã§alÄ±ÅŸ.
            3. Arama sonuÃ§larÄ±ndaki en alakalÄ± ve gÃ¼venilir bilgileri tespit et.
            4. Bu bilgileri nasÄ±l sentezleyeceÄŸini ve organize edeceÄŸini dÃ¼ÅŸÃ¼n.
            5. Ã‡eliÅŸkili bilgiler varsa, bunlarÄ± nasÄ±l deÄŸerlendireceÄŸini ve sunacaÄŸÄ±nÄ± planla.
            6. Eksik bilgiler veya belirsizlikler varsa, bunlarÄ± nasÄ±l ele alacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼n.
            7. TÃ¼m bu dÃ¼ÅŸÃ¼nceleri kullanarak kapsamlÄ± bir yanÄ±t oluÅŸtur.

            LÃ¼tfen dÃ¼ÅŸÃ¼nce sÃ¼recini adÄ±m adÄ±m gÃ¶ster ve sonunda ÅŸu kurallara uygun bir cevap oluÅŸtur:
            - Ã–nemli baÄŸlantÄ±larÄ± ve kaynaklarÄ± cevap iÃ§inde belirt.
            - CevabÄ± {user_lang} dilinde yaz ve samimi bir dil kullan.
            - CevabÄ± madde iÅŸaretleri veya numaralandÄ±rma kullanarak dÃ¼zenli ve okunabilir hale getir.
            - Sadece dÃ¼z metin olarak cevap ver. JSON veya baÅŸka formatlama kullanma.
            """
            dusunce_logger.info(f"Final Chain of Thoughts Promptu:\n{final_prompt}", extra={'user_id': user_id})

            try:
                final_cot_response = await search_model.generate_content_async(final_prompt) # Use search model
                dusunce_logger.info(f"Final Chain of Thoughts Cevap (Gemini): {final_cot_response.text}", extra={'user_id': user_id})

                clean_final_prompt = f"""
                GÃ¶revin: AÅŸaÄŸÄ±daki dÃ¼ÅŸÃ¼nce zincirini (chain of thoughts) kullanarak kullanÄ±cÄ±ya verilecek net ve kapsamlÄ± bir yanÄ±t oluÅŸturmak.
                DÃ¼ÅŸÃ¼nce sÃ¼recini ASLA dahil etme, sadece final cevabÄ± ver.

                KullanÄ±cÄ± Sorgusu: {user_message}

                DÃ¼ÅŸÃ¼nce Zinciri:
                {final_cot_response.text}

                YanÄ±tÄ±nÄ± {user_lang} dilinde ver ve sadece net ve kapsamlÄ± cevabÄ± oluÅŸtur:
                """

                dusunce_logger.info(f"Temiz Final YanÄ±t Promptu:\n{clean_final_prompt}", extra={'user_id': user_id})
                final_response = await search_model.generate_content_async(clean_final_prompt) # Use search model
                dusunce_logger.info(f"Final Temiz Cevap (Gemini): {final_response.text}", extra={'user_id': user_id})

                if final_response.prompt_feedback and final_response.prompt_feedback.block_reason:
                    block_reason = final_response.prompt_feedback.block_reason
                    logger.warning(f"Deep search final response blocked. Reason: {block_reason}")
                    dusunce_logger.warning(f"Derin arama final cevabÄ± engellendi. Sebep: {block_reason}", extra={'user_id': user_id})
                    error_message = get_error_message('blocked_prompt', user_lang)
                    await update.message.reply_text(error_message)
                else:
                    response_text = final_response.text if hasattr(final_response, 'text') else final_response.candidates[0].content.parts[0].text
                    response_text = await add_emojis_to_text(response_text, user_id)
                    await split_and_send_message(update, response_text)

                    user_memory.add_message(user_id, "user", f"/derinarama {user_message}")
                    user_memory.add_message(user_id, "assistant", response_text)

            except Exception as final_response_error:
                logging.error(f"Error generating final response for deep search: {final_response_error}")
                dusunce_logger.error(f"Final Cevap OluÅŸturma HatasÄ± (Derin Arama): {final_response_error}", extra={'user_id': user_id})
                await update.message.reply_text(get_error_message('ai_error', user_lang))
        else:
            await update.message.reply_text("Derinlemesine arama yapÄ±ldÄ± ama OwO, anlamlÄ± bir ÅŸey bulamadÄ±m... Belki sorgumu kontrol etmelisin? ğŸ¤” Ya da sonra tekrar deneyebilirsin! ğŸ¥º")

    except Exception as deep_search_error:
        logging.error(f"Error during deep search process: {deep_search_error}", exc_info=True)
        dusunce_logger.error(f"Derin Arama SÃ¼reci HatasÄ±: {deep_search_error}", exc_info=True, extra={'user_id': user_id})
        await update.message.reply_text(get_error_message('general', user_lang))
    finally:
        await context.bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)

# --- Command handlers for emoji preferences (no change) ---
async def set_emoji_auto(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    user_memory.update_user_settings(user_id, {'preferences': {'emoji_preference': 'auto'}})
    await update.message.reply_text("Emoji kullanÄ±mÄ± otomatik moda ayarlandÄ±. Bot, mesajlarÄ±na gÃ¶re emojileri ayarlayacak. ğŸ¤–")

async def set_emoji_high(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    user_memory.update_user_settings(user_id, {'preferences': {'emoji_preference': 'high'}})
    await update.message.reply_text("Emoji kullanÄ±mÄ± yÃ¼ksek moda ayarlandÄ±. Bot, mesajlarÄ±nda daha Ã§ok emoji kullanacak. ğŸ‰")

async def set_emoji_low(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    user_memory.update_user_settings(user_id, {'preferences': {'emoji_preference': 'low'}})
    await update.message.reply_text("Emoji kullanÄ±mÄ± dÃ¼ÅŸÃ¼k moda ayarlandÄ±. Bot, mesajlarÄ±nda daha az emoji kullanacak. ğŸ¤")

async def set_emoji_none(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    user_memory.update_user_settings(user_id, {'preferences': {'emoji_preference': 'none'}})
    await update.message.reply_text("Emoji kullanÄ±mÄ± kapalÄ± moda ayarlandÄ±. Bot, mesajlarÄ±nda emoji kullanmayacak. ğŸš«")

# --- Handle message function (typing indicator delay from config) ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    dusunce_logger.info("Mesaj iÅŸleme fonksiyonuna girildi.", extra={'user_id': user_id})

    try:
        if not update or not update.message:
            logger.error("Invalid update object or message")
            dusunce_logger.error("GeÃ§ersiz update veya mesaj objesi.", extra={'user_id': user_id})
            return

        logger.info(f"Message received: {update.message}")
        logger.info(f"Message text: {update.message.text}")
        dusunce_logger.info(f"Mesaj alÄ±ndÄ±: {update.message}", extra={'user_id': user_id})
        dusunce_logger.info(f"Mesaj metni: {update.message.text}", extra={'user_id': user_id})

        if update.message.text and not update.message.text.startswith('/'):
            message_text = update.message.text.strip()
            user_lang = await detect_and_set_user_language(message_text, user_id)
            logger.info(f"Detected language: {user_lang}")
            dusunce_logger.info(f"Tespit edilen dil: {user_lang}", extra={'user_id': user_id})
        else:
            user_lang = user_memory.get_user_settings(user_id).get('language', BOT_CONFIG["default_language"]) # Use default from config

        if update.message.text and update.message.text.startswith('/derinarama'):
            query = update.message.text[len('/derinarama'):].strip()
            if not query:
                await update.message.reply_text("Derin arama iÃ§in bir sorgu girmelisin! ğŸ¥º Ã–rnek: `/derinarama TÃ¼rkiye'deki antik kentler`")
                return
            await perform_deep_search(update, context, query)
            return
        if update.message.text and update.message.text.startswith('/emoji_'): # Emoji commands
            return # Emoji commands are handled by their respective handlers

        if update.message.text and not update.message.text.startswith('/'):
            message_text = update.message.text.strip()
            logger.info(f"Processed message text: {message_text}")
            dusunce_logger.info(f"Ä°ÅŸlenen mesaj metni: {message_text}", extra={'user_id': user_id})

            async def show_typing():
                while True:
                    try:
                        await context.bot.send_chat_action(
                            chat_id=update.message.chat_id,
                            action=ChatAction.TYPING
                        )
                        await asyncio.sleep(BOT_CONFIG["typing_indicator_delay"]) # Typing indicator delay from config
                    except Exception as e:
                        logger.error(f"Error in typing indicator: {e}")
                        dusunce_logger.error(f"YazÄ±yor gÃ¶stergesi hatasÄ±: {e}", extra={'user_id': user_id})
                        break

            typing_task = asyncio.create_task(show_typing())

            try:
                MAX_RETRIES = 3 # Reduced retries, token limit error handling improved
                retry_count = 0
                context_messages = []

                while retry_count < MAX_RETRIES:
                    try:
                        context_messages = user_memory.get_relevant_context(user_id)
                        user_settings = user_memory.get_user_settings(user_id)
                        personality_profile = user_settings.get('personality_profile')

                        personality_context = get_time_aware_personality(
                            datetime.now(),
                            user_lang,
                            user_settings.get('preferences', {}).get('timezone', 'Europe/Istanbul'), # Safe access
                            personality_profile
                        )

                        ai_prompt = f"""{personality_context}

                        GÃ¶revin: KullanÄ±cÄ±nÄ±n mesajÄ±na cevap vermek, ama Ã¶nce bir dÃ¼ÅŸÃ¼nce zinciri (chain of thoughts) oluÅŸturarak adÄ±m adÄ±m dÃ¼ÅŸÃ¼nmek! ğŸ¤”ğŸ’­

                        Ã–nceki KonuÅŸma BaÄŸlamÄ±:
                        {context_messages}

                        KullanÄ±cÄ± MesajÄ±: {message_text}

                        LÃ¼tfen aÅŸaÄŸÄ±daki adÄ±mlarÄ± izle UwU:
                        1. KullanÄ±cÄ±nÄ±n ne sorduÄŸunu veya ne istediÄŸini ANALÄ°Z ET! ğŸ§
                        2. Konuyla ilgili BÄ°LGÄ°LERÄ°NÄ° GÃ–ZDEN GEÃ‡Ä°R! ğŸ§ 
                        3. OlasÄ± CEVAP YOLLARINI DÃœÅÃœN! ğŸ¤”
                        4. En doÄŸru ve yararlÄ± CEVABI SEÃ‡! ğŸ‘
                        5. CevabÄ±nÄ± NET ve ANLAÅILIR bir ÅŸekilde oluÅŸtur! ğŸ“âœ¨

                        DÃ¼ÅŸÃ¼nce Zinciri (Chain of Thoughts):
                        """
                        dusunce_logger.info(f"AI Prompt (Chain of Thoughts):\n{ai_prompt}", extra={'user_id': user_id})

                        try:
                            ai_model = genai.GenerativeModel(BOT_CONFIG["gemini_model_name"]) # Use configured model name
                            web_search_response, _ = await intelligent_web_search(message_text, ai_model, user_id) # Pass model

                            if web_search_response and len(web_search_response.strip()) > 10:
                                ai_prompt += f"\n\nEk Bilgi (Web Arama SonuÃ§larÄ± - SADECE DÄ°REKT SONUÃ‡LARI KULLAN):\n{web_search_response}"
                                dusunce_logger.info(f"AI Prompt (Web AramalÄ±):\n{ai_prompt}", extra={'user_id': user_id})

                            dusunce_logger.info("Gemini'den chain of thoughts cevabÄ± bekleniyor... ğŸ’«", extra={'user_id': user_id})
                            response = await asyncio.wait_for(ai_model.generate_content_async( # Use ai_model and timeout
                                ai_prompt,
                                generation_config={
                                    "temperature": 0.7,
                                    "top_p": 0.8,
                                    "top_k": 40
                                }
                            ), timeout=30.0) # Added timeout to Gemini response

                            dusunce_logger.info(f"Gemini Chain of Thoughts CevabÄ±: {response.text}", extra={'user_id': user_id})

                            if response.prompt_feedback and response.prompt_feedback.block_reason:
                                block_reason = response.prompt_feedback.block_reason
                                logger.warning(f"Prompt blocked for regular message. Reason: {block_reason}")
                                dusunce_logger.warning(f"Normal mesaj iÃ§in prompt engellendi. Sebep: {block_reason}", extra={'user_id': user_id})
                                error_message = get_error_message('blocked_prompt', user_lang)
                                await update.message.reply_text(error_message)
                                break
                            else:
                                full_response = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text
                                dusunce_logger.info(f"Tam Chain of Thoughts yanÄ±tÄ±: {full_response}", extra={'user_id': user_id})

                                clean_response_prompt = f"""${personality_context}

                                GÃ¶revin: AÅŸaÄŸÄ±daki dÃ¼ÅŸÃ¼nce zincirini (chain of thoughts) kullanarak kullanÄ±cÄ±ya verilecek NET ve SADE bir yanÄ±t oluÅŸturmak! Ama dÃ¼ÅŸÃ¼nce sÃ¼recini SAKIN dahil etme! ğŸ™…â€â™€ï¸ Sadece final cevabÄ± ver! ğŸ˜‰

                                DÃ¼ÅŸÃ¼nce Zinciri:
                                {full_response}

                                KullanÄ±cÄ± MesajÄ±: {message_text}

                                Sadece net ve sade cevabÄ± ver:"""

                                dusunce_logger.info(f"Temiz yanÄ±t promptu: {clean_response_prompt}", extra={'user_id': user_id})
                                clean_response = await ai_model.generate_content_async(clean_response_prompt) # Use ai_model
                                response_text = clean_response.text if hasattr(clean_response, 'text') else clean_response.candidates[0].content.parts[0].text
                                dusunce_logger.info(f"Temiz yanÄ±t: {response_text}", extra={'user_id': user_id})

                                response_text = await add_emojis_to_text(response_text, user_id)
                                await split_and_send_message(update, response_text.strip())

                                user_memory.add_message(user_id, "user", message_text)
                                user_memory.add_message(user_id, "assistant", response_text)
                                break # Success, break retry loop

                        except asyncio.TimeoutError: # Handle Gemini API timeout
                            logger.warning("Gemini API timed out during message processing.")
                            dusunce_logger.warning("Gemini API mesaj iÅŸleme sÄ±rasÄ±nda zaman aÅŸÄ±mÄ±na uÄŸradÄ±.", extra={'user_id': user_id})
                            error_message = get_error_message('ai_error', user_lang) # Or a more specific timeout error message
                            await update.message.reply_text(error_message)
                            break # Break retry loop after timeout

                        except Exception as search_error: # Token limit handling - improved
                            if "Token limit exceeded" in str(search_error):
                                user_memory.trim_context(user_id) # Trim context directly using DB aware function
                                retry_count += 1
                                logger.warning(f"Token limit exceeded, retrying {retry_count}/{MAX_RETRIES}")
                                dusunce_logger.warning(f"Token limiti aÅŸÄ±ldÄ±, tekrar deneniyor {retry_count}/{MAX_RETRIES}", extra={'user_id': user_id})

                                if retry_count % 1 == 0: # Less frequent token limit messages
                                    await update.message.reply_text(f"ğŸ”„ Ay ay ay! KonuÅŸma Ã§ok uzun! Biraz hafÄ±zayÄ± temizliyorum... ({retry_count}. deneme) ğŸ¥º")

                                if retry_count == MAX_RETRIES: # Max retries reached for token limit
                                    error_message = get_error_message('token_limit', user_lang)
                                    await update.message.reply_text(error_message)
                                    break # Break retry loop after max token retries
                            else:
                                raise search_error # Re-raise other errors

                    except Exception as context_error: # Context retrieval error handling
                        logger.error(f"Context retrieval error: {context_error}")
                        dusunce_logger.error(f"Kontekst alma hatasÄ±: {context_error}", extra={'user_id': user_id})
                        retry_count += 1
                        if retry_count == MAX_RETRIES: # Max retries reached for context error
                            error_message = get_error_message('general', user_lang)
                            await update.message.reply_text(error_message)
                            break # Break retry loop after max context retries

                if retry_count == MAX_RETRIES: # Max retries reached overall
                    logger.error("Max retries reached for message processing.")
                    dusunce_logger.error("Mesaj iÅŸleme iÃ§in maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±.", extra={'user_id': user_id})
                    error_message = get_error_message('max_retries', user_lang)
                    await update.message.reply_text(error_message)

            except Exception as e: # General message processing error handling
                logger.error(f"Message processing error: {e}")
                dusunce_logger.error(f"Mesaj iÅŸleme hatasÄ±: {e}", extra={'user_id': user_id})
                error_message = get_error_message('general', user_lang)
                await update.message.reply_text(error_message)

            finally:
                typing_task.cancel() # Cancel typing task in finally block

        elif update.message.photo: # Image and video handlers remain the same
            await handle_image(update, context)
        elif update.message.video:
            await handle_video(update, context)
        else: # Unhandled message type
            logger.warning("Unhandled message type received")
            dusunce_logger.warning("Ä°ÅŸlenemeyen mesaj tÃ¼rÃ¼ alÄ±ndÄ±.", extra={'user_id': user_id})
            user_lang = user_memory.get_user_settings(user_id).get('language', BOT_CONFIG["default_language"]) # Use default from config
            unhandled_message = get_error_message('unhandled', user_lang)
            await update.message.reply_text(unhandled_message)

    except Exception as e: # General error handling for handle_message
        logger.error(f"General error in handle_message: {e}")
        dusunce_logger.error(f"Genel hata handle_message iÃ§inde: {e}", extra={'user_id': user_id})
        user_lang = user_memory.get_user_settings(user_id).get('language', BOT_CONFIG["default_language"]) # Use default from config
        error_message = get_error_message('general', user_lang)
        await update.message.reply_text(error_message)
    except SyntaxError as e: # Syntax error handling
        logger.error(f"Syntax error in handle_message: {e}")
        dusunce_logger.error(f"Syntax error handle_message iÃ§inde: {e}", extra={'user_id': user_id})
        user_lang = user_memory.get_user_settings(user_id).get('language', BOT_CONFIG["default_language"]) # Use default from config
        error_message = get_error_message('general', user_lang)
        await update.message.reply_text(error_message)

# --- Image and Video handlers (same as before, model name from config) ---
async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)

    try:
        logger.info(f"Starting image processing for user {user_id}")
        dusunce_logger.info(f"Resim iÅŸleme baÅŸlatÄ±lÄ±yor. KullanÄ±cÄ± ID: {user_id}", extra={'user_id': user_id})

        if not update.message:
            logger.warning("No message found in update")
            await update.message.reply_text("A-aa! Mesaj kayÄ±p! ğŸ¥º LÃ¼tfen tekrar dener misin?")
            dusunce_logger.warning("Update iÃ§inde mesaj bulunamadÄ±.", extra={'user_id': user_id})
            return

        user_settings = user_memory.get_user_settings(user_id)
        user_lang = user_settings.get('language', BOT_CONFIG["default_language"]) # Use default from config
        logger.info(f"User language: {user_lang}")
        dusunce_logger.info(f"KullanÄ±cÄ± dili: {user_lang}", extra={'user_id': user_id})

        if not update.message.photo:
            logger.warning("No photo found in the message")
            await update.message.reply_text("Resim de kayÄ±p! ğŸ˜­ Tekrar gÃ¶nderebilir misin lÃ¼tfen?")
            dusunce_logger.warning("Mesajda fotoÄŸraf bulunamadÄ±.", extra={'user_id': user_id})
            return

        try:
            photo = max(update.message.photo, key=lambda x: x.file_size)
        except Exception as photo_error:
            logger.error(f"Error selecting photo: {photo_error}")
            await update.message.reply_text("Resmi seÃ§erken bir sorun oldu! ğŸ¤¯ Belki tekrar denemelisin?")
            dusunce_logger.error(f"FotoÄŸraf seÃ§imi hatasÄ±: {photo_error}", extra={'user_id': user_id})
            return

        try:
            photo_file = await context.bot.get_file(photo.file_id)
            photo_bytes = bytes(await photo_file.download_as_bytearray())
        except Exception as download_error:
            logger.error(f"Photo download error: {download_error}")
            await update.message.reply_text("Resmi indiremedim! ğŸ¥º Ä°nternet baÄŸlantÄ±nÄ± kontrol eder misin?")
            dusunce_logger.error(f"FotoÄŸraf indirme hatasÄ±: {download_error}", extra={'user_id': user_id})
            return

        logger.info(f"Photo bytes downloaded: {len(photo_bytes)} bytes")
        dusunce_logger.info(f"FotoÄŸraf indirildi. Boyut: {len(photo_bytes)} bytes", extra={'user_id': user_id})

        caption = update.message.caption
        logger.info(f"Original caption: {caption}")
        dusunce_logger.info(f"Orijinal baÅŸlÄ±k: {caption}", extra={'user_id': user_id})

        default_prompt = get_analysis_prompt('image', None, user_lang)
        logger.info(f"Default prompt: {default_prompt}")
        dusunce_logger.info(f"VarsayÄ±lan prompt: {default_prompt}", extra={'user_id': user_id})

        if caption is None:
            caption = default_prompt or "Bu resmi detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla."

        caption = str(caption).strip()
        logger.info(f"Final processed caption: {caption}")
        dusunce_logger.info(f"Son iÅŸlenmiÅŸ baÅŸlÄ±k: {caption}", extra={'user_id': user_id})

        personality_context = get_time_aware_personality(
            datetime.now(),
            user_lang,
            user_settings.get('preferences', {}).get('timezone', 'Europe/Istanbul'), # Safe access
            user_settings.get('personality_profile')
        )

        if not personality_context:
            personality_context = "Sen Nyxie'sin ve resimleri analiz ediyorsun."

        analysis_prompt = f"""DÄ°KKAT: BU ANALÄ°ZÄ° TÃœRKÃ‡E YAPACAKSIN! SADECE TÃœRKÃ‡E KULLAN! KESÄ°NLÄ°KLE BAÅKA DÄ°L KULLANMA!

        {personality_context}

        GÃ¶revin: KullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi gÃ¶rseli analiz ederek sadece dÃ¼z metin bir aÃ§Ä±klama sunmak.
        Rol: Sen Nyxie'sin ve bu gÃ¶rseli TÃ¼rkÃ§e olarak aÃ§Ä±klÄ±yorsun.

        YÃ¶nergeler:

        SADECE TÃœRKÃ‡E KULLAN! ğŸ‡¹ğŸ‡·ğŸ’¯

        GÃ¶rseldeki metinleri (varsa) orijinal dilinde bÄ±rak, Ã§evirme! ğŸš«âœï¸

        Analizini yaparken NAZÄ°K ve YARDIMSEVER bir ton kullan! ğŸ¥°ğŸ’–

        KÃ¼ltÃ¼rel DUYARLILIÄA dikkat et! ğŸŒğŸ•Šï¸
        5. Sadece dÃ¼z metin cevap ver. JSON veya baÅŸka format kullanma. ğŸš«ğŸ“¦

        LÃ¼tfen analiz et ve sadece dÃ¼z metin olarak Ã¶zetle:

        GÃ¶rseldeki ANA Ã–ÄELERÄ° ve KONULARI tanÄ±mla! ğŸ”ğŸ‘€

        Aktiviteler veya OLAYLAR varsa, bunlarÄ± aÃ§Ä±kla! ğŸï¸ğŸ‰

        GÃ¶rselin GENEL ATMOSFERÄ°NÄ° ve olasÄ± DUYGUSAL ETKÄ°SÄ°NÄ° deÄŸerlendir! ğŸ˜ŒğŸ¤”

        GÃ¶rselde METÄ°N varsa, bunlarÄ± belirt (Ã§evirme yapma)! ğŸ“ğŸ“¢

        KullanÄ±cÄ±nÄ±n isteÄŸi (varsa): {caption}"""
        dusunce_logger.info(f"Resim Analiz Promptu:\n{analysis_prompt}", extra={'user_id': user_id})

        try:
            image_model = genai.GenerativeModel(BOT_CONFIG["gemini_model_name"]) # Use configured model name
            dusunce_logger.info(f"Gemini'ye resim analizi isteÄŸi gÃ¶nderiliyor... ğŸš€ğŸŒŒ", extra={'user_id': user_id})
            response = await asyncio.wait_for(image_model.generate_content_async( # Use image_model and timeout
                [analysis_prompt, {"mime_type": "image/jpeg", "data": photo_bytes}],
                timeout=60.0 # Added timeout for image analysis
            ), timeout=60.0)

            dusunce_logger.info(f"Resim Analizi CevabÄ± (Gemini): {response.text}", extra={'user_id': user_id})

            if response.prompt_feedback and response.prompt_feedback.block_reason:
                block_reason = response.prompt_feedback.block_reason
                logger.warning(f"Prompt blocked for image analysis. Reason: {block_reason}")
                dusunce_logger.warning(f"Resim analizi iÃ§in prompt engellendi. Sebep: {block_reason}", extra={'user_id': user_id})
                error_message = get_error_message('blocked_prompt', user_lang)
                await update.message.reply_text(error_message)
            else:
                response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text
                response_text = await add_emojis_to_text(response_text, user_id)
                user_memory.add_message(user_id, "user", f"[Image] {caption}")
                user_memory.add_message(user_id, "assistant", response_text)
                await split_and_send_message(update, response_text.strip())

        except asyncio.TimeoutError: # Handle timeout for image analysis
            logger.warning("Gemini API timed out during image analysis.")
            dusunce_logger.warning("Gemini API resim analizi sÄ±rasÄ±nda zaman aÅŸÄ±mÄ±na uÄŸradÄ±.", extra={'user_id': user_id})
            error_message = get_error_message('ai_error', user_lang) # Or a more specific timeout error
            await update.message.reply_text(error_message)

        except Exception as processing_error: # Image processing error handling
            logger.error(f"GÃ¶rsel iÅŸleme hatasÄ±: {processing_error}", exc_info=True)
            dusunce_logger.error(f"GÃ¶rsel iÅŸleme hatasÄ±: {processing_error}", exc_info=True, extra={'user_id': user_id})
            error_message = get_error_message('ai_error', user_lang)
            await update.message.reply_text(error_message)

    except Exception as critical_error: # Critical image processing error handling
        logger.error(f"Kritik gÃ¶rsel iÅŸleme hatasÄ±: {critical_error}", exc_info=True)
        dusunce_logger.error(f"Kritik gÃ¶rsel iÅŸleme hatasÄ±: {critical_error}", exc_info=True, extra={'user_id': user_id})
        await update.message.reply_text(get_error_message('general', user_lang))

async def handle_video(update: Update, context: ContextTypes.DEFAULT_TYPE): # Video handler - similar to image, model name from config, timeouts added
    user_id = str(update.effective_user.id)

    try:
        logger.info(f"Starting video processing for user {user_id}")
        dusunce_logger.info(f"Video iÅŸleme baÅŸlatÄ±lÄ±yor. KullanÄ±cÄ± ID: {user_id}", extra={'user_id': user_id})

        if not update.message:
            logger.warning("No message found in update")
            await update.message.reply_text("A-aa! Mesaj kayÄ±p! ğŸ¥º LÃ¼tfen tekrar dener misin?")
            dusunce_logger.warning("Update iÃ§inde mesaj bulunamadÄ±.", extra={'user_id': user_id})
            return

        user_settings = user_memory.get_user_settings(user_id)
        user_lang = user_settings.get('language', BOT_CONFIG["default_language"]) # Use default from config
        logger.info(f"User language: {user_lang}")
        dusunce_logger.info(f"KullanÄ±cÄ± dili: {user_lang}", extra={'user_id': user_id})

        if not update.message.video:
            logger.warning("No video found in the message")
            await update.message.reply_text("Video da kayÄ±p! ğŸ˜­ Tekrar gÃ¶nderebilir misin lÃ¼tfen?")
            dusunce_logger.warning("Mesajda video bulunamadÄ±.", extra={'user_id': user_id})
            return

        video = update.message.video
        if not video:
            logger.warning("No video found in the message")
            await update.message.reply_text("Video da kayÄ±p! ğŸ˜­ Tekrar gÃ¶nderebilir misin lÃ¼tfen?")
            dusunce_logger.warning("Mesajda video objesi bulunamadÄ±.", extra={'user_id': user_id})
            return

        video_file = await context.bot.get_file(video.file_id)
        video_bytes = bytes(await video_file.download_as_bytearray())
        logger.info(f"Video bytes downloaded: {len(video_bytes)} bytes")
        dusunce_logger.info(f"Video indirildi. Boyut: {len(video_bytes)} bytes", extra={'user_id': user_id})

        caption = update.message.caption
        logger.info(f"Original caption: {caption}")
        dusunce_logger.info(f"Orijinal baÅŸlÄ±k: {caption}", extra={'user_id': user_id})

        default_prompt = get_analysis_prompt('video', None, user_lang)
        logger.info(f"Default prompt: {default_prompt}")
        dusunce_logger.info(f"VarsayÄ±lan prompt: {default_prompt}", extra={'user_id': user_id})

        if caption is None:
            caption = default_prompt or "Bu videoyu detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla."

        caption = str(caption).strip()
        logger.info(f"Final processed caption: {caption}")
        dusunce_logger.info(f"Son iÅŸlenmiÅŸ baÅŸlÄ±k: {caption}", extra={'user_id': user_id})

        personality_context = get_time_aware_personality(
            datetime.now(),
            user_lang,
            user_settings.get('preferences', {}).get('timezone', 'Europe/Istanbul'), # Safe access
            user_settings.get('personality_profile')
        )

        if not personality_context:
            personality_context = "Sen Nyxie'sin ve videolarÄ± analiz ediyorsun."

        analysis_prompt = f"""DÄ°KKAT: BU ANALÄ°ZÄ° TÃœRKÃ‡E YAPACAKSIN! SADECE TÃœRKÃ‡E KULLAN! KESÄ°NLÄ°KLE BAÅKA DÄ°L KULLANMA!

        {personality_context}

        GÃ¶revin: KullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi videoyu analiz ederek sadece dÃ¼z metin bir aÃ§Ä±klama sunmak.
        Rol: Sen Nyxie'sin ve bu videoyu TÃ¼rkÃ§e olarak aÃ§Ä±klÄ±yorsun.

        YÃ¶nergeler:

        SADECE TÃœRKÃ‡E KULLAN! ğŸ‡¹ğŸ‡·ğŸ’¯

        Videodaki konuÅŸma veya metinleri (varsa) orijinal dilinde bÄ±rak, Ã§evirme! ğŸš«âœï¸

        Analizini yaparken NAZÄ°K ve YARDIMSEVER bir ton kullan! ğŸ¥°ğŸ’–

        KÃ¼ltÃ¼rel DUYARLILIÄA dikkat et! ğŸŒğŸ•Šï¸
        5. Sadece dÃ¼z metin cevap ver. JSON veya baÅŸka format kullanma. ğŸš«ğŸ“¦

        LÃ¼tfen analiz et ve sadece dÃ¼z metin olarak Ã¶zetle:

        Videodaki ANA OLAYLARI ve EYLEMLERÄ° tanÄ±mla! ğŸ”ğŸ¬

        Ã–nemli Ä°NSANLAR veya NESNELER varsa, bunlarÄ± belirt! ğŸ§‘â€ğŸ¤â€ğŸ§‘ğŸ“¦

        Videodaki SESLERÄ° ve KONUÅMALARI (varsa) analiz et! ğŸ§ğŸ—£ï¸

        Videonun GENEL ATMOSFERÄ°NÄ° ve olasÄ± DUYGUSAL ETKÄ°SÄ°NÄ° deÄŸerlendir! ğŸ˜ŒğŸ¤”

        Videoda METÄ°N varsa, bunlarÄ± belirt (Ã§evirme yapma)! ğŸ“ğŸ“¢

        KullanÄ±cÄ±nÄ±n isteÄŸi (varsa): {caption}"""
        dusunce_logger.info(f"Video Analiz Promptu:\n{analysis_prompt}", extra={'user_id': user_id})

        try:
            video_model = genai.GenerativeModel(BOT_CONFIG["gemini_model_name"]) # Use configured model name
            dusunce_logger.info(f"Gemini'ye video analizi isteÄŸi gÃ¶nderiliyor... ğŸš€ğŸŒŒ", extra={'user_id': user_id})
            response = await asyncio.wait_for(video_model.generate_content_async( # Use video_model and timeout
                [analysis_prompt, {"mime_type": "video/mp4", "data": video_bytes}],
                timeout=90.0 # Added timeout for video analysis, longer than image
            ), timeout=90.0)

            dusunce_logger.info(f"Video Analizi CevabÄ± (Gemini): {response.text}", extra={'user_id': user_id})

            if response.prompt_feedback and response.prompt_feedback.block_reason:
                block_reason = response.prompt_feedback.block_reason
                logger.warning(f"Prompt blocked for video analysis. Reason: {block_reason}")
                dusunce_logger.warning(f"Video analizi iÃ§in prompt engellendi. Sebep: {block_reason}", extra={'user_id': user_id})
                error_message = get_error_message('blocked_prompt', user_lang)
                await update.message.reply_text(error_message)
            else:
                response_text = response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text
                response_text = await add_emojis_to_text(response_text, user_id)
                user_memory.add_message(user_id, "user", f"[Video] {caption}")
                user_memory.add_message(user_id, "assistant", response_text)
                await split_and_send_message(update, response_text.strip())

        except asyncio.TimeoutError: # Handle timeout for video analysis
            logger.warning("Gemini API timed out during video analysis.")
            dusunce_logger.warning("Gemini API video analizi sÄ±rasÄ±nda zaman aÅŸÄ±mÄ±na uÄŸradÄ±.", extra={'user_id': user_id})
            error_message = get_error_message('ai_error', user_lang) # Or more specific timeout error
            await update.message.reply_text(error_message)

        except Exception as processing_error: # Video processing error handling
            logger.error(f"Video processing error: {processing_error}", exc_info=True)
            dusunce_logger.error(f"Video iÅŸleme hatasÄ±: {processing_error}", exc_info=True, extra={'user_id': user_id})
            error_message = get_error_message('ai_error', user_lang)
            await update.message.reply_text(error_message)

    except Exception as e: # Critical video processing error handling
        logger.error(f"Kritik video iÅŸleme hatasÄ±: {e}", exc_info=True)
        dusunce_logger.error(f"Kritik video iÅŸleme hatasÄ±: {e}", exc_info=True, extra={'user_id': user_id})
        await update.message.reply_text(get_error_message('general', user_lang))

# --- Token and memory error handlers (no change) ---
async def handle_token_limit_error(update: Update):
    error_message = "Ay ay ay! Mesaj geÃ§miÅŸi Ã§ok uzun! ğŸ¥º Åu an cevap veremiyorum ama biraz bekleyip tekrar dener misin? ğŸ™"
    await update.message.reply_text(error_message)

async def handle_memory_error(update: Update):
    error_message = "HafÄ±zam doldu sandÄ±m bir an! ğŸ¤¯ Bellek sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ± galiba... Biraz bekleyip tekrar dener misin? ğŸ™"
    await update.message.reply_text(error_message)

# --- Emoji adding function (model name from config) ---
async def add_emojis_to_text(text, user_id):
    try:
        user_settings = user_memory.get_user_settings(user_id)
        emoji_preference = user_settings['preferences'].get('emoji_preference', 'auto')
        emoji_model = genai.GenerativeModel(BOT_CONFIG["gemini_model_name"]) # Use configured model name

        if emoji_preference == 'none':
            return text

        sentiment_analysis_prompt = f"""
        Analyze the sentiment of the following text. Is it positive, negative, or neutral?

        Text: "{text}"

        Respond with ONLY one word: "positive", "negative", or "neutral".
        """
        sentiment_response = await emoji_model.generate_content_async(sentiment_analysis_prompt)
        sentiment = sentiment_response.text.strip().lower()
        dusunce_logger.info(f"Sentiment Analysis for Emoji: '{text}' - Sentiment: {sentiment}", extra={'user_id': user_id})

        emoji_prompt = f"""
        Sen ultra complex bir Protogen furry fox'sun, Nyxie.  AÅŸaÄŸÄ±daki metni analiz et ve kiÅŸiliÄŸine UYGUN emoji(leri) Ã¶ner.

        Metin: "{text}"
        Sentiment: {sentiment}
        Emoji Preference: {emoji_preference}

        Kurallar:
        - **Emoji SayÄ±sÄ±:**
            - EÄŸer emoji_preference 'high' ise: 2-4 emoji Ã¶ner.
            - EÄŸer emoji_preference 'low' ise: 0-2 emoji Ã¶ner (Ã§oÄŸunlukla 1 veya 0).
            - EÄŸer emoji_preference 'auto' ise: 0-3 emoji Ã¶ner.
            - EÄŸer emoji_preference 'none' ise: BOÅ DÄ°ZE dÃ¶ndÃ¼r (zaten baÅŸta kontrol edildi ama gÃ¼venlik iÃ§in burada da belirtiliyor).
        - Emojiler metnin tonuna, sentimente ve Nyxie'nin kiÅŸiliÄŸine uygun olsun. Enerjik, oyuncu, sevecen, teknoloji meraklÄ±sÄ± bir furry fox protogen gibi dÃ¼ÅŸÃ¼n.
        - Sentiment 'negative' ise, Ã§ok fazla veya aÅŸÄ±rÄ± neÅŸeli emoji kullanma. Daha sakin veya ilgili emojiler seÃ§.
        - EÄŸer uygun emoji yoksa, boÅŸ dize dÃ¶ndÃ¼r.
        - SADECE emoji(leri) veya boÅŸ dize ile yanÄ±t ver. BaÅŸka metin veya aÃ§Ä±klama YOK.

        YanÄ±t formatÄ±: Sadece emoji(ler) veya boÅŸ dize (aralarÄ±nda boÅŸluk olabilir)
        """
        dusunce_logger.info(f"GeliÅŸmiÅŸ Emoji Promptu (Sentiment Aware):\n{emoji_prompt}", extra={'user_id': 'N/A'})

        emoji_response = await emoji_model.generate_content_async(emoji_prompt)
        dusunce_logger.info(f"GeliÅŸmiÅŸ Emoji CevabÄ± (Gemini, Sentiment Aware): {emoji_response.text}", extra={'user_id': 'N/A'})

        if emoji_response.prompt_feedback and emoji_response.prompt_feedback.block_reason:
            logger.warning("Emoji suggestion blocked.")
            dusunce_logger.warning("Emoji Ã¶nerisi engellendi.", extra={'user_id': 'N/A'})
            return text
        else:
            suggested_emojis_str = emoji_response.text.strip()
            if not suggested_emojis_str:
                return text
            suggested_emojis = suggested_emojis_str.split()
            return f"{text} {' '.join(suggested_emojis)}"

    except Exception as e:
        logger.error(f"Error adding context-relevant emojis: {e}")
        dusunce_logger.error(f"Emoji ekleme hatasÄ±: {e}", extra={'user_id': 'N/A'})
        return text

# --- Analysis prompt function (no change) ---
def get_analysis_prompt(media_type, caption, lang):
    prompts = {
        'image': {
            'tr': "Bu resmi detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Resimdeki her ÅŸeyi dikkatle incele.",
            'en': "Analyze this image in detail and explain what you see. Carefully examine every aspect of the image.",
            'es': "Analiza esta imagen en detalle y explica lo que ves. Examina cuidadosamente cada aspecto de la imagen.",
            'fr': "Analysez cette image en dÃ©tail et expliquez ce que vous voyez. Examinez attentivement chaque aspect de l'image.",
            'de': "Analysieren Sie dieses Bild detailliert und erklÃ¤ren Sie, was Sie sehen. Untersuchen Sie jeden Aspekt des Bildes sorgfÃ¤ltig.",
            'it': "Analizza questa immagine in dettaglio e spiega cosa vedi. Esamina attentamente ogni aspetto dell'immagine.",
            'pt': "Analise esta imagem em detalhes e explique o que vÃª. Examine cuidadosamente cada aspecto da imagem.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°ÑĞ¿ĞµĞºÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.",
            'ja': "ã“ã®ç”»åƒã‚’è©³ç´°ã«åˆ†æã—ã€è¦‹ãŸã‚‚ã®ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ç”»åƒã®ã‚ã‚‰ã‚†ã‚‹å´é¢ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ë³´ì´ëŠ” ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ì´ë¯¸ì§€ì˜ ëª¨ë“  ì¸¡ë©´ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡å¹¶è§£é‡Šä½ æ‰€çœ‹åˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥å›¾ç‰‡çš„æ¯ä¸ªç»†èŠ‚ã€‚"
        },
        'video': {
            'tr': "Bu videoyu detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Videodaki her sahneyi ve detayÄ± dikkatle incele.",
            'en': "Analyze this video in detail and explain what you observe. Carefully examine every scene and detail in the video.",
            'es': "Analiza este video en detalle y explica lo que observas. Examina cuidadosamente cada escena y detalle del video.",
            'fr': "Analysez cette vidÃ©o en dÃ©tail et expliquez ce que vous observez. Examinez attentivement chaque scÃ¨ne et dÃ©tail de la vidÃ©o.",
            'de': "Analysieren Sie dieses Video detailliert und erklÃ¤ren Sie, was Sie beobachten. Untersuchen Sie jede Szene und jeden Aspekt des Videos sorgfÃ¤ltig.",
            'it': "Analizza questo video in dettaglio e spiega cosa osservi. Esamina attentamente ogni scena e dettaglio del video.",
            'pt': "Analise este vÃ­deo em detalhes e explique o que observa. Examine cuidadosamente cada cena e detalhe do vÃ­deo.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµÑ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´ÑƒÑ ÑÑ†ĞµĞ½Ñƒ Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾.",
            'ja': "ã“ã®ãƒ“ãƒ‡ã‚ªã‚’è©³ç´°ã«åˆ†æã—ã€è¦³å¯Ÿã—ãŸã“ã¨ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ãƒ“ãƒ‡ã‚ªã®å„ã‚·ãƒ¼ãƒ³ã¨è©³ç´°ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ë¹„ë””ì˜¤ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ê´€ì°°í•œ ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ë¹„ë””ì˜¤ì˜ ëª¨ë“  ì¥ë©´ê³¼ ì„¸ë¶€ ì‚¬í•­ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™æ®µè§†é¢‘å¹¶è§£é‡Šä½ æ‰€è§‚å¯Ÿåˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥è§†é¢‘çš„æ¯ä¸ªåœºæ™¯å’Œç»†èŠ‚ã€‚"
        },
        'default': {
            'tr': "Bu medyayÄ± detaylÄ± bir ÅŸekilde analiz et ve aÃ§Ä±kla. Her detayÄ± dikkatle incele.",
            'en': "Analyze this media in detail and explain what you see. Carefully examine every detail.",
            'es': "Analiza este medio en detalle y explica lo que ves. Examina cuidadosamente cada detalle.",
            'fr': "Analysez ce mÃ©dia en dÃ©tail et expliquez ce que vous voyez. Examinez attentivement chaque dÃ©tail.",
            'de': "Analysieren Sie dieses Medium detailliert und erklÃ¤ren Sie, was Sie sehen. Untersuchen Sie jeden Aspekt sorgfÃ¤ltig.",
            'it': "Analizza questo media in dettaglio e spiega cosa vedi. Esamina attentamente ogni dettaglio.",
            'pt': "Analise este meio em detalhes e explique o que vÃª. Examine cuidadosamente cada detalhe.",
            'ru': "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ğ¾Ñ‚ Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ. Ğ¢Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°ÑĞ¿ĞµĞºÑ‚.",
            'ja': "ã“ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’è©³ç´°ã«åˆ†æã—ã€è¦‹ãŸã‚‚ã®ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã™ã¹ã¦ã®è©³ç´°ã‚’æ³¨æ„æ·±ãèª¿ã¹ã¦ãã ã•ã„ã€‚",
            'ko': "ì´ ë¯¸ë””ì–´ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ë³´ì´ëŠ” ê²ƒì„ ì„¤ëª…í•˜ì„¸ìš”. ëª¨ë“  ì„¸ë¶€ ì‚¬í•­ì„ ì£¼ì˜ ê¹Šê²Œ ì¡°ì‚¬í•˜ì„¸ìš”.",
            'zh': "è¯¦ç»†åˆ†æè¿™ä¸ªåª’ä½“å¹¶è§£é‡Šä½ æ‰€çœ‹åˆ°çš„å†…å®¹ã€‚ä»”ç»†æ£€æŸ¥æ¯ä¸ªç»†èŠ‚ã€‚"
        }
    }

    if caption and caption.strip():
        return caption

    if media_type in prompts:
        return prompts[media_type].get(lang, prompts[media_type]['en'])

    return prompts['default'].get(lang, prompts['default']['en'])

def main():
    global user_memory
    application = Application.builder().token(os.getenv("TELEGRAM_TOKEN")).build()

    application.add_handler(CommandHandler("start", start)) # Added start command
    application.add_handler(CommandHandler("derinarama", handle_message))
    application.add_handler(CommandHandler("emoji_auto", set_emoji_auto))
    application.add_handler(CommandHandler("emoji_high", set_emoji_high))
    application.add_handler(CommandHandler("emoji_low", set_emoji_low))
    application.add_handler(CommandHandler("emoji_none", set_emoji_none))
    application.add_handler(MessageHandler(filters.VIDEO, handle_video))
    application.add_handler(MessageHandler(filters.PHOTO, handle_image))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    user_memory = UserMemoryDB(BOT_CONFIG["database_file"]) # Initialize UserMemoryDB

    async def initial_personality_generation(): # No change
        for user_file in Path(BOT_CONFIG["memory_dir"]).glob('user_*.json'): # Path changed to DB dir - but glob is not used anymore with DB
            user_id_str = user_file.stem.replace('user_', '')
            user_id = int(user_id_str)
            user_data = user_memory.get_user_settings(user_id)
            if 'personality_profile' not in user_data or user_data.get('personality_profile') is None:
                dusunce_logger.info(f"BaÅŸlangÄ±Ã§ kiÅŸilik profili oluÅŸturma baÅŸlatÄ±ldÄ±. KullanÄ±cÄ± ID: {user_id}", extra={'user_id': user_id})
                await user_memory.generate_user_personality(user_id)
                dusunce_logger.info(f"BaÅŸlangÄ±Ã§ kiÅŸilik profili oluÅŸturma tamamlandÄ±. KullanÄ±cÄ± ID: {user_id}", extra={'user_id': user_id})

    # asyncio.run(initial_personality_generation()) # Removed initial personality generation at startup for DB version - personality will be generated on first message

    # Fix for Python 3.12 asyncio event loop issue (no change)
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    loop.run_until_complete(application.run_polling(allowed_updates=Update.ALL_TYPES))

if __name__ == '__main__':
    main()